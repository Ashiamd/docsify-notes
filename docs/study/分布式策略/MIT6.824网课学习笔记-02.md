# MIT6.824网课学习笔记-02

> [【MIT 6.824】学习笔记 1： MapReduce (qq.com)](https://mp.weixin.qq.com/s/I0PBo_O8sl18O5cgMvQPYA) <= 2021版网络大佬的笔记
>
> [简介 - MIT6.824 (gitbook.io)](https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/) <= 知乎大佬的gitbook完整笔记(2020版，我这里看的网课是2021版)，推荐也阅读一遍2020版课程的大佬笔记
>
> [6.824](https://pdos.csail.mit.edu/6.824/schedule.html) <= 课程表

# Lecture16 BigData-Spark

> [MIT 6.824：spark - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/516534599) <= 网络博主的笔记

## 16.1 Spark-简述

​	某种程度上，Spark是Hadoop的继任者（毕竟都是批处理框架），通常用于科学计算。Spark很适合需要执行多轮mapreduce的场景，因为Spark将中间结果保存在内存中。

​	这篇论文中定义的RDD已经过时了，RDD被**数据帧(dataframes)**取代。但是<u>数据帧(dataframes)可认为是特定列的RDD(RDD with explicit columns)</u>，RDD的所有好的设计思想同样适用于数据帧(dataframes)。这节课只讨论RDD，并将其等同于数据帧。

+ In-memory computaion：Spark针对内存进行计算

## 16.2 Spark-RDD执行模型(execution model)

> [Spark中的Transformations和Actions介绍_sisi.li8的博客-CSDN博客_spark actions transformations](https://blog.csdn.net/qq_35885488/article/details/102745211) <= 有详细的算子清单描述
>
> 1. 所有的`transformation`都是采用的懒策略，如果只是将`transformation`提交是不会执行计算的，计算只有在`action`被提交的时候才被触发。
> 2. `action`操作：action是得到一个值，或者一个结果（直接将RDD cache到内存中）
>
> [Spark：Stage介绍_简单随风的博客-CSDN博客_spark stage](https://blog.csdn.net/lt326030434/article/details/120073802) <= stage划分讲解，图文并茂
>
> [spark——宽/窄依赖 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/350746998) <= 图文并茂，推荐阅读
>
> spark中， 某些操作会导致RDD中的数据在分区之间进行重新分区。新的分区被创建出来，同时有些分区被分解或合并。所有基于重分区操作而需要移动的数据被成为shuffle。在编写spark作业时，由于此时的计算并不是在同一个executor的内存中完成，而是通过网络在多个executor之间交换数据，因此shuffle操作可能导致严重的性能滞后。shuffle越多，作业执行过程中的stage也越多，这样会影响性能。之后的计划中将会学习spark的调优，所以shuffle过程将会在后面的学习中进行补充。
>
> spark driver会基于两方面的因素来确定stage。这是通过定义RDD的两种依赖类型来完成的，**窄依赖和宽依赖。**
>
> [spark持久化操作 persist(),cache()_donger__chen的博客-CSDN博客_spark persist](https://blog.csdn.net/donger__chen/article/details/86366339)
>
> spark对同一个RDD执行多次算法的默认原理：每次对一个RDD执行一个算子操作时，都会重新从源头处计算一遍。如果某一部分的数据在程序中需要反复使用，这样会增加时间的消耗。
>
> 为了改善这个问题，spark提供了一个数据持久化的操作，我们可通过persist()或cache()将需要反复使用的数据加载在内存或硬盘当中，以备后用。

​	了解RDD编程模型的最好方式就是先了解一些简单用例：

```scala
lines = sparks.textFile("hdfs://...") // 1. 仅创建一个RDD: lines，这里表示RDD存储在HDFS中
errors = lines.filter(_.startsWith("ERROR")) // 2. 创建第二个RDD: errors，lines只读，对其执行filter过滤以"ERROR"开头的行，生成新的RDD
errors.persist() // 3. Spark在内存中保存原始的RDD(errors)，用于后续计算。

// Count errors mentioning MySQL:
errors.filter(_.contains("MySQL")).count() // 4. count指令为action操作，会实际导致计算

// Return the time fields of errors mentioning
// HDFS as an array (assuming time is field
// number 3 in a tab-separated format):
erorrs.filter(_.contains("HDFS")) // 5. 
			.map(_.split('\t')(3)) // 6. 
			.collect() // 7. 
```

1. 这里创建一个RDD对象lines，该RDD存储在HDFS中，例如第100万条记录在HDFS分区1上，第200万条数据在分区2。这个RDD lines代表了这组分区。运行这行时，什么都不会发生，即论文所说的**惰性计算(lazy computations)**，实际计算在后续才进行。
2. 创建第二个RDD对象errors，接收对只读对象lines过滤仅保留开头"ERROR"的数据行。这里同样没有进行计算，只是预先创一个一个**数据流(dataflow)**，或者论文中所说的**计算迭代图(iterative graph of the computation)**。<u>后续如果完整到某个action操作时，整个逻辑流水线式执行，即先创建lines，后过滤lines的数据获取errors，再进行后续的其他RDD操作</u>。
3. 指定RDD对象errors在内存中保存，以便后续计算使用
4. 过滤errors中的数据，只保留带有"MySQL"字眼的记录，使用`count()`这个action操作统计数量（实际导致计算）
5. 过滤errors中的数据，只保留带有"HDFS"字眼的记录
6. 用`\t`切割字符串后保留第3个匹配的切割后字符串部分
7. 最后`collect()`该action操作，汇总结果（实际导致计算）

​	**可以看出来这里和Mapreduce有很大不同。在mapreduce中，每次运算完后数据回到文件中，下一轮计算需要重新从文件中读取数据；而这里Spark使用persist方法避免从磁盘重新读取数据**。

​	**RDD的API支持两类方法：Transformations和Actions，Actions才是实际导致计算发生的操作。**

+ Transformations：负责将RDD转换成别的RDD，**每个RDD都是只读(read-only)或者不可变的(immutable)**。所以你不能修改RDD，只能从现有的RDD生成新的RDD。
+ Actions：实际执行计算。只有执行了Actions后，前面的Transformations涉及的文件操作等逻辑才会实际被执行。

​	假设是使用命令行用Scala编写Spark，那么在4和7执行的时候，用户交互的命令行界面才会返回，因为执行的`count()`和`collect()`都是action操作，会实际触发Spark进行计算。action操作对应的时间点，Spark会collect许多worker，向它们发送jobs，或者通知调度器(scheduler)需要执行job。	

---

**问题：当错误文件从P1（HDFS分区1）中提取出来时，然后另一个错误文件从P2中提取出来，我理解上这是并行发生的？**

**回答：是的，就像mapreduce中有很多worker，worker在每个分区上工作，调度者scheduler会发送job给每个worker，而job是和数据分区关联的task。worker获取一个task后运行。所以你可以在分区之间获得并行性。你也会得到流水线中各个阶段之间的并行性。**

问题：lineage和事务日志(the log of transactions)有什么不同，是否只是操作粒度不同(the granularity of the operations)？

回答：目前我们看到的日志是严格线性的(strictly linear)，lineage也是线性的，但稍后会看到的使用fork的例子，其中一个阶段依赖于多个不同的RDD，这在日志中不具有代表性。它们有一些相似之处，比如你从开始状态开始，所有的操作都是具有确定性的，最后你会得到某种确定性的结束状态，就这点上它们是相似的。

问题：这个filter的例子中，它只需在每个分区上应用filter，但有时，比如我看到transformation也包含join或sort。

回答：是的，join和sort更复杂，后序介绍。

问题：第三行persist是不是我们开始进行计算的时候？

回答：不，这里还没有任何东西会被计算出来，前三行仍然只是在描述Spark程序需要执行的操作。

**问题：前面的代码中，如果不调用`errors.persist`，会发生什么？**

**回答：如果不调用`errors.persist`，那么后续发生的第二次计算，即（序号7. action，collect），Spark需要先重新计算errors（我理解上，指的是需要重新构造lines对象RDD，然后过滤得到errors。即如果没有保存RDD到内存，那么当前RDD进行完一次action计算后，下一次如果代码中用同一个RDD想进行下一个action计算，就需要重新从源头构造当前的RDD）**

问题：对于不调用persist的分区，在mapreduce的情况中，我们把它们存储在中间文件中，但我们仍然将它们存储在本地文件系统中。Spark这里处理数据时，是会产生中间文件存储在磁盘中吗，还是将整个数据流处理保存在内存中？

回答：默认情况下，整个流都在内存中，但有一个例外，稍后会详细讨论。代码序号3.这里`persist`使用另一个flag，应该是reliable。然而集合存储在HDFS，这个称为checkpoint（代码序号2.）。

问题：对于分区，这里代码序号2.对应的HDFS，说有多个分区，这个是Spark临时为每个worker进行的分区划分HDFS数据？

回答：代码序号1.对应的lines这个RDD产生于HDFS。这里说的分区，是HDFS文件直接直接定义的（也就是说原始的HDFS中的文件本来就分区好了，不是后面SPark临时分区的）。但是你也可以执行repetition重新分区的transformation，一般是stage这样做，后续会提到。比如使用hash partition技巧，你还可以定义自己的分区程序，提供一个分区程序对象或抽象。

追问：所以这里代码里HDFS文件分区，之前就已经由HDFS处理了，但如果你后续想Spark再自定义patition流程，也可以再来一次。

回答：是的。

## 16.3 Spark-worker窄依赖容错

​	和mapreduce处理容错的方式基本一致，Spark中的某个worker崩溃时，需要重新执行stage。

​	<u>这里只讨论Spark的worker崩溃的情况。Spark的worker崩溃，意味着丢失内存中的数据，或者说丢失RDD的partition数据，而后续的RDD计算部分可能依赖于丢失的partition。所以，这里需要重新读取(reread)或重新计算(re-compute)这个partition分区</u>。**调度器(scheduler)某时刻发现没有得到worker的应答，然后重新运行对应partition的stage**。

​	<u>和mapreduce函数式编程一样，视频中列举的transformations算子，都是**函数式的**。它们将RDD作为输入，产生另一个RDD作为输出，是完全确定性的(completely deterministic)</u>。所以这里如果发现一个worker崩溃了，scheduler重新安排某个worker生成同样的partition即可。

---

问题：所以就是因为函数式API实现，所以Spark能保证partion重计算后不变？

回答：是的。

## 16.4 Spark-worker宽依赖容错

​	如"16.3 Spark-worker窄依赖容错"所述，Spark的窄依赖容错，和mapreduce的容错处理基本一致。相对更为棘手的是宽依赖的容错处理。	

​	假设有个Spark在指令流中，child-RDD-1的数据来源自parent-RDD-1～parent-RDD-3的结果，假设是由于进行了join等操作，而child-RDD-1往下执行产生child-RDD-2。此时如果产生chid-RDD-2的worker崩溃，为了恢复这个RDD，就需要往源头追溯，重新计算，最后会追溯到需要parent-RDD-1～parent-RDD-3并行进行重新计算。显然，如果还是按照窄依赖的方式进行容错恢复，性能损耗严重。

​	**对于宽依赖容错恢复，解决方案是设置检查点或持久化RDD**。

​	比如在parent-RDD-1～parent-RDD-3取checkpoint检查点存储的partition快照RDD，而不是重新进行并发计算。之后只需要重新计算child-RDD-1～child-RDD-2即可。

---

**问题：如果使用了一般的persist函数，但是论文也提到了一个RELIABLE flag。想知道，使用persist函数和使用RELIABLE flag有什么区别？**

**回答：persist函数，意味着你将RDD保存到内存，后续action计算可以重复使用（默认是一个action触发后，后续其他action使用到同样的RDD用于触发计算时，需要重新计算一遍这个被依赖的RDD，而persist会保存这个RDD在内存中免去重新计算）；checkpoint或者RELIABLE flag意味着，你将整个RDD的副本写入HDFS，而HDFS是持久或稳定的文件存储系统。**

问题：有没有一种方法可以告诉Spark不再持久化某些东西，因为如果你持久化了RDD，而且你做了大量的计算，但是后面的计算不在使用那个RDD，你可能会把它永远留在内存中。

回答：Spark使用了一个通用的策略，如果真的没有空间了，它们可能会将一些RDD放到HDFS或者删除它们，论文对具体的计划有些含糊。当然，当计算结束，用户退出或停止driver，那我想那些RDD肯定从内存中消失了。

## 16.5 Spark-迭代计算PageRank

> [google pagerank_百度百科 (baidu.com)](https://baike.baidu.com/item/google pagerank/2465380?fromtitle=pagerank&fromid=111004&fr=aladdin)
>
> PageRank，网页排名，又称网页级别、Google左侧排名或佩奇排名，是一种由根据[网页](https://baike.baidu.com/item/网页?fromModule=lemma_inlink)之间相互的[超链接](https://baike.baidu.com/item/超链接?fromModule=lemma_inlink)计算的技术，而作为网页排名的要素之一，以[Google](https://baike.baidu.com/item/Google?fromModule=lemma_inlink)公司创办人[拉里·佩奇](https://baike.baidu.com/item/拉里·佩奇?fromModule=lemma_inlink)（Larry Page）之姓来命名。
>
> PageRank通过网络浩瀚的超链接关系来确定一个页面的等级。Google把从A页面到B页面的链接解释为A页面给B页面投票，Google根据投票来源（甚至来源的来源，即链接到A页面的页面）和投票目标的等级来决定新的等级。简单的说，一个高等级的页面可以使其他低等级页面的等级提升。
>
> [PageRank算法详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/137561088) <= 推荐阅读
>
> 在实际应用中许多数据都以图（graph）的形式存在，比如，互联网、社交网络都可以看作是一个图。图数据上的机器学习具有理论与应用上的重要意义。 PageRank 算 法是图的链接分析（link analysis）的代表性算法，属于图数据上的无监督学习方法。
>
> PageRank算法最初作为互联网网页重要度的计算方法，1996 年由Page和Brin提出，并用于谷歌搜索引擎的网页排序。事实上，PageRank 可以定义在任意有向图上，后来被应用到社会影响力分析、文本摘要等多个问题。

​	PageRank是一个对网页赋予权重或重要性的算法，（权重）取决于指向网页的超链接的数量。

​	这里代码用例通过Spark实现PageRank算法，如果最后补充`ranks.collect()`，那么计算就会实际在机器集群上进行：

```scala
val links = spark.textFile(...).map(...).persist()
var ranks = // RDD of (URL, rank) pairs
for (i <- 1 to ITERATIONS) {
  // Build an RDD of (targetURL, float) pairs
  // with the contributions sent by each page
  val contribs = links.join(ranks).flatMap {
    (url, (links, rank)) =>
    links.map(dest => (dest, rank/links.size))
  }
  // Sum contributions by URL and get new ranks
  ranks = contribs.reduceByKey((x,y) => x+y)
  .mapValues(sum => a/N + (1-a)*sum)
}
```

​	这里有2个RDD，其中links表示图的连接/边(the connection of the graphs)，即URL之间的指向关系；而ranks表示每个url的排名。（这里省略代码讲解的记录，想仔细分析的可以看原视频）

​	这里links通过`persist()`常驻内存，所以下面ranks在for循环中迭代使用links，不需要重新计算links，直接从内存中读同一份RDD对象links即可。

![img](https://pic3.zhimg.com/80/v2-2afc25a81e3c651a9a02c50801562412_1440w.webp)

​	随着ranks中迭代次数的不断增加，每一次循环(图中的contribs)都是一个stage，当调度器计算新的stage时会将transformation的一部分附加到lineage graph中。代码中，links被保存到内存，下面ranks中每一次循环都会重复使用links。<u>图中links和ranks在每次循环中做join，构成一个stage，这里涉及网络分区通信，论文中提到一些优化手段，可以指定分区RDD，使用hash分区</u>，意味着links和ranks文件，这两个RDD将以相同的方式分区，它们是按key或hash key进行partition的。**论文中提到这里可以通过hash key分区，使得具有相同hash key的数据partition落到同一个机器上，这样即使join直观上是宽依赖，但是可以像窄依赖一样执行**。比如对于U1，对应分区P1，你只需要查看links的P1和ranks的P1，而hash key以相同的方式散列到同一台机器上。<u>scheduler或程序员可以指定这些散列分区，调度器看到join使用相同的散列分区，因此就不需要做宽依赖，不需要像mapreduce那样做一个完整的barrier，而是优化成窄依赖执行</u>。

​	这里如果一个worker崩溃，你可能需要重新执行许多循环或一次迭代，所以这里可以设置比如每10次迭代生成一个checkpoint，避免重新整个完整的计算。

---

问题：所以我们不是每次都需要重新计算links或其他东西，比如我们不持久化的话？

回答：这里唯一持久化的只有links，这里常驻内存，而ranks1、ranks2等都是新的RDD，但你偶尔可能像持久化它们，保存到HDFS中。这样如果你遇到故障，就不需要循环迭代从0开始计算所有东西。

问题：不同的contribs，可以并行计算吗？

回答：在不同的分区上，所以是可以并行计算的。

## 16.6 Spark-小结

+ RDD by functional transformation：RDD是函数式转换创建的
+ group togethr in sort of lineage graph：他们以谱系图的形式聚集在一起
  + reuse：允许重复使用
  + clever optimization：允许调度器进行一些优化组织
+ more expressive than MR：表现力比mapreduce更强

+ in memory：大多数数据在内存中，读写性能好

---

问题：我想论文中提到了自动检查点(automatic checkpoints)，使用关于每次计算所需时间的数据，我不太理解是什么意思。但是，他们将针对什么进行优化？

回答：可以创建一个完整的检查点，这是一种优化。创建检查点是昂贵的，需要时间。但在重新执行时，如果机器出现故障，也要花很多时间。比如，如果你从来不做检查点，那么你要从头开始计算。但如果你定期创建检查点，你不需要重新计算。但如果你频繁创建检查点，你可能把所有时间都花费在了创建检查点上。所以这里有一个优化问题。

问题：所以可能计算检查点，需要非常大的计算？

回答：是的，或者在PageRank的情况中，也许每10次迭代做一次checkpoint。当然如果检查点很小，你可以创建checkpoint稍微频繁点。但在PageRank中checkpoint很大， 每个网页都有一行或一条记录。

问题：关于driver的问题，driver是不是在客户端？

回答：是的。

问题：如果driver崩溃，我们会丢弃整个图，因为这是个应用程序？

回答：是的，但我也不知道具体会发生什么，因为调度器有容错。也许你可以重新连接，但我不太清楚。

问题：关于为什么dependency optimization的问题。你提到他们会进行hash patitioning，这是怎么回事？

回答：这个和Spark无关，是数据库数据常见的分区概念。即假设对dataset1和dataset2使用hash partion，之后相同hash key的links和ranks数据会分布到同一个机器上，而此时对links和ranks进行join，就不需要机器进行网络通信，直接在机器本地进行处理即可。即多个机器处理多个分区，但是每个分区内links和ranks的join只需要本地进行，不需要和其他机器网络通信。

问题：什么时候是宽依赖，什么时候是窄依赖？

回答：明确的父RDD和子RDD是一对一那就是窄依赖；如果是1父RDD对N个子RDD，就是宽依赖。

**问题：worker和stage？**

**回答：每个worker在parition上运行一个stage。所有stage在不同的worker上并行运行。pipeline中每个stage是批处理(batch)。**

# Lecture17 缓存一致性-Memcached缓存系统

> [MIT6.824 Facebook的Memcache - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/471267649) <= 网络博主的笔记
>
> [redis探索之缓存一致性_青铜大神的博客-CSDN博客](https://blog.csdn.net/qq_22156459/article/details/125496995)
>
>  一致性是指同一时刻的请求，在缓存中的数据是否与数据库中的数据相同的。
>
> + **强一致性**：数据库更新操作与缓存更新操作是原子性的，缓存与数据库的数据在任何时刻都是一致的，这是最难实现的一致性。
>
> + **弱一致性**：当数据更新后，缓存中的数据可能是更新前的值，也可能是更新后的值，因为这种更新是异步的。
>
> + **最终一致性**：一种特殊的弱一致性，在一定时间后，数据会达到一致的状态。最终一致性是弱一致性的理想状态，也是分布式系统的数据一致性解决方案上比较推崇的。

​	这是一篇2013年来自Facebook的论文，memcached在网站开发中很常用。这篇论文不目的不是介绍构建系统的新思想/新概念/新方式，更多的是构建系统的实践经验的总结。

​	在这种情况下，可以支持10亿/s的请求量。从论文中可以学到3个lesson：

+ 高性能：只使用市面上现有的组件构建系统，但是整体性能很高。

+ 性能和一致性之间的取舍：设计主要受性能驱动，但同时想要得到某种程度的一致性。这里Facebook的应用不需要真正的线性一致性，比如新闻的消息延迟了一会后才更新并不影响业务。
+ 经验法则：cautionaru tables，论文中列举了一些警示项。

## 17.1 网站演变

1. 单服务端，单DB
2. 多服务端，单DB
3. 多服务端，多DB（分片或其他手段，使DB处理环节也有并行性。这里可能涉及分布式事务，需要2PL+2PC）
4. 多服务端，多DB，添加缓存

​	到了4. 添加缓存时，系统新增了缓存层(cache layer)，每个单独的缓存服务器被称为memcached daemon，整个缓存集群称为memcache。

​	这里的主要挑战包括：

1. 如何保持数据库和缓存之间的一致性

2. 如何保证数据库不会过载

## 17.2 最终一致性(eventual consistency)

​	Facebook这里不追求强一致性/线性一致性，他们追求的是：

+ 顺序写入(write ordering)：写入按照某种一致的整体顺序应用，你不会在时间问题上感到奇怪，这些由数据库完成，对于memcache层不是大问题
+ 可接受读旧数据(reads are behind is ok)：读取短暂落后也没关系。
  + 例外就是客户端进行写后读，即写后要求读到刚更新的数据。(clients read their own writes)

​	*zookeeper也是不同session不保证读到其他session的最新写入，但是同一个session内写后读能读到最新数据。*

## 17.3 缓存失效方案(cache invalidation)

​	Facebook的基本方案即，**缓存失效方案(cache invalidation plan)**。

![img](https://pic2.zhimg.com/80/v2-95c3f42178d2995e6dfbafc36feb538d_1440w.webp)

​	FE前端将数据写入MySQL，此时squeal监听MySQL的事务日志，发现有一个key被修改，向缓存发送失效消息，缓存将会删除指定key的value缓存。此时另一个FE发起read，缓存不命中，然后从MySQL读数据，之后将数据加入缓存。

---

**问题：为什么不在删除缓存后，立即更新缓存呢？**

**回答：那就是所谓的更新方案(update scheme)，原则上也是可行的，但实现会更麻烦点，这里缓存、数据库、客户端之间会需要一些cooperation。比如client1和client2发请求，原本client1发送的x=1应该更早生效，client2发送的x=2应该后生效作为新值，但由于网络问题，导致client2请求先被处理，如果用更新方案，缓存x=2，后续client1请求被处理后，缓存x=1，这里缓存中的x会一直都是旧值。当然，你可以通过修改MySQL内部一些流程，比如要求按序处理client1和client2的请求等等。但是这里系统希望能直接用现成的组件搭建，而不是再进行复杂的修改，所以论文中选择的是失效方案。**

## 17.4 系统优化

​	Facebook为了容灾，在两个地区部署了数据中心：

+ 只有primary数据中心接收数据的写入，backup数据中心只读

+ **就算是backup数据中心发生了写入请求，也会请求primary数据中心**

+ primary数据中心的数据变化，通过squeal进程监听并同步到backup数据中心

  这里primary和backup之间存在一定延迟，不过系统不追求强一致性，所以可以接受。

​	系统获取高性能的手段（按序逐渐增加优化手段）：

1. 分区或分片 (partition or shard data)

   + 大容量 (capacity)：一般对数据分区后，每个分区可以容纳大量数据

   + 并行度 (parallism)：分区后，不同分区数据读取可以并行

2. **复制数据 (replicate data)**

   + <u>热键友好 (hot key)：可以使相同键扩展到不同的memcached服务器（两个数据中心），缓解单点热键问题</u>

   + 需扩容 (capacity)：复制数据本身需要另外的硬件资源，但本身没有扩大存储的数据的容量

3. **构造集群(cluster)**

   + <u>热键友好 (hot key)：同一个数据中心内，再将单缓存服务扩展成缓存集群服务，热键由单实例存储复制到集群内多实例</u>
   + 减少连接 (reduce connection)：避免了incast congestion问题，集群内实例均摊了前端的缓存数据请求TCP连接
   + 网络压力 (reduce network pressure)：很难建立具有双向带宽的网络，这里流量均摊到集群内的实例，整体网络压力承载量大

​	如果系统中有冷键，其将被存储在多个regions，基本上什么都不做。所以Facebook还有一个额外的pool，称为**region pool，应用程序可以决定保存不是很受欢迎的键到regional pool，它们不会在时间上跨所有集群复制，你可以考虑region pool在多个集群之间共享，用于不太受欢迎的键存储。**

---

问题：这里如果backup发起写请求，会写到primary，但是这里backup缓存失效后，因为同步需要时间，backup可能还是会缓存到旧数据？

回答：是的，后面会说怎么处理这个问题。

## 17.5 保护数据库(protecting db)

> [什么是惊群，如何有效避免惊群? - 知乎 (zhihu.com)](https://www.zhihu.com/question/22756773)
>
> 惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。

​	假设所有的memcache都失效了，db就算分片了也不能够扛下10亿/s的查询请求。

+  新建集群 (new cluster)

  假设新建了一个cluster，预想分担系统50%流量，但是new cluster的memcache还没有数据，如果50%读请求都进入new cluster，会导致流量都直接击中底层db，导致db崩溃。所以这里创建new cluster时，会填充new cluster的memcache，待预热完缓存数据后，再实际切50%流量到new cluster。

+ **惊群问题 (thundering herd problem)**

  某个热键被更新后，缓存失效，多个前端请求同一个热键，得到null后都请求db查询数据，增大了数据库瞬时压力。**这里Facebook采用租约(lease)解决这个问题，即热键失效时，某个前端获得lease，负责更新该缓存，而其他前端则retry请求缓存，而不是直接查询db。**（这里lease用于解决性能问题，后续会提到同样也解决一致性问题）

+ 缓存崩溃 (memcache server failed)

  如果不做处理，缓存崩溃后，会有大量请求直接发送到db，增加db压力。这里系统设置了gutter pool，用于临时处理memcache崩溃的场景。当memcache崩溃后，改成查询gutter pool，若还是没有，就查询数据库然后将数据放到gutter pool中（同样起到缓存作用，但gutter pool只是容错应急用的，非常态使用）。

## 17.6 缓存读写竞争(race)

1. 避免缓存旧值(avoid stale set problem)

   Client1执行`get(key)`，Client2执行`delete(key)`，Client1执行`put(key)`。由于有lease机制，这里C1执行get时获取lease，而C2执行delete时会使得C1的lease失效（因为更新了db，所以C2需要让key缓存失效），后面C1的put会失效(被拒绝)。**利用lease机制，避免了"17.5 保护数据库(protecting db)"提到的惊群问题，也避免了这里旧值填充的问题**。

2. 冷集群预热时缓存其他集群旧值(cold cluster)

   C1更新db值，执行`delete(key)`，C2从cold cluster读数据未命中，从另一个cluster缓存取数据，并执行`put(key)`。这里C2设置的缓存还是旧值。**这里Facebook通过two-second hold-off，推迟两秒机制解决该问题，其规定从cold cluser删除key值后，2s内不能对那个key做任何put操作**。所以这里举例的C2执行的put操作会被拒绝。<u>这种问题只会出现在集群预热阶段，即集群新建后暂时没有数据，会从其他运行中的集群取数据（可能由于primary和backup之间同步延迟问题，导致取到旧缓存值）</u>。因为这问题只出现在预热阶段，所以他们认为2s够用了，这也足够让其他写入传播/同步到cold database。

3. backup写后读不到值(primary/backup)

   C1在backup执行写操作，数据会写到primary的DB，随后backup的缓存失效(执行`delete(key)`)，此时C1直接`get(key)`取到空值，因为primary的数据修改通过squeal同步到backup的缓存需要时间。**这里Facebook通过remote marker解决该问题。当C1执行`delete(key)`后，标记key为"remote"，后续马上执行`get(key)`时，发现key的"remote"标记，于是从远程的primary的缓存读取值，而不是从本地读取。完成`get(key)`后，再移除key的"remote"标记。**

---

问题：即使没有lease invalidation机制，我们仍然会遵从弱一致性，你会获得在过去某个时间发生的顺序写入。但至少这能确保观察到自己的写入，对吗？

回答：lease还能确保你不会回到过去（读旧数据）。

## 17.7 小结

+ 缓存的重要性(caching is vital)：正确的使用缓存，使得论文中的系统能够承载10亿/s的请求
+ 分区和分片(partition and shard)：分区和分片，提高整体存储量和并行度
+ 复制(replicaiton)：均摊热键访问成本
+ 缓存和DB的一致性处理：利于lease、two-second hold off、remote marker等特殊技术手段，保证系统的弱一致性，主要是防止出现长期缓存旧值的问题。

---

问题：远程标记(remote marker)，他们怎么知道这是一个相关的data race。或者他们怎么决定什么时候需要使用远程标记？

回答：论文中没有明确说明，但猜测是为了保证最终一致性(eventual consistency)中的写后读能读取到刚才的最新写入。

问题：他们对get请求使用UDP，对其他请求使用TCP，这是一种业界普遍的做法吗？

回答：一般人们更喜欢用TCP，但TCP开销更大。有些人喜欢在UDP上使用他们自己的类似可靠传输协议的技术，比如QUIC等。

# Lecture18 fork一致性-SUNDR

## 18.1 SUNDR简述

> [拜占庭将军问题_百度百科 (baidu.com)](https://baike.baidu.com/item/拜占庭将军问题/265656?fr=aladdin)
>
> 拜占庭将军问题（Byzantine failures），是由莱斯利·兰伯特提出的点对点通信中的基本问题。含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。
>
> [分布式系统入门 | 拜占庭将军问题 - Alan-Yin - 博客园 (cnblogs.com)](https://www.cnblogs.com/alan-yin/p/14901121.html) <= 详细的文章，推荐阅读
>
> **拜占庭故障**（也叫做**交互一致性**，**源一致性**，**错误雪崩**，**拜占庭协议问题**，**拜占庭将领问题**和**拜占庭故障**）是一个计算机系统的状态，特别是**「分布式计算」**系统中，其中的组件可能会故障，并且在组件故障时可能发生故障信息。
>
> 项目开始时，并不清楚总共需要多少台计算机才能保证 n 台故障计算机的阴谋不会“阻挠”正确运行的计算机达成共识。Shostak 表明至少需要 `3 n+ 1`，并设计了一个两轮 `3 n+ 1` 消息传递协议，该协议适用于 n = 1。他的同事 Marshall Pease 将算法推广到任何 n > 0，证明 `3 n+ 1` 是充分必要的。这些结果，连同[Leslie Lamport](https://en.wikipedia.org/wiki/Leslie_Lamport)后来使用数字签名证明 3n 的充分性，发表在开创性的论文—— 《[Reaching Agreement in the Presence of Faults](https://en.wikipedia.org/wiki/Byzantine_fault#cite_note-9)》(在存在故障的情况下达成共识)。

​	该章节主要讨论的主题为**去中心化的系统(decentralized system)**。

​	去中心化，即没有单一的权威机构(single authority)来控制这个系统。前面介绍的系统，或多或少所有的机器和服务在某种程度上合作(cooperate)，且在单一机构处于或任何单一autority的控制下。

​	去中心化的系统更难建立，因为你可能不得不解释**拜占庭失败(byzantine failures)**。在过去的课程中，介绍的分布式协议，都是默认认为每个参与者都遵守协议规则，但在拜占庭问题和拜占庭参与者之间，情况就不一样了，可能有参与者恶意捏造虚假数据进行传输。这类话题，位于分布式系统(distributed system)和安全性(security)的交汇点(intersection)上。后面即将介绍的论文，主要就和密码学或安全理念有关，比如签名(signing)和哈希(hashing)。

​	<u>可能有人好奇，SUNDR有被普遍使用吗？实际上没有任何系统直接实现SUNDR，或者直接基于SUNDR</u>。但是，**SUNDR提出了一些强大的技术或设计思想，特别是signed log，尽管是概念设计。同样的想法出现在很多其他去中心化的系统中**。从git到比特币(Bitcoin)，或其他类型的**加密帐本(cryptographic ledger)**，都能看到类似的设计思想。有一个系统直接收到SUNDR的影响，即Keybase，其被Zoom收购。

## 18.2 SUNDR论文背景

​	论文动机，是为了设置网络文件系统(network file system)。回想之前读过的Frangipani论文，其主题也是实现一致的网络文件系统。不同的是，SUNDR这里认为网络文件系统可以是拜占庭式的，攻击者可能通过某些手段得以操控网络文件系统。

​	**SUNDR实际上不是在文件服务器上维护整个文件系统，文件系统尽可能简单，类似Frangipani论文中的Pedal，它几乎就像一个块设备，而客户端真正实现了文件系统**。所以在SUNDR中，不是client向serevr发送、创建文件，而是从block服务器发送数据块和读取数据块。

​	SUNDR就整体文件操作流程，和Frangipani论文类似，文件系统在client，server负责硬件磁盘块(blocks)资源管理。**两者最大的在于，Frangipani的文件系统Pedal和所有client之间是完全信任的，而SUNDR中client不受信任，文件系统本身也不可信**。

​	这篇论文主要集中在一些安全属性的讨论，重点是**完整性属性(integrity properties)**。与保密性(confidentiality)相反，保密性关于保护数据避免泄漏；而完整性只是为了确保系统结构是正确的，检测数据非法修改行为，无论数据本身是否公开。

​	比如，2003年Debian Linux遭受过恶意开发者在代码嵌入trapdoor的问题，而Debian Linux被部署到众多服务器上使用。当时Debian Linux为了处理该问题，开发冻结了几天，试图找出源代码库中哪些部分仍然是正确的，以及哪些部分被攻击者修改了。这类攻击会周期性地发生，Ubuntu在2018年或2019年也有出现类似的问题。

## 18.3 安全场景举例

> [树根|主体_比特币技术原理----区块链的本质 (cha138.com)](https://it.cha138.com/javascript/show-84427.html)

​	zoobar是一个虚拟银行类型的应用程序，系统的注册用户可以互相转移zoobar（充当货币的作用）。

+ A：某有权限修改`auth.py`的程序员，主要负责权限校验开发
+ B：某有权限修改`bank.py`的程序员，主要负责银行交易等行为的开发
+ C：某拷贝git项目，部署zoobar代码，后续由于代码有后门等原因被攻击的大冤种

​	这里明显存在安全隐患：

1. 某个程序员S偷偷修改`auth.py`，导致C部署项目后，项目内缺失身份认证的一些关键步骤，存在安全漏洞。
2. 某程序员S针对C修改了`bank.py`，删除了里面关于身份校验的逻辑，导致银行业务内不在进行身份认证等校验。因为银行业务流程本身没有改动，所以相对难察觉。

---

​	接下来谈谈一些常见的处理手段，来尝试避免上面的安全隐患。

​	修改文件后，对文件使用非对称加密，即public key加密。这样程序员S无法获取到程序员A的私钥，无法完成程序代码`auth.py`的修改，因为S没有密钥，签名自己的代码修改后上传会被代码托管服务器拒绝。但这里S仍有方法攻击，比如发送程序员A以前修改过的`auth.py`文件，这个文件以前由A签名，所以能成功上传，也许旧代码存在安全漏洞。另外，S可以声明删除`auth.py`文件，C无法知道这是否正常，这可能需要对系统所有文件做一个捆绑，以某种方式决定文件系统最新版本是什么，来避免这个问题。

## 18.4 SUNDR设计思想

​	从前面的`18.3 安全场景举例`，可想到网络文件系统存在很多攻击的方式，并且对应的修复方法并不容易或很难只通过某一种手段完全规避攻击。而SUNDR论文就是为了试图解决这类问题。

​	SUNDR论文提到了一个设计思想，即**对操作的日志签名(signed log of operations)**，尽管论文本身没有直接实现这个大的想法。<u>可以理解为操作日志的增强版本，在日志条目有签名的情况下，涵盖了条目及之前的条目</u>。

​	我们在前面的所有**分布式系统(distributed systems)**和**故障恢复协议(recovery protocols)**中看到，日志是一个非常强大的设计思想，经常用于保证系统的正确性，同样也适用于拜占庭背景下的系统正确性保障。

​	这里假象一个log结构如下，假设写操作为mod，读操作为fetch：

| mod<br/>auth.py<br/>signed A | mod<br/>bank.py<br/>signed B | fetch<br/>auth.py<br/>signed C | Fetch<br/>bank.py<br/>signed C |
| ---------------------------- | ---------------------------- | ------------------------------ | ------------------------------ |

​	**这里每次读或写操作都进行log记录，并且每次操作完后，需要对当前操作记录log以及之前的log进行签名**。即`signed B`这里签名的log包括当前B对`bank.py`的mod操作，也包含之前A对`auth.py`的mod操作。这样当client C接收到B的log时，就不可能丢失A的日志条目，因为一旦丢失，签名就对应不上。通过这种机制，服务器现在更难有选择地删除日志条目。

​	此时如果有一个用户下载项目代码，其参与维护，经过以下流程：

1. 校验签名(check signatures)：项目中所有的操作log都有签名，只要对不上，就知道项目有其他恶意开发者篡改代码。
2. **检查最后一个日志条目(check its own last entry)**：**这是为了保证客户端不会被服务器回滚，所以服务器总是检查最后一个条目，确保最新的log修改条目没有被恶意攻击者回滚**。比如A新增了一个mod操作log，但S通过某些手段回滚log记录，使A的修改在log中不存在。

3. 构造文件系统(construct FS)：它知道文件系统系统没有被回滚到旧版本，所以可以应用所有现存的修改，基本上就是在client上构建文件系统树
4. 新增操作log条目并签名(add entry log + sign)：对项目进行修改，在操作log中新增条目，并对其进行签名（和前面说的一样，需要对当前log条目以及之前的log条目进行签名）
5. 上传操作log到文件系统服务器(upload log to FS)：本地记录log后，向服务器上传log。

​	这个协议在现实中是未完成的，但提供了一些设计概念，让我们思考最终怎么成功在拜占庭服务器的上下文中实现安全。

## 18.5 SUNDR为什么记录fetch

​	可能有人会有疑问，修改操作记录log中很正常，为什么fetch读取操作也要记录到log中？

​	假设fetch操作不需要记录到log中，那么前面"18.4 SUNDR设计思想"的log可以看作如下：

| mod<br/>auth.py<br/>signed A | mod<br/>bank.py<br/>signed B |      |      |
| ---------------------------- | ---------------------------- | ---- | ---- |

​	C一开始从服务器获取前面的log（比如到A的操作log为止），校验无问题后，安装`auth.py`；后面B的操作log也发送过来，C发现B对`bank.py`进行了修改，校验log后无异常，于是安装`bank.py`。<u>问题在于这里A和B之间的修改可能对应的系统版本不一致</u>。比如`auth.py`对应系统版本1，`bank.py`对应系统版本2，两者同时运行会有一些异常。

​	而如果log需要记录fetch，那么故事变更如下：

1. C fetch `auth.py`，服务器发送过来prefix，即A和B的操作记录
2. C add fetch  to log，upload log，C获取log后，添加fetch操作记录，上传log到服务器
3. C fetch `bank.py`，服务器发送过来prefix，包括A和B操作，以及C刚才的fetch操作记录。此时如果log中没有刚才新增的fetch操作，C就会拒绝该日志

​	*（这里稍微有点懵，感觉大意就是如果没有把fetch加入log的话，那么当前client只会一味地接受新log，新log产生的影响可能对上次读log得到的数据有影响；而如果把fetch加入log，那么client就能感知到新log插入的位置在自己fetch之前还是之后，避免新log对已读出的数据有影响却无感知的问题。）*

---

问题：当前例子中是什么阻止服务器将fetch放在日志的正确位置？

回答：每个日志条目都包含之前的所有条目（指签名），服务器不能在fetch A和B之前的prefix之后修改切片。

问题：假设它只想发送A的修改，它知道A的修改和之前所有内容的hash，然后它可以把fetch C插入到那里，因为它知道，这是一个hash。

回答：是的，然后他们就不能发送B的修改。因为B的修改直接在A之后，所以它也不能切分A和B。

## 18.6 fork一致性

​	目前看到的是，服务器不能真正操作日志，它只能发送prefixes或hide parts，他可以将前缀发送给client，但它自身不能修改log。所以log被时刻修改时，不同客户端可能看到不同版本的log。这就是fork一致性的含义。

​	fork一致性场景举例，下面描述A、B、S三方的log记录：

| server S | a    |      |      |
| -------- | ---- | ---- | ---- |
| client A | a    | b    | c    |
| client B | a    | d    | e    |

​	<u>A和B从S fetch log后，自己在本地修改，后续并发地upload log到S。这里可以看出来A和B都拥有同样的a日志前缀记录，但是后面各自的本地log不一样，S接收到A和B的log后，作为服务端不能擅自修改log，所以根据fork一致性，会同时保留A和B的两条log修改链路，而不是直接合并到原有log上</u>。

## 18.7 如何检测fork

​	这篇论文提到了两个检测fork的方案：

1. 带外通信(out-of-band communication)：如果A和B互相访问，询问对方最后一条记录是什么，得到不同的答案，他们就意识到双方造成了log分叉。如果没有分叉，一方的log应该是另一方的前缀。所以<u>客户端可以定期交换最新的日志条目，确保不产生log分叉</u>。
2. **三方受信时间戳机器(timestamp box)**：引入某种受信任的机器，比如时间戳机器。它将时间戳添加到log中，每个客户端知道它是一个文件。在文件系统中，包含当前时间，时间戳机器每隔几秒钟就更新一次文件，客户端读取该文件。他们知道每隔几秒钟会有一次新修改。这里timestamp box相当于就是fork

​	第二种方案也就是SUNDR论文中提出的。Bitcoin比特币就采用类似方案二的方式，以某种方式达成读取共识，决定哪个fork能继续执行。

## 18.8 用户粒度文件系统快照(i-handle)和版本向量(version vector)

​	为处理fork一致性问题（即让用户在不同fork上做取舍，决定使用哪个fork），SUNDR采用用户文件系统快照和版本向量（版本向量包含快照i-handle和用户修改计数）。

​	服务器维护log，而其他人维护snapshot快照。**实际上SUNDR所做的，不是字面上创建快照，而是维护着文件系统的快照视图，并针对每个用户。文件系统按照用户进行分片，每个用户都有属于自己的视图快照。这里有一些协议确保不同的快照和不同的用户是一致的**。

​	**SUNDR中，有一种叫做用户i-handle的东西，用户i-handle唯一标识文件系统中的快照**。<u>i-handle对应一个i-table的加密hash表，其记录系统中所有inode的hash值。当某个文件被修改时，对应的inode节点hash值会更新，往上追溯，i-table、i-handle都会更新。这提供给用户一个完整的文件系统快照</u>。

​	而为了处理用户之间的一致性，SUNDR提出了**版本向量(version vector)**的概念。<u>每个版本向量对应一个用户的i-handle，比如A在修改`auth.py`后有一个i-handle，同时版本向量维护所有用户的当前i-handle的修改计数。比如对于A的i-handle有记录`{A:1; B:0; C:0}`表示只有A修改了A自身的i-handle一次，其他人没进行过修改</u>。

​	**用户对于整个文件系统的快照i-handle，以及每个用户(包括当前用户)对当前i-handle的修改次数，<u>作为一个版本向量(version vector)整体进行签名</u>**。

```pseudocode
// 1. A修改auth.py后生成一个信的i-handle,假设叫 i-handle-A，对应的修改计数只有A进行过1次，所以A的版本向量如下
VS-A: i-handle-A , {A:1; B:0; C:0} // 之后对VS-A sign签名

// 2. B修改之前获取所有的变更，然后新建VS-B版本变量，其修改了文件bank.py，对应版本向量如下
VS-B: i-handle-B , {A:1; B:1; C:0} // 之后对VS-B sign签名
// 这里A修改计数为1，因为B获取了所有的log记录后，才进行修改，而之前A对文件系统中的auth.py进行过1次修改

// 3. C下载所有用户的版本向量，取版本最新的1个，这里最新的是VS-B。因为VS-B包含A的所有操作，以及后续B的所有操作
此时C通过对比VS-A、VS-B，发现VS-B最新，从VS-B版本向量对应的文件系统快照，获取auth.py和bank.py
```

## 18.9 小结

> [梅克尔树_百度百科 (baidu.com)](https://baike.baidu.com/item/梅克尔树/22456281?fr=aladdin)
>
> 梅克尔树（Merkle trees）是[区块链](https://baike.baidu.com/item/区块链/13465666?fromModule=lemma_inlink)的基本组成部分。虽说从理论上来讲，没有梅克尔树的区块链当然也是可能的，只需创建直接包含每一笔交易的巨大区块头（block header）就可以实现，但这样做无疑会带来可扩展性方面的挑战，从长远发展来看，可能最后将只有那些最强大的计算机，才可以运行这些无需受信的区块链。 正是因为有了梅克尔树，以太坊节点才可以建立运行在所有的计算机、笔记本、[智能手机](https://baike.baidu.com/item/智能手机/94396?fromModule=lemma_inlink)，甚至是那些由Slock.it生产的物联网设备之上。

+ 拜占庭参与者问题(Byzantine participant)：拜占庭参与者问题，需要在去中心化系统中处理。因为没有单一的机构作为信任的来源/担保。

+ 签名式日志(signed log)：签名式日志，是对付恶意服务器的一个强大工具，后续的课程会讨论这类日志如何在比特币中使用。特别是fork一致性，fork是如何被创建的，在比特币案例中是如何解决的。

​	这些就是去中心化系统主要讨论的知识点/技术点。

----

问题：SUNDR使用B+树还是什么数据结构？Merkle tree和这些数据结构有什么区别

回答：SUNDR使用Merkle，因为提出这个结构的人就是这个名字，所以称这种树结构为Merkle tree。

问题：验证签名时，如果log有100个条目，需要计算100次hash吗？

回答：通常只计算一次，也就是最后一个新增的条目。虽然理论上每个log entry的签名需要重新计算，但实际应用中，一般用户本地也会保存之前的log的hash值，只需要计算后面新增的hash值进行比对就好了。（提问者吐槽这样效率低，但是就是这么做）

问题：所以hash就像一条Merkle chain？

回答：是的。同样的想法。

**问题：如果改变文件系统中某几个block，是所有block的hash都需要重新计算吗？然后再追溯到inode、i-table、i-handle？**

**回答：只需要计算被修改的几个block的hash，然后往前追溯相关的inode（block对应的inode）、i-table（对应的几个inode）、i-handle（对应的i-table）需要重新计算。论文有提到一种优化可以让这一过程计算更快，但hash通常很快，而签名才是成本更高的操作。**

问题：我们使用版本向量来确保系统不会返回/回滚到旧状态，那为什么系统不直接返回旧状态和旧版本向量，如果它保留第二份复制的话？

回答：版本向量只有fork一致性，SUNDR fork一致性，没有保证更多其他别的。

**问题：fork一致性，需要用到时间戳吗？**

**回答：fork一致性，我的意思是，服务器可以在任何时间点fork日志，为他们可以将日志合并回一起提供一致的视图。**（如何合并决策权还是在client端，sevrer端只是负责存储各种fork情况的log发展分支）

问题：所以这里我们能做到的最好的情况就是保持fork一致性，它允许fork，但我们可以检查出fork。

回答：是的。

追问：这里我们能检测到fork，那么能得到比fork一致性更强的东西吗？

回答：我们可以选择一个fork并继续。

追问：但是SUNDR没有办法做到这一点。

回答：是的。（我理解上就是SUNDR的server不直接决定哪个fork能继续，而是交给client自己决定用哪个fork继续，sevrer只负责存储多个用户版本向量，换言之server保存多个fork，但不对外声明哪个fork是所谓的正统/主干）

**问题：SUNDR现在提出了一些(检测fork的)方法吗？**

**回答：检测fork的方法，提出时间戳机器来检测fork。**

问题：时间戳机器只是一个附加条目的服务器？

回答：是的，并且是可信的，不在对手的控制下。

# Lecture19 p2p比特币(peer-to-peer bitcoin)

​	谈论比特币的一个很大原因在于，其完成了实现难度高的**拜占庭参与者达成共识(consensus with byzantine paticipants)**。

​	*人们可以随意加入或退出，其中有些人是恶意的，并且在事务发生的顺序上达成了共识，这是一个很有挑战性的实现，尤其是比特币还和金钱相关。*

​	和SUNDR类似，比特币也有**签名的操作日志(signed log of operations)**，比特币也能处理fork (handle fork)。

​	比特币是一个真正开放的系统，可以容忍拜占庭参与者，并达成共识。

## 19.1 实现的难点

1. 担心出现完全的伪造(concern outright forgery)

   人们试图凭空捏造交易，并输入日志中，试图误导其他参与者。从根本上，签名操作使伪造变得困难。这里假设密码系统不易被攻破，所以很多核心流程经密码学加密处理后，认为是可靠的。

2. 双重花费(double spending)

   假设你手头有一些比特币，一个拜占庭参与者试图花费同一个比特币两次。通过查询所有交易的公共账本或公共日志，判断是否存在这种情况，并就日志的以往交易记录达成共识，避免重复消费同一个比特币能成功。

3. 偷窃(theft)

   论文中讨论不多，即有人偷窃了别人的私钥，因此可以冒充身份花钱或使用比特币。因为人们将自己的钱包和签名密钥存储在计算机上，这使得黑客有机会破解并窃取他们财产。（这里不会花太多时间介绍这个，这里主要集中讨论分布式系统方面的知识）

## 19.2 交易简述

​	这里简化交易的记录，即一个交易记录主要包含以下数据：

+ 转账的目标用户的公钥(public key)，dst

+ 之前交易的hash值(hash(prev))
+ 比特币的前持有者的私钥签名(signature)，src
+ 金额，更多的dst、src...（这里出于简化交易流程的描述，不对其他数据做描述）

​	一条记录表示比特币经过src的同意，从src转移到dst。交易也是经过编码(encoded)的，而不是纯粹的记录，这里忽略这些细节。

+ T6：pub(x), .... 
+ T7：pub(y), hash(T6), sig(x) // 这里表示x因为某些原因向y转账
+ T8：pub(z), hash(T7), sig(y) // 假设y想要在咖啡店买咖啡，于是向z比特币支付费用

​	这里假设y的密钥只有y知道，否则任何人可以顶替y进行签名，即使用y钱包的钱进行消费。

​	这里z可以对交易记录进行校验，有效则完成实质的交易。

## 19.3 双重花费(double spending)

> [区块链中双重支付/ 双重花费/ 双花是什么？ - 区块链文库 (5m88.com)](https://www.5m88.com/post/4445.html)
>
> 双重支付是一个故意的分叉，是指具有大量计算能力的节点发送一个交易请求并购买资产，在收到资产后又做出另外一个交易将相同量的币发给自己。攻击者通过创造一个分叉区块，将原始交易及伪造交易放在该区块上并基于该分叉上开始挖矿。如果攻击者有超过50％的计算能力，双重花费最终可以在保证在任何区块深度上成功；如果低于50％则有部分可能性成功。
>
> [区块链中双花问题背后的力量角逐 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/473103163)
>
> [中本聪共识 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/446608209)

​	考虑一下双重花费问题(double spending)。

​	这里假设前面举例中，y对同一笔比特币生成2次交易记录(y creates two txn records)。假设Z和Q都是拿铁店，Y试图同时产生两笔交易。

+ T8：pub(Z), hash(T7), sig(y) // Y => Z
+ T8'：pub(Q), hash(T7), sig(y) // Y => Q

​	如果Z和Q都认同了交易记录，那么Y将收获两份拿铁，但是只实际支付了一份拿铁的费用。

​	处理方法即，检查所有之前存储的日志。交易记录在log中按序存储，假设如下：

.... T6，T7，T8，T8'

​	这时Q检查到T7为止，发现交易都还是正常的，但是到T8时，发现原本Y打算转给Q的比特币实际已经被消费，于是拒绝T8'交易。但现在问题在于，我们怎么确保系统中所有参与者都同意这个日志？

​	所有交易都在同一位置，包含相同的内容、相同的hash，相同的签名，所以我们可以验证交易，这就是共识问题涉及的场景。人们有时也把现在所述的这种验证方法称为**中本聪共识(the Nakamoto consensus protocol)**。

## 19.4 共识问题思考

日志顺序和fork思考：

​	假设有一个受信的服务器S，其他客户端C1、C2、C3向S发送交易记录T5、T6、T7....。最后由S对这些交易记录进行排序。很显然，在比特币的场景下，服务器S不可信，所以这种方案不可靠。

​	如果用之前SUNDR的思路，则可以让Client生成log，Server只负责追加log，那么同样会遇到fork的问题，即可能出现两个分支：

+ T5，T6，T7，T8
+ T5，T6，T7，T8'

​	<u>按照SUNDR的思路，server产生fork后，由client自行达成共识选择fork。这里假设Z走fork1，Q走fork2，两者校验log都会认为Y的交易是合法的（即没有检测出来双重花费）</u>。显然，直接这么设计不合理。

---

网络中日志顺序思考：

​	假设Client往网络中其他多个服务器都发送log，那么怎么确定最后每个服务器在追加log的顺序上达成共识？可以想到之前Raft等共识算法处理方式即majority大多数原则，只要所有服务器中大多数（超过一半）都认为log应该是某个顺序排列的，那么这种序列作为主流传播。

​	然而，**在比特币这种去中心化的系统中，系统节点在任何时候都可能加入或离开，并且系统中没有维护所有参与者的列表，所以也无法得知系统在什么情况达到majority大多数**。majority解决共识问题的方案不适用于比特币这类去中心化的开发分布式系统，只适用于Raft这类在设置中封闭的系统。

## 19.5 加密货币的共识算法PoW和PoS简述

> [权益证明_百度百科 (baidu.com)](https://baike.baidu.com/item/权益证明/22447953?fr=aladdin)
>
> 与要求证明人执行一定量的计算工作不同，权益证明要求证明人提供一定数量加密货币的所有权即可。权益证明机制的运作方式是，当创造一个新区块时，矿工需要创建一个“币权”交易，交易会按照预先设定的比例把一些币发送给矿工本身。权益证明机制根据每个节点拥有代币的比例和时间，依据算法等比例地降低节点的挖矿难度，从而加快了寻找随机数的速度。这种共识机制可以缩短达成共识所需的时间，但本质上仍然需要网络中的节点进行挖矿运算。因此，PoS机制并没有从根本上解决PoW机制难以应用于商业领域的问题。
>
> POS一并解决了POW浪费能源和算力集中两个痛点，理论上还能缩短了共识时间，但同时也丢弃了POW的某些优势，因此更容易分叉，一笔交易需要等待更多确认才能确保安全，而POS最大的问题是其安全性和容错性还没有得到严格的数学论证。
>
> [Proof of Stake 是什么？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/71195492)
>
> 权益证明（PoS）是一种公共区块链的共识算法类别，它依赖于验证者在网络中的经济利益 。 在基于工作证明（PoW）的公共区块链（比如比特币和当前实施的以太坊）中，算法奖励解决密码难题的参与者，以验证交易并创建新的区块（即采矿）。 在基于PoS的公共区块链（例如以太坊即将推出的Casper实现）中，一组验证者轮流在下一个区块提出投票并投票，每个验证人投票的权重取决于其存款的大小（即股权）。 PoS的显着优势包括安全性，集中化风险降低和能源效率 。
>
> [区块链共识算法Proof-of-Stake (PoS权益证明) 常见问题解答 (1)_济源IT小伙一枚的博客-CSDN博客_proof-of-stake](https://blog.csdn.net/qq_43518645/article/details/105661513)

​	其关键的想法在于，**工作量证明(proof-of-work, PoW)**。<u>基本规则即，一个机器节点需要经过大量的计算才能扩展日志(extend the log)，通过PoW胜出的节点决定下一个log entry</u>。

​	为什么PoW是有效的？因为很难冒充winner。扩展日志时需要解决的问题，实际上需要一台计算机进行一个月的计算。（因为矿工通过挖矿能获取比特币，所以不需要担心没人挖矿，即增加了其他人双重花费的难度）

​	而PoW的缺点也很明显，那就是浪费资源(energy waste)。

​	由于PoW浪费资源严重，后续出现了其他加密货币或其他设计，基于其他想法，比如基于**权益证明(proof-of-stake)**。

​	在PoS中，假设你拥有3%的货币，那么你可以决定3%的日志条目，哪个可以被追加。PoS不需要解决PoW中的计算密集型难题。PoS也获得业界关注，其中**以太坊(Ethereum)**是使用PoS的代表之一。

---

问题：冒充PoW中的winner有多难，假设我们有服务器A和B，A想要log附加e1，B想追加e2。而A解决难题并发布解决方案，然后B认可A的解决方案。B不能直接用自己的签名重新发布解决方案，是因为e2的难题(puzzle)和e1的难题不一样是吗？

回答：是的，难题不同，后续会介绍更多细节。但是这足以决定在哪个fork上，比特币会接受fork，就像SUNDR一样，比特币通过某种方法决定选择哪个fork。

**问题：网络分区(network partitioin)问题。假设能做到在广大互联网级别的网络分区，那就不能证实某人确实双重花费(double spend)。比如这个人在两个网络分区里进行花费。假设这里网络分区时间持久很长。**

**回答：比特币基本上每10min产生一次交易日志。如果你想小心地避免double spend，那么你通常会等待更多的日志entry，比如5～6个，所以基本是经过了1个小时，在真正决定接受(某些新产生的fork)之前，仍在正确的fork上。**

## 19.6 区块链(block-chain)

> [区块链（数据结构）_百度百科 (baidu.com)](https://baike.baidu.com/link?url=opf5hLlleFKG2hk8ZhGC2XcNgPwKwnhW4sY5TZkW3XrrdwWbPYW2doWYhm4OBrC3FnjvHqMP5bDJ2xxSAZI9mlE0NFV3PtxrknREGsISYLlO7lykdNP0fnwBHRvIbyfC)
>
> 区块链，就是一个又一个区块组成的链条。每一个区块中保存了一定的信息，它们按照各自产生的时间顺序连接成链条。这个链条被保存在所有的服务器中，只要整个系统中有一台服务器可以工作，整条区块链就是安全的。这些服务器在区块链系统中被称为节点，它们为整个区块链系统提供存储空间和算力支持。如果要修改区块链中的信息，必须征得半数以上节点的同意并修改所有节点中的信息，而这些节点通常掌握在不同的主体手中，因此篡改区块链中的信息是一件极其困难的事。相比于传统的网络，区块链具有两大核心特点：一是数据难以篡改、二是去中心化。基于这两个特点，区块链所记录的信息更加真实可靠，可以帮助解决人们互不信任的问题。

​	PoW需要花费大量能量，完成操作的一种方式是，以块(block)为单位对组(group)进行交易处理，PoW以一个block为基础。

​	其工作方式中，我们不会直接创建blocks，但会通过进行很多交易(transactions)来创建很多blocks，形成**区块链(block-chain)**。

​	每个block区块的数据，这里简单描述以下几个：

+ 链中前一个block的hash值唯一标识符

+ 交易记录txns
+ nonce（难题中发挥关键作用）
+ 时间戳timestamp

​	一个block一般是1MB级别大小。游戏规则即收集交易的节点，然后解决难题，一旦有人解决难题，他就会把这个block发送给网路中每一个人。每个人都可以检查节点是否真正解决了难题，如果检查通过，那么他们会接受这个block作为chain中的下一个区块。

​	<u>当winner到达下一个block，该区块即是winner的工作量证明(PoW)，通常计算PoW的一方被称为矿工(miners)</u>。矿工(miner)必须计算这个新block的hash，使其包含n个前置零(H(B) has N leading zero)，矿工可以通过改变nonce做到这点。<u>所以miner对nonce进行随机猜测，计算hash并检查前置0的个数，前置零的数量越大，那么这个块越容易被接受</u>。很明显前置零的数量要求N越大，计算难度越大，N可以随着时间推移而改变，以调整难度。

+ 对于比特币系统而言，矿工工作是必要存在的，目标是让每个矿工平均进行一个月的CPU计算。

+ 目标希望第一个解决难题的人，需要计算约10分钟。

​	无论哪个miner最先完成了难题，在整个网络中传播该block，这么做大概需要10min。10min的原因是，网络中传播1MB的block需要一点时间，而且需要有足够的时间将区块提供给许多节点，以避免fork。

---

问题：所以需要一些leading zeros，hash需要被节点接受，它是每个节点单独设置的数字吗？

回答：不，这是protocol的难题，一个agreed puzzle，关于N的共识。

**追问：那么这个N说会时间推移而改变，进而变动难题解决的难度。这里变量N是这么通过网络传播的？有一个中央服务器计算出N并发送到其他地方吗？**

**回答：不，后续会介绍。block中的时间戳是一个提示点。如果一个块之间的时间变得太短，那么难度就上升了。当然，这里时间戳是使用hash进行验证的，所有这些东西都在blockchain中，每个人看到相同的blockchain。所以他们将计算时间戳之间的相同差值，并在难度方面作出同样的调整。这是一种很酷的设计，日志中有很多东西，如果其中一些是具有确定性的，你可以对日志的内容计算任何确定性函数。**

追问：所以这里对于N有确定性的函数能够计算。那我如果尝试发送少于N个前置0的hash记录block，然后网络中的节点都会把我赶出来？

回答：是的，因为你没有真正的解决方案。

问题：有什么办法能阻止攻击者不断向网络发送错误的解决方案吗？

回答：是的，拒绝服务攻击(denial of service attack, DOS)，幸运的是检查解决方案非常容易，所以拒绝一个不正确的解决方案不需要多少时间。

**问题：如何确定时间戳？比如每个block都设置自己的时间戳。**

**回答：是的，winner，成功开采的矿工在block中设置timestamp时间戳。**

追问：如果他们故意将时间戳设置成比所用时间更长的时间，或许后面计算难度就会因此下降？（因为N计算难度受block之间时间戳差值影响，如果差值小说明当前计算难度不够高，进而会导致N上升，即计算难度上升）

回答：它不能说谎说过头，他们有10min的时间（应该指的是计算难度一般都是10min左右能出下一个block），我不知道时间戳具体怎么检查的，但应该是有办法检查的。

## 19.7 块和交易(block + txns)

​	假设B5已经被miner i计算出来，B5前一个位置是B4。此时miner i得知一些交易，进行难题计算中，而新来的交易被存放到内存缓冲区中，已备用于生成后续的block。假设miner i幸运的完成这些交易的计算，得到B6，并广播网络声明B6为B5的下一个log entry。miner i构造B6时，会选择B6包含的交易是哪一些，而其他本地接收到但未解决难题的交易用于后续的block计算。假设有别的矿工用剩余的交易计算出B7，那么miner i会在B6后记录B7，然后删除本地缓存中B7已经结束的所有交易，继续处理剩下的且不在B7内的交易。

​	这就是high level上对于每个block之间如何交互的大致介绍。

---

问题：随着交易的到来，试着计算区块的nonce，这会给你N个leading zeros，然后新的交易会进来....

回答：不，这些新的交易不会是当前block的一部分，他们被放在一边，用于下一个区块的计算。

追问：不能把这些新来的交易加入当前block吗？

回答：这会改变hash值。

追问：就算让block容纳更多的交易导致hash值改变了，不也还可以继续调整nonce吗？

回答：但你还需要考虑block大小限制，不能超过协议规定的某个预定义常量。当然还有其他别的限制使得一个block不能无限制地一直追加容纳的交易记录。整体来说就是你计算一个hash，得到一个新block，或者接收到别人计算的新block，然后尝试再继续计算下一个（需要去除已经被新block容纳的交易，用剩余的交易继续计算）。

问题：有没有可能有些矿工因为算力不够一直输，导致从来没获利？

回答：是的，当然。如果我用自己的笔记本挖矿，我很肯定只会亏电费。

问题：交易池(transaction pool)是本地的吗？

回答：是的，每个节点都维护一个交易池(transaction pool)。当它们从网络中其他节点接收交易时，他们使用交易池使下一个区块失败。这里包含各种各样的规则来决定如何选择交易，但不是课程重点。

问题：如果要append，你需要把你的transaction告诉每个人？

回答：是的，或者你告诉一群节点(a bunch of peers)，它们会继续把交易传播给其他网络节点。

问题：据我所知，当一名矿工挖矿成功或核实一笔交易时，都会得到奖励。

回答：是的。

追问：他们做了核实，但涉及到时间戳时，它们也可以选择撒谎，假设你有两个verifers，并且它们在同一个block上工作，而且它们几乎同时完成核实，但其中一个撒谎了，它们把时间戳做得稍微更早了一点...

回答：难度并不是在每个block改变，它会定期更改，在一定数量的区块被计算出来之后。后续每个人都能看到这些时间戳是什么，我想一般在经历某个数量的block之后，难度会进行调整。在这个点上，你已经同意了过去所有的block，所有人都达成一致，这也包括block上的时间戳值。

**问题：共识问题，我想这能运作归结于几乎每个节点都运行中相同的代码，或至少非常精确地遵守规则。如果我的代码有bug，会发生什么？也许我的bug代码在一堆不同的节点上运作着，这是不是抛出了一致性的概念。**

**回答：是的，只要大多数节点运行正确的代码，系统就能正常工作。但如果代码有后门，那你就会遇到问题。比如Linux如果有后门，你也会有问题。**

**问题：所以每个节点都运行相同代码？**

**回答：有几个不同的比特币版本，但它们中有一个主要的核心，类似Linux项目，它有维护者，代码审核以及其他类似的事情。而大多数钱包和大多数节点，都会运行其中一个标准化版本。**

## 19.8 分叉和最长链(forks and longest chain)

> [最长链原则_a soldiers的博客-CSDN博客_最长链原则](https://blog.csdn.net/qq_38491875/article/details/108858450)

​	区块链系统中，任何节点都有可能扩展log或者chain，因此会产生分叉(forks)。

​	比如B5=>B6=>B7，可能正好几乎同时有人解决难题，得到另一个fork，B5=>B6=>B7'。而B7内含有Y->Z的交易，B7'含有Y->Q的交易，必须以某种形式确定后续只使用某一个fork，否则Y出现双重花费（同一个比特币消费两次）。

​	产生fork的原因一般有：

1. 存在至少两个miner几乎同时解决难题，并发布block(find nonce at same time) 
2. 网络延迟导致block传播缓慢(slow network)

​	<u>在遇到fork时，当前节点对fork保留，不做处理。当forks中一个分支出现新的block，比其他fork长时，**节点会切换到最长的fork(peer switches to longest fork)**</u>。最终所有节点都会选择最长的fork，在最长链上达成一致，并且沿着最长的链继续采矿。

​	最长链是如何降低双重花费(double spending)的可能性的，这里先回顾一下双重花费的两种情况：

1. Y同时发送Y->Z和Y->Q两笔交易给peers，显然通过log校验，Y->Q会被拒绝
2. Y发送Y->Z和Y->Q到不同的peers，此时可能产生forks，但是通过最长链原则，只有一笔交易能生效

​	**论文假设攻击者算力比好人的整体算力低。当Y试图双重花费时，除了Y->Z该交易所属的block生成，Z需要等待该block后再产生5～6个block，此时Z就可以认为当前fork是最长链，线下认同这笔交易**。（此时就算有Y->Q这个fork，也可以认为不可能比Y->Z所在的chain长。一般一个fork领先5～6个block后，就基本不可能被另一个frok赶超了）	

---

问题：产生fork的第二个原因，比如网速慢，你能不能检测到。如果矿工包含的时间戳，当他们找到解决方案时？

回答：你可能存疑什么是下一个正确的chain，但这将在之后的区块得到确认，而你使用的未来的区块确实最长的链是什么。

问题：是谁分发这些难题(puzzle)的？

回答：没有必要分配难题，难题是预先确定的。你必须通过block计算出一个hash，且有足够的前置零。所以没有难题被分发的过程，唯一被分发的东西可能是解题的难度N。正如前面所说，这种情况通过时间以一种确定性的方式调整难度N。

问题：所有这些发生的交易，然后通过gossip协议或别的什么，交易被分发给所有节点，然后达成一致，比如哪些交易被打包成一个block。所有人都对block达成了一致。

回答：不，矿工收到交易，由矿工来决定哪些交易该放在block中，然后它开始计算，如果它win了，那block中就含有它指定的那些交易。还有其他复杂的规则限制，但是矿工一定程度上可以决定block中含有哪些交易。而且有一定的激励制度让矿工们愿意做正确的事情。

## 19.9 矿工激励(miner incentive)

> [区块链 矿工奖励 - 蝴蝶教程 (jc2182.com)](https://www.jc2182.com/blockchain/blockchain-merkle-tree.html)
>
> 正如我们在“[比特币-采矿](https://www.jc2182.com/blockchain/blockchain-mining.html)”一章中所看到的，在任何给定时间段内，矿工可能会被许多交易淹没。系统中预先定义了一个块的最大大小，因此必须在该块中仅包含一定数量的事务。
>
> 区块中的交易数量取决于预定义的区块大小和每个区块的平均长度。这里的一个重要提示是，发件人不应在其消息中包含太多信息，以使其简短，从而激励矿工在其他冗长的消息之前接受它。
>
> 通常，发件人还会根据一定数量的比特币增加交易费，以激励矿工尽早将其包括在他的区块中。
>
> 构建区块链的另一个结果是它的规模。在一段时间内，整个区块链可能变得太大，以至于节点无法将其存储在其磁盘上。这可以通过使用下面描述的Merkle树来解决。

​	到目前为止，我们看到难题是工作量证明(PoW)的思想核心，也是真正达成共识的核心。但是这需要矿工们做相当多的工作，他们必须使用高性能的计算机计算hash，平均下来每个矿工约需要进行一个月的计算工作。

矿工愿意进行计算工作，是因为有矿工激励机制：

+ 有一些比特币保留在池(pool)中，用于奖励矿工（主要奖励）

  比如第一批比特币交易被创建时，矿工从池子里拿到奖励。区块中的交易对矿工来说就是奖励。矿工可以在block中第一个插槽插入交易，把钱从pool转到自己身上。随着时间推移，奖励的比特币数额会降低。几年前是12.5比特币，一段时间后编程6.25。每21万个区块，奖励数额减半，直到它遇到了最后正好能接受的比特币分母，然后就会停下来。

+ 交易本身需要支付奖励费用（次要奖励）

  为了挖一个区块，每一笔交易都需要支付一点费用，而矿工收取区块中所有交易的费用，用这些费用奖励矿工自身。所以实际上矿工的收入不仅是pool中瓜分的6.25比特币，还有伴随着交易而来的费用。这是次要的奖励。

比特币发展至今，已经可以看作是矿工之间的军备竞赛，因此产生一些新事物：

+ 矿工池(miner pool)

  矿工们彼此合作，并互相分享收入。如果你的pool中有很多很多节点，人们可以分享采矿带来的收入，因为他们（矿工）作为一个pool运作的，从概率上讲，他们更有可能win。

+ 特殊硬件(special hardware)

  一些公司发行特殊版本的硬件，它们很擅长计算hash，就是专门为miner pools量身打造的。

+ 高速链路(speed links)

  他们(矿工团体)有到许多节点的高速链路，所以如果他们找到了一个区块，他们可以先把它拿出来，称为winner。

----

问题：这就是你说的为什么每个block都需要大约10min来挖掘，尽管它需要一个月的CPU算力。

回答：是的，平均一个月。但是偶尔运气好，选对nonce，就能更快解决问题。通过改变nonce，你可能只需要不到一个月的时间，这就是10min的由来。

问题：是一个月比较重要还是10min比较重要？因为如果只有一个矿工，预计是平均需要一个月，对吧？

回答：是的，但是如果有很多很多矿工，平均一个block就是10min。

问题：有没有可能出现完全无解的难题？

回答：不，可能需要花费很长的时间，但终究有解。

**问题：由于比特币的价值实际上非常不稳定，那我们如何确保矿工的激励制度足以保证未来矿工们会继续计算？我的意思是因为奖励的数量是预先确定的，假设是6.25比特币，但由于某些原因，比特币价值下跌了，然后对于矿工来说，激励措施不够好。**

**回答：是的，这时候矿工这样做就没有任何价值，然后比特币网络就崩溃了。如果要解决这件事，那可以通过上涨交易费用（即对于矿工而言的次要奖励）。**

**追问：但交易费用上涨，对于使用区块链的人们来说，又是一种相反的激励。**

**回答：是的，但如果每个人都在比特币网络上，如果你想交易商品，就必须和比特币网络上某个人交易。所以有各种各样复杂的分析，我不想预测结果会是什么。按照目前的速率，我想在2140年，这是奖励制度用尽的时候，之后将完全基于交易费用激励矿工。**

## 19.10 实际问题(practical issues)

> [软分叉_百度百科 (baidu.com)](https://baike.baidu.com/item/软分叉/22447204?fr=aladdin)
>
> 硬分叉是指比特币区块格式或交易格式（这就是广泛流传的“共识”）发生改变时，未升级的节点拒绝验证已经升级的节点生产出的区块，然后大家各自延续自己认为正确的链，所以分成两条链。
>
> 软分叉是指比特币交易的数据结构（这就是被广泛流传的“共识”）发生改变时，未升级的节点可以验证已经升级的节点生产出的区块，而且已经升级的节点也可以验证未升级的节点生产出的区块。
>
> [比特币硬分叉与软分叉(BTC,BCH,BTG,B2X)_链圈子 (wwsww.cn)](https://www.wwsww.cn/btbwhy/5815.html)
>
> (区块大小导致交易速度问题) : 比特币网路受制于区块大小，目前每个区块1MB的区块大小，处理能力大概是20万笔交易。近年来随着比特币蓬勃发展，交易数量越来越多，因此区块空余空间越来越小，交易速率也受限制。
>
> 2015年5月，比特币前核心开发者Gavin Andresen 表示，比特币网路扩容问题迫在眉睫，并提出了透过硬分叉的方式，将比特币块大小上限提高到20mb，时间定为utc 时间2016 年3 月1 日。
>
> 不过，到了2016 年，各大阵营提出的扩容方案达不到一致。整个社群对于应该直接进行链上扩容的硬分叉方案，还是采用SegWit 软分叉方案，分成了两大阵营。
>
> + 什么是硬分叉: 硬分叉是指当规则改版，采新旧不同版本的节点因规则不同而导致共用的区块錬的分叉时，旧版本的节点硬性地不接受新版本节点产生的区块，因此采用旧规则的节点而生的分叉继续依旧规而变长，而采用新规则的节点而生的分叉也继续依新规则而变长，采取不同新旧规则的世界两分明，各自筑构各自的分叉（branch/fork）。<u>简单说 就是不相容旧比特币</u>。
>
> + 什么是软分叉 : 软分叉是指当规则改版，采新旧不同版本规则的节点因规则不同而导致共用的区块錬的分叉时，采用旧规则的节点也会软性地接受新规则节点产生的区块，新旧不同版本的节点混在一起筑构区块錬。<u>简单说 就是相容旧比特币</u>。

+ 块计算和传播时间(10 min)

  我认为10min是时间的上限，大概是10次传播到网络的时间。所以比特币试图避免一种特权，特权分叉(privilege fork)。避免fork的两个节点几乎同时计算，大致同时扩展一条链。避免这种问题的一种方法，就是给节点留有足够的时间传播block到其他很多节点，让其他大多数节点接受这个block。这就是10min的由来。

+ 区块大小(block size)

  当然，区块大小决定了每秒的交易数量，一个block大概是1MB，大约每隔10min生成一个新区块，然后交易数量也被限制成能在单个block中容纳的数量。

+ 改变协议(changes require consensus)

  改变需要达成共识。

  + some are easy

    其中一些改变是容易达成共识的，比如解题难度N（前置零的数量）调整，其有一种确定性的算法，每个节点使用相同算法计算

  + some changes in soft fork

    还有一些变化导致了soft fork。比如比特币的核心发布版本作出改变，有一些不兼容的。所以你会有旧客户端(old clients)，旧版本的client和新版本client之间会产生一些forks。当然从长远看，人们很可能会选择安装了新软件的新fork。

  + some changes in hard fork

     例如几年前，社区内就block size进行讨论（增大size还是保持原本的size），然后分裂出两fork，实际可能不止2个fork。

​	当共识算法进入比特币这类去中心化的系统，你会遇到各种各样的实际问题，它可能导致soft fork或者hard fork。因为人们不想在特定的新形式上进行合作。

---

问题：在硬分叉上，发生了什么？

回答：你有两个不同的区块链，客户端必须选择他们想要跟随哪个分支fork。或者在两个都发布他们的交易，我不太清楚。

**追问：假如我有几个比特币，我会在两个分叉都拥有这几个比特币。我可以开始花费它们....**

**回答：好的，你有那些前缀的比特币，所以两个分叉都有前缀，所以你不能重复花钱...(后续另一个人回答)当比特币有一个硬分叉，其中一个新的分叉被称为比特币现金(Bitcoin cash)，所有代币都是在代币的价值内复制的，你没有使自己的价值翻倍。而比特币所减少的价值，其减少的差额正是比特币现金(Bitcoin cash)的价值。所以可以把它想象成股票拆分，你得到了更多的代币，但实际价值保持不变，因为增加了代币的供应。**

## 19.11 小结

+ 分布式共识(distribute consensus with byzantine participants)

  具有潜在拜占庭参与者的开放分布式系统中，达成共识。

+ 公开的账单(public ledger)

  在公开帐本或公开日志上，允许人们检查每个公钥的余额，并避免重复花费。

+ 工作量证明(proof-of-work, PoW)

  确定了允许谁扩展区块链。

---

问题：能不能多谈一点关于权益证明(proof-of-stake, PoS)？

回答：讲师表示自己不是很懂，可以自己google，哈哈。但基本上网络中的power，与网络中的proof-of-stake成正比。基本的想法即如果你拥有所有比特币的10%，你能决定10%的新区块。你会得到激励，更多的权益。

问题：在PoS下，斗争变得更加具有确定性，对吗？

回答：取决于协议细节。在算法方面，有一个周期性的领导者(periodical leader)，还有一个委员会选举(committee election)，然后委员会决定下一个区块是什么。然后有一个新的领导者，新的委员会选举，等等。其中许多方面，可能是固定的和随机的，所以攻击者可能赢得游戏。

问题：为了能够挖掘，你必须拥有日志来验证交易，对吧？

回答：是的。矿工复制了整个日志，GB级别。

问题：GB级别的日志会不会太大？

回答：对于一个合理的计算机来说，完全可以接受。

**问题：一旦一个币中最新的交易放在足够的区块中，它之前花费的交易可以放弃，进而节省磁盘空间。我认知中的区块链，从来不会丢弃交易，它保存着所有交易的完整日志。为什么实践中要怎么做。**

**回答：因为为了节省空间。允许矿工节点上的空间压缩。所以，他们（矿工）不必跟踪日志中每一笔交易、每一个比特币。他们必须跟踪最后一个。一种考虑方式是，你可以按照时间计算出所有点所有值的快照，然后你就不需要记住所有过去（的交易记录）了。**

**追问：那谁会保留完整的历史交易记录呢？**

**回答：一个是，当你检查交易是否有效时，去扫描整个日志。但人们实际不会这么做。而构建一个数据结构没有太大的影响，有每一个没有花掉的硬币的最后一笔交易。你完全可以下载完整的日志，这些完整日志确实有某些节点维护和保存。而其他人可以选择丢弃古早的历史交易记录，他们可以计算出所有的余额，从一开始就运行所有的交易。**

**问题：系统中谁维护整个区块，整个交易。**

**回答：复制到任何地方，每个想得到日志的人。**

**追问：但如果大多数人都选择截断交易（指放弃历史的交易记录日志），为什么有人会选择一直保持？**

**回答：（如果你截断了古早的交易记录日志）这让你可以自行决定交易在过去发生在哪里，但它不允许你验证交易。所以，如果你想要能够验证，你就必须保留过去的交易。**

# Lecture20 Blockstack



