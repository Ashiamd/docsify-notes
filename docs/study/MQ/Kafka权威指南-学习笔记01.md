# Kafka权威指南-学习笔记01

# 1. 初识Kafka

## 1. 1 发布与订阅消息系统

### 1 .1 .1 如何开始

### 1.1.2 独立的队列系统

## 1.2 Kafka 登场

### 1.2.1 消息和批次

+ Kafka 的数据单元被称为**消息**
+ 为了提高效率，消息被分批次写入Kafka 。**批次**就是一组消息，这些消息属于同一个主题和分区

### 1.2.2 模式

​	对于Kafka 来说，消息不过是晦涩难懂的字节数组，所以有人建议用一些额外的结构来定义消息内容，让它们更易于理解。根据应用程序的需求，消息**模式**（ schema ）有许多可用的选项（JSON、XML、proto、Avro等）。

### * 1.2.3 主题和分区

​	Kafka 的消息通过**主题**进行分类。主题就好比数据库的表，或者文件系统里的文件夹。主题可以被分为若干个**分区**， 一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。<u>要注意，由于一个主题一般包含几个分区，因此**无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序**</u>。

​	图1-5 所示的主题有4个分区，消息被迫加写入<u>每个分区</u>的尾部。Kafka 通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说， 一个主题可以横跨多个服务器，以此来提供比单个服务器更强大的性能。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a4299ce6a~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1- 5：包含多个分区的主题表示

### * 1.2.4 生产者和消费者

​	<u>Kafka 的客户端</u>就是Kafka系统的用户，它们被分为两种基本类型：**生产者**和**消费者**。除此之外，还有其他高级客户端API —— 用于数据集成的Kafka Connect API 和用于流式处理的Kafka Streams 。这些高级客户端API使用生产者和消费者作为内部组件，提供了高级的功能。

+ **生产者**创建消息。在其他发布与订阅系统中，生产者可能被称为<u>发布者</u>或<u>写入者</u>。一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。第3章将详细介绍生产者。

+ **消费者**读取消息。在其他发布与订阅系统中，消费者可能被称为<u>订阅者</u>或<u>读者</u>。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。<u>消费者通过检查消息的偏移盘来区分已经读取过的消息</u>。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时， Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。<u>消费者把每个分区最后读取的消息偏移量保存在Zookeeper 或Kafka 上，如果消费者关闭或重启，它的读取状态不会丢失</u>。

​	消费者是**消费者群组**的一部分，也就是说，会有一个或多个消费者共同读取一个主题。<u>**群组保证每个分区只能被一个消费者使用**</u>。图1-6 所示的群组中，有3 个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。<u>消费者与分区之间的映射通常被称为消费者对分区的所有权关系</u>。

​	**通过这种方式，消费者可以消费包含大量消息的主题。而且，如果一个消费者失效，群组里的其他消费者可以接管失效消费者的工作**。第4章将详细介绍消费者和悄费者群组。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a4233c775~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1-6 ：消费者群组从主题读取消息

### * 1.2.5 broker和集群

​	**一个独立的<u>Kafka 服务器</u>被称为broker**。

+ broker接收来自生产者的消息，**为消息设置偏移量**，并提交消息到磁盘保存。
+ broker为消费者提供服务，对读取<u>分区</u>的请求作出响应，返回已经提交到磁盘上的消息。

​	<u>根据特定的硬件及其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级的消息量</u>。

​	broker 是**集群**的组成部分。<u>每个集群都有一个broker 同时充当了**集群控制器**的角色（自动从集群的活跃成员中选举出来）。**控制器负责管理工作，包括将分区分配给broker 和监控broker**</u>。

​	<u>在集群中， 一个分区从属于一个broker，该broker 被称为分区的**首领**</u>。

​	**一个分区可以分配给多个broker**，这个时候会发生**分区复制**（见图1-7）。**这种复制机制为分区提供了消息冗余，如果有一个broker 失效，其他broker 可以接管领导权。不过，<u>相关的消费者和生产者都要重新连接到新的首领</u>**。第6章将详细介绍集群的操作，包括分区复制。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a43368941~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1-7 ：集群里的分区复制

​	**保留消息**（在一定期限内）是Kafka 的一个重要特性。

​	Kafka broker 默认的消息保留策略是这样的：

+ 要么保留一段时间（比如7 天）
+ 要么保留到消息达到一定大小的字节数（比如1GB ）。当消息数量达到这些上限时，旧消息就会过期井被删除。

​	所以在任何时刻， 可用消息的总量都不会超过配置参数所指定的大小。<u>主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止</u>。

​	例如，用于跟踪用户活动的数据可能需要保留几天，而应用程序的度量指标可能只需要保留几个小时。可以通过配置把主题当作**紧凑型日志**， 只有最后一个带有特定键的消息会被保留下来。这种情况对于变更日志类型的数据来说比较适用，因为人们只关心最后时刻发生的那个变更。

### * 1.2.6 多集群

​	随着Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。

+ 数据类型分离

+ 安全需求隔离

+ 多数据中心（灾难恢复）

​	**如果使用多个数据中心，就需要在它们之间复制消息**。这样，在线应用程序才可以访问到多个站点的用户活动信息。*例如，如果一个用户修改了他们的资料信息，不管从哪个数据中心都应该能看到这些改动。或者多个站点的监控数据可以被聚集到一个部署了分析程序和告警系统的中心位置*。不过， **<u>Kafka的消息复制机制只能在单个集群里进行，不能在多个集群之间进行</u>**。

​	Kafka 提供了一个叫作MirrorMaker 的工具，可以用它来实现集群间的消息复制。<u>MirrorMaker的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连</u>。**消费者从一个集群读取消息，生产者把消息发送到另一个集群上**。

​	![v2-8869847fc733df34a94a54d4d9076ee5_b.jpg](https://img-blog.csdnimg.cn/img_convert/e1e93adef38fa5a0084cb6e0b34d21e7.png)

​	图1-8 ： 多数据中的架构

​	图1-8 展示了一个使用MirrorMaker 的例子，两个“本地”集群的消息被聚集到一个“聚合”集群上，然后将该集群复制到其他数据中心。不过，这种方式在创建复杂的数据管道方面显得有点力不从心。第7章将详细讨论这些案例。

## 1.3 为什么选择Kafka

### 1.3.1 多个生产者

​	<u>Kafka可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题</u>。所以它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。例如， 一个包含了多个微服务的网站，可以为页面视图创建一个单独的主题，所有服务都以相同的消息格式向该主题写入数据。消费者应用程序会获得统一的页面视图，而无需协调来自不同生产者的数据流。

### * 1.3.2 多个消费者

​	<u>除了支持多个生产者外， Kafka 也支持多个消费者从一个单独的消息流上读取数据，而且**消费者之间互不影响**</u>。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。**另外，多个消费者可以组成一个群组，它们共享一个消息流，并<u>保证整个群组对每个给定的消息只处理一次</u>**。

### 1.3. 3 基于磁盘的数据存储

​	Kafka 不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于Kafka 的数据保留特性。消息被提交到磁盘，根据设置的保留规则进行保存。**每个主题可以设置单独的保留规则**，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息，而持久化数据可以保证数据不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。<u>消费者可以被关闭，但消息会继续保留在Kafka 里。消费者可以从上次中断的地方继续处理消息</u>。

### 1.3.4 伸缩性

​	为了能够轻松处理大量数据， Kafka 从一开始就被设计成一个具有灵活伸缩性的系统。用户在开发阶段可以先使用单个broker ，再扩展到包含3个broker 的小型开发集群，然后随着数据量不断增长，部署到生产环境的集群可能包含上百个broker 。<u>对在线集群进行扩展丝毫不影响整体系统的可用性。也就是说， 一个包含多个broker 的集群，即使个别broker失效，仍然可以持续地为客户提供服务</u>。<u>要提高集群的容错能力，需要配置较高的复制系数</u>。第6章将讨论关于复制的更多细节。

### 1.3.5 高性能

​	上面提到的所有特性，让Kafka 成为了一个高性能的**发布与订阅消息**系统。通过横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的消息流。在处理大量数据的同时，它还能保证**亚秒级**的消息延迟。

## 1.4 数据生态系统

​	Kafka 为数据生态系统带来了循环系统，如图1-9 所示。它在基础设施的各个组件之间传递消息，为所有客户端提供一致的接口。<u>当与提供消息模式的系统集成时，生产者和消费者之间不再有紧密的祸合，也**不需要在它们之间建立任何类型的直连**</u>。我们可以根据业务需要添加或移除组件．因为生产者不再关心谁在使用数据，也不关心有多少个消费者。

![v2-90d0e87bef7b3732cfd70a8c78710e95_b.jpg](https://img-blog.csdnimg.cn/img_convert/14b915f52caadd0f56ff37357dbce671.png)

​	圄1-9 ：大数据生态系统

​	使用场景：

1. 活动跟踪

2. 传递消息
3. 度量指标和日志记录
4. 提交日志
5. 流处理

## 1.5 起源故事

​	Kafka 是为了解决Linkedln数据管道问题应运而生的。<u>它的设计目的是提供一个高性能的消息系统，可以处理多种数据类型，并能够实时提供纯净且结构化的用户活动数据和系统度量指标</u>。

### 1.5.1 Linkedln的问题

​	最开始，我们调研了一些现成的开源解决方案，希望能够找到一个系统，可以实时访问数据，并通过横向扩展来处理大量的悄息。我们使用ActiveMQ 创建了一个原型系统，但它当时还无能满足横向扩展的需求。Linkedln 不得不使用这种脆弱的解决方案， 虽然ActiveMQ 有很多触陷会导致broker 暂停服务。客户端的连接因此被阻塞，处理用户请求的能力也受到影响。于是我们最后决定构建自己的基础设施。

### 1.5.2 Kafka 的诞生

​	Linkedln 的开发团队由Jay Kreps 领导。Jay Kreps 是Linkedln 的首席工程师，之前负责分布式键值存储系统Voldemort的开发。初建团队成员还包括Neha Narkhede ，不久之后，Jun Rao 也加入了进来。他们一起着手创建一个消息系统，可以同时满足上述的两种需求，并且可以在未来进行横向扩展。他们的主要目标如下：

+ 使用推送和拉取模型解耦生产者和消费者

+ 为消息传递系统中的消息提供数据持久化，以便支持多个消费者
+ 通过系统优化实现高吞吐量
+ 系统可以随着数据流的增长进行横向扩展

​	最后我们看到的这个发布与订阅消息系统具有典型的消息系统接口，但从存储层来看，它更像是一个日志聚合系统。Kafka 使用Avro作为消息序列化框架，每天高效地处理数十亿级别的度量指标和用户活动跟踪信息。Linkedln已经拥有超过万亿级别的消息使用量（截止到2015 年8 月），而且每天仍然需要处理超过千万亿字节的数据。

### 1.5.3 走向开源

​	2010 年底， Kafka 作为开源项目在GitHub 上发布。2011年7月，因为倍受开源社区的关注，它成为Apache软件基金会的孵化器项目。2012年10 月， Kafka 从孵化器项目毕业。	

### 1.5.4 命名

## 1.6 开始Kafka之旅

## 2. 安装Kafka

## 2.1 要事先行

### 2.1.1 选择操作系统

### 2.1.2 安装Java

​	在安装Zookeeper和Kafka之前，需要先安装Java环境。

### 2.1.3 安装Zookeeper

​	**Kafka 使用Zookeeper 保存集群的元数据信息和消费者信息**。Kafka 发行版自带了Zookeeper ，可以直接从脚本启动，不过安装一个完整版的Zookeeper 也并不费劲。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019112413373216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly94aWFvY2hlbmd4aW55aXpoYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)

图2-1 : Kafka 和Zookeeper

## 2.2 安装Kafka Broker

## 2.3 broker配置

### 2.3.1 常规配置

​	有一些配置选项，在单机安装时可以直接使用默认值，但在部署到其他环境时要格外小心。这些参数是单个服务器最基本的配置，它们中的大部分需要经过修改后才能用在集群里。

1. broker.id

   每个broker 都需要有一个标识符，使用broker.id 来表示。它的默认值是0 ，也可以被设置成其他任意整数。**这个值在整个Kafka 集群里必须是唯一的**。这个值可以任意选定，如果出于维护的需要，可以在服务器节点间交换使用这些ID 。建议把它们设置成与机器名具有相关性的整数，这样在进行维护时，将ID 号映射到机器名就没那么麻烦了。例如，如果机器名包含唯一性的数字（比如hostl . example.com 、host2.example.com），那么用这些数字来设置broker.id 就再好不过了。

2. port

   如果使用配置样本来启动Kafka ，它会监听9092 端口。修改port配置参数可以把它设置成其他任意可用的端口。要注意，如果使用1024以下的端口，需要使用root权限启动Kafka ，不过不建议这么做。

3. Zookeeper.connect

   **用于保存broker元数据的Zookeeper 地址是通过zookeeper.connect 来指定的**。`localhost:2181`表示这个Zookeeper 是运行在本地的2181端口上。该配置参数是用冒号分隔的一组`hostname:port/path`列表，每一部分的含义如下：

   + hostname 是Zookeeper 服务器的机器名或IP 地址

   + port 是Zookeeper 的客户端连接端口

   + /path 是可选的Zookeeper 路径，作为Kafka集群的chroot 环境。如果不指定，默认使用根路径。

   如果指定的chroot路径不存在， broker 会在启动的时候创建它。

   > 为什么使用chroot路径
   >
   > 在Kafka 集群里使用chroot 路径是一种最佳实践。Zookeeper 群组可以共享给其他应用程序，即使还有其他Kafka集群存在， 也不会产生冲突。最好是在配置文件里指定一组Zookeeper服务器，用分号把它们隔开。一旦有一个Zookeeper 服务器岩机， broker可以连接到Zookeeper群组的另一个节点上。

4. log.dirs

   **Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过log.dirs指定的**。它是一组用逗号分隔的本地文件系统路径。<u>如果指定了多个路径，那么broker 会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下</u>。要注意， broker 会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。

5. num.recovery.threads.per.data.dir

   对于如下3种情况， Kafka 会使用可配置的线程池来处理日志片段：

   + 服务器正常启动，用于打开每个分区的日志片段

   + 服务器崩愤后重启，用于检查和截短每个分区的日志片段
   + 服务器正常关闭，用于关闭日志片段

   <u>默认情况下，每个日志目录只使用一个线程</u>。因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程来达到井行操作的目的。特别是对于包含大量分区的服务器来说， 一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。设此参数时需要注意，所配置的数字对应的是log.dirs指定的单个日志目录。也就是说，如果num.recovery.threads.per.data.dir被设为8 ， 井且log.dir指定了3 个路径，那么总共需要24 个线程。

6. auto.create.topics.enable

   默认情况下， Kafka 会在如下几种情形下<u>自动创建主题</u>：

   + 当一个生产者开始往主题写入消息时

   + 当一个消费者开始从主题读取消息时

   + 当任意一个客户端向主题发送元数据请求时。

   很多时候，这些行为都是非预期的。而且，根据Kafka协议，如果一个主题不先被创建，根本无法知道它是否已经存在。如果显式地创建主题， 不管是手动创建还是通过其他配置系统来创建，都可以把auto.create.topics.enable设为false 。

### * 2.3.2 主题的默认配置

​	Kafka 为新创建的主题提供了很多默认配置参数。可以通过管理工具（将在第9 章介绍）为每个主题单独配置一部分参数，比如分区个数和数据保留策略。服务器提供的默认配置可以作为基准，它们适用于大部分主题。

> 使用主题配置覆盖（override)
>
> 之前的Kafka 版本允许主题覆盖服务器的默认配置，包括log.retention.hours.per.topic 、log.retention.bytes.per.topic和log.segment.bytes.per.topic 这几个参数。新版本不再支持这些参数，而且如果要对参数进行覆盖，需要使用管理工具。

1. num.paritions

   num.paritions参数指定了新创建的主题将包含多少个分区。如果启用了主题自动创建功能（该功能默认是启用的），主题分区的个数就是该参数指定的值。该参数的默认值是1。**要注意，我们可以增加主题分区的个数，但不能减少分区的个数**。所以，如果要让一个主题的分区个数少于num.partitions指定的值，需要手动创建该主题（将在第9章讨论）。

   第1章里已经提到， Kafka集群通过分区对主题进行横向扩展，所以当有新的broker 加入集群时，可以通过分区个数来实现集群的负载均衡。当然，这并不是说，在存在多个主题的情况下（它们分布在多个broker上），为了能让分区分布到所有broker上， 主题分区的个数必须要大于broker的个数。不过，<u>拥有大量消息的主题如果要进行负载分散，就需要大量的分区</u>。

   > 如何选定分区数量
   >
   > 为主题选定分区数量并不是一件可有可无的事情，在进行数量选择时，需要考虑如下几个因素。
   >
   > + 主题需要达到多大的吞吐量？例如，是希望每秒钟写入100KB 还是1GB?
   >
   > + 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果你知道消费者将数据写入数据库的速度不会超过每秒50MB ，那么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒50MB 。
   >
   > + 可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。
   >
   > + 每个broker 包含的分区个数、可用的磁盘空间和网络带宽。
   >
   > + <u>如果消息是按照不同的键来写入分区的，那么为已有的主题新增分区就会很困难</u>。
   >
   > + **单个broker 对分区个数是有限制的，因为分区越多，占用的内存越多，完成首领选举需要的时间也越长**。

   很显然，综合考虑以上几个因素，你需要很多分区，但不能太多。**如果你估算出主题的吞吐量和消费者吞吐量，可以用主题吞吐量除以消费者吞吐量算出分区的个数**。也就是说，如果每秒钟要从主题上写入和读取1GB 的数据，并且每个消费者每秒钟可以处理50MB的数据，那么至少需要20个分区。这样就可以让20 个消费者同时读取这些分区，从而达到每秒钟1GB 的吞吐量。

   如果不知道这些信息，那么<u>根据经验，把分区的大小限制在25GB以内可以得到比较理想的效果</u>。

2. log.retention.ms

   **Kafka 通常根据时间来决定数据可以被保留多久。默认使用log.retention.ms参数来配置时间，默认值为168小时，也就是一周**。除此以外，还有其他两个参数log.retention.minutes和log.retention.ms。这3个参数的作用是一样的，都是决定消息多久以后会被删除，不过还是推荐使用log.retention.ms。<u>如果指定了不止一个参数， Kafka会优先使用具有最小值的那个参数。</u>

   > 根据时间保留数据和最后修改时间
   >
   > **根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的**。<u>一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里最后一个消息的时间戳。不过，如果使用管理工具在服务器间移动分区，最后修改时间就不准确了</u>。时间误差可能导致这些分区过多地保留数据。在第9章讨论分区移动时会提到更多这方面的内容。

3. log.retention.bytes

   另一种方式是通过保留的消息字节数来判断消息是否过期。它的值通过参数log.retention.bytes来指定，**作用在每一个分区上**。也就是说，如果有一个包含8个分区的主题，井且log.retention.bytes被设为1GB ，那么这个主题最多可以保留8GB 的数据。所以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。

   > 根据字节大小和时间保留数据
   >
   > **如果同时指定了log.retention.bytes和log.retention.ms（或者另一个时间参数），只要任意一个条件得到满足，消息就会被删除**。例如，假设log.retention.ms设置为86 400 000 （也就是1 天），log.retention.bytes设置为1 000 000 000 （也就是1GB ），如果消息字节总数在不到一天的时间就超过了1GB ，那么<u>多出来的部分就会被删除</u>。相反，如果消息字节总数小于1GB ，那么一天之后这些消息也会被删除，尽管分区的数据总量小于1GB 。

4. log.segment.bytes

   **以上的设置都作用在日志片段上，而不是作用在单个消息上**。当消息到达broker 时，它们被迫加到分区的当前日志片段上。当日志片段大小达到log.segment.bytes指定的上限（默认是1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。<u>如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率</u>。

   如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。例如，如果一个主题每天只接收100MB 的消息，而log.retention.ms使用默认设置，那么需要10天时间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果log.retention.ms被设为604 800 000 （ 也就是1 周），那么日志片段最多需要17 天才会过期。<u>这是因为关闭日志片段需要10 天的时间，而根据配置的过期时间，还需要再保留7 天时间（要等到日志片段里的最后一个消息过期才能被删除）</u> 。

   > 使用时间戳获取偏移量
   >
   > 日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移量时， Kafka 会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小子指定时向戳。然后， Kafka 返回该日志片段（也就是文件名）开头的偏移量。**对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确**。

5. log.segment.ms

   **另一个可以控制日志片段关闭时间的参数是log.segment.ms时，它指定了多长时间之后日志片段会被关闭**。就像log.retention.bytes和log.retention.ms这两个参数一样，log.segment.bytes和log.segment.ms这两个参数之间也不存在互斥问题。日志片段会在大小或时间达到上限时被关闭，就看哪个条件先得到满足。<u>默认情况下，log.segment.ms没有设定值，所以只根据大小来关闭日志片段</u>。

   > 基于时间的日志片段对磁盘性能的影响
   >
   > 在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这种情况，因为broker 在启动之后就开始计算日志片段的过期时间，对于那些数据量小的分区来说，日志片段的关闭操作总是同时发生。

6. message.max.bytes

   **broker 通过设置message.max.bytes参数来限制单个消息的大小，默认值是1 000 000 ，也就是1MB** 。如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到broker 返回的错误信息。<u>跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息大小，也就是说，只要压缩后的消息小于message.max.bytes指定的值，消息的实际大小可以远大于这个值</u>。

   这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响IO吞吐量。

   > 在服务端和客户端之间协调消息大小的配置
   >
   > **消费者客户端设置的fetch.message.max.bytes必须与服务器端设置的消息大小进行协调。<u>如果这个值比message.max.bytes小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。在为集群里的broker 配置fetch.message.max.bytes参数时， 也遵循同样的原则</u>。**

## 2.4 硬件的选择

​	如果比较关注性能，那么就需要考虑几个会影响整体性能的因素：磁盘吞吐量和容量、内存、网络和CPU。

### * 2.4.1 磁盘吞吐量

​	**生产者客户端的性能直接受到服务器端磁盘吞吐量的影响**。<u>生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认悄息已经成功提交为止</u>。也就是说，**磁盘写入速度越快，生成消息的延迟就越低**。

> 在考虑硬盘类型对磁盘吞吐量的影响时，是选择传统的机械硬盘（HDD）还是固态硬盘(SSD），我们可以很容易地作出决定。固态硬盘的查找和访问速度都很快，提供了最好的性能。机械硬盘更便宜， 单块硬盘容量也更大。在同一个服务器上使用多个机械硬盘，可以设置多个数据目录，或者把它们设置成磁盘阵列，这样可以提升机械硬盘的性能。其他方面的因素，比如磁盘特定的技术（串行连接存储技术或SATA ），或者磁盘控制器的质量， 都会影响吞吐量。	

### 2.4.2 磁盘容量

​	磁盘容量是另一个值得讨论的话题。需要多大的磁盘容量取决于需要保留的消息数量。如果服务器每天会收到1TB 消息，并且保留7天，那么就需要7TB 的存储空间，而且还要为其他文件提供至少10%的额外空间。除此之外，还需要提供缓冲区，用于应付消息流量的增长和波动。

​	在决定扩展Kafka集群规模时，存储容量是一个需要考虑的因素。**通过让主题拥有多个分区， 集群的总流量可以被均衡到整个集群，而且如果单个broker无法支撑全部容量，可以让其他broker提供可用的容量**。<u>存储容量的选择同时受到集群复制策略的影响</u>（将在第6章讨论更多的细节） 。

### * 2.4.3 内存

​	除了磁盘性能外，服务器端可用的内存容量是影响客户端性能的主要因素。**磁盘性能影响生产者，而内存影响消费者**。<u>消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。在这种情况下，消费者读取的消息会直接存放在系统的页面缓存里，这比从磁盘上重新读取要快得多</u>。

​	<u>运行Kafka 的JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，或者用来缓存正在使用中的日志片段</u>。这也就是为什么不建议把Kafka 同其他重要的应用程序部署在一起的原因，它们需要共享页面缓存，最终会降低Kafka 消费者的性能。

 ### * 2.4.4 网络

​	**网络吞吐量决定了Kafka 能够处理的最大数据流量**。它和磁盘存储是制约Kafka扩展规模的主要因素。Kafka支持多个消费者，造成流入和流出的网络流量不平衡，从而让情况变得更加复杂。对于给定的主题， 一个生产者可能每秒钟写入1MB 数据，但可能同时有多个消费者瓜分网络流量。其他的操作，如集群复制（在第6章介绍）和镜像（在第8章介绍）也会占用网络流量。<u>如果网络接口出现饱和，那么集群的复制出现延时就在所难免，从而让集群不堪一击</u>。

### 2.4.5 CPU

​	与磁盘和内存相比， **Kafka 对计算处理能力的要求相对较低**，不过它在一定程度上还是会影响整体的性能。<u>**客户端为了优化网络和磁盘空间，会对消息进行压缩。服务器需要对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上**。这就是Kafka 对计算处理能力有所要求的地方</u>。不过不管怎样，这都不应该成为选择硬件的主要考虑因素。

## 2.5 云端的Kafka

## 2.6 Kafka集群

​	单个Kafka 服务器足以满足本地开发或POC 要求，不过集群也有它的强大之处。**使用集群最大的好处是可以跨服务器进行负载均衡，再则就是可以<u>使用复制功能来避免因单点故障造成的数据丢失</u>**。在维护Kafka 或底层系统时，使用集群可以确保为客户端提供高可用性。本节只是介绍如何配置Kafka 集群，第6章将介绍更多关于数据复制的内容。

![img](http://www.ituring.com.cn/figures/2017/Kafka/013.png)

### * 2.6.1 需要多少个broker

​	一个Kafka 集群需要多少个broker 取决于以下几个因素。首先，需要多少<u>磁盘空间</u>来保留数据，以及单个broker 有多少空间可用。如果整个集群需要保留10TB 的数据， 每个broker 可以存储2TB ，那么至少需要5个broker 。如果启用了数据复制，那么至少还需要一倍的空间，不过这要取决于配置的复制系数是多少（将在第6 章介绍）。也就是说，如果启用了数据复制，那么这个集群至少需要10 个broker 。

​	第二个要考虑的因素是集群处理请求的能力。这通常与<u>网络接口处理客户端流量的能力</u>有关，特别是当有多个消费者存在或者在数据保留期间流量发生波动（比如高峰时段的流量爆发）时。如果单个broker的网络接口在高峰时段可以达到80%的使用量，并且有两个消费者，那么消费者就无法保持峰值，除非有两个broker 。如果集群启用了复制功能，则要把这个额外的消费者考虑在内。<u>因磁盘吞吐量低和系统内存不足造成的性能问题，也可以通过扩展多个broker来解决</u>。

### 2.6.2 broker配置

​	要把一个broker 加入到集群里，只需要修改两个配置参数。

​	首先，所有broker 都必须配置相同的zookeeper.connect， 该参数指定了用于保存元数据的Zookeeper群组和路径。

​	其次，每个broker 都必须为broker.id参数设置唯一的值。<u>如果两个broker 使用相同的broker.id，那么第二个broker 就无法启动</u>。在运行集群时，还可以配置其他一些参数，特别是那些用于控制数据复制的参数，这些将在后续的章节介绍。

### 2.6.3 操作系统调优

​	大部分Linux发行版默认的内核调优参数配置已经能够满足大多数应用程序的运行需求，不过还是可以通过调整一些参数来进一步提升Kafka的性能。这些参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。这些参数一般配置在`/etc/sysctl.conf`文件里，不过在对内核参数进行调整时，最好参考操作系统的文挡。

1. 虚拟内存

   一般来说， Linux 的虚拟内存会根据系统的工作负荷进行自动调整。我们可以对交换分区的处理方式和内存脏页进行调整，从而让Kafka 更好地处理工作负载。

   **对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换**。内存页和磁盘之间的交换对Kafka 各方面的性能都有重大影响。Kafka大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，说明已经没有多余内存可以分配给页面缓存了。

   <u>一种避免内存交换的方告是不设置任何交换分区。内存交换不是必需的，不过它确实能够在系统发生灾难性错误时提供一些帮助</u>。进行内存交换可以防止操作系统由于内存不足而突然终止进程。基于上述原因，建议把vm.swappiness参数的值设置得小一点，比如1。该参数指明了虚拟机的子系统将如何使用交换分区，而不是只把内存页从页面缓存里移除。要优先考虑减小页面缓存，而不是进行内存交换。

   > 为什么不把vm.swappiness设为零
   >
   > 先前，人们建议尽量把vm.swappiness设为0 ，它意味着“除非发生内存溢出，否则不要进行内存交换”。直到Linux 内核3.5-rc1版本发布，这个值的意义才发生了变化。这个变化被移植到其他的发行版上，包括Red Hat 企业版内核2.6.32-303。在发生变化之后， 0 意味着“在任何情况下都不要发生交换”。所以现在建议把这个值设为1。

   脏页会被冲刷到磁盘上，调整内核对脏页的处理方式可以让我们从中获益。Kafka 依赖I/O性能为生产者提供快速的响应。这就是为什么日志片段一般要保存在快速磁盘上，不管是单个快速磁盘（如SSD）还是具有NVRAM 缓存的磁盘子系统（如RAID）。这样一来，在后台刷新进程将脏页写入磁盘之前，可以减少脏页的数量，这个可以通过将ratio设为小于10 的值来实现。该值指的是系统内存的百分比，大部分情况下设为5 就可以了。它不应该被设为0 ，因为那样会促使内核频繁地刷新页面，从而降低内核为底层设备的磁盘写入提供缓冲的能力。

   通过设置vm.dirty_ratio参数可以增加被内核进程刷新到磁盘之前的脏页数量，可以将它设为大于20 的值（这也是系统内存的百分比）。这个值可设置的范围很广， 60～80 是个比较合理的区间。不过调整这个参数会带来一些风险，包括未刷新磁盘操作的数量和同步刷新引起的长时间I/O等待。<u>如果该参数设置了较高的值，建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失</u>。

   为了给这些参数设置合适的值，最好是在Kafka 集群运行期间检查脏页的数量，不管是在生存环境还是模拟环境。可以在`/proc/vmstat`文件里查看当前脏页数量。

   ```shell
   # cat /proc/vmstat | egrep "dirty|writeback"
   nr_dirty 3875
   nr_writeback 29
   nr_writeback_temp 0
   ```

2. 磁盘

   除了选择合适的磁盘硬件设备和使用RAID外，文件系统是影响性能的另一个重要因素。有很多种文件系统可供选择，不过对于本地文件系统来说，EXT4（第四代可扩展文件系统）和XFS 最为常见。近来，XFS成为很多Linux发行版默认的文件系统，因为它只需要做少量调优就可以承担大部分的工作负荷，比EXT4具有更好的表现。EXT4 也可以做得很好，但需要做更多的调优，存在较大的风险。其中就包括设置更长的提交间隔（默认是5 ），以便降低刷新的频率。<u>EXT4还引入了块分配延迟， 一旦系统崩愤，更容易造成数据丢失和文件系统毁坏。XFS也使用了分配延迟算撞，不过比EXT4的要安全些。XFS为Kafka 提供了更好的性能，除了由文件系统提供的自动调优之外，无需额外的调优。批量磁盘写入具有更高的效率，可以提升整体的I/O吞吐量</u>。

   不管使用哪一种文件系统来存储日志片段，最好要对挂载点的noatime参数进行合理的设置。**<u>文件元数据包含3 个时间戳： 创建时间（ctime）、最后修改时间（mtime）以及最后访问时间（atime）</u>**。**默认情况下，每次文件被读取后都会更新atime ，这会导致大量的磁盘写操作，而且atime属性的用处不大，除非某些应用程序想要知道某个文件在最近一次修改后有没有被访问过（这种情况可以使用realtime）**。<u>Kafka用不到该属性，所以完全可以把它禁用掉。为挂载点设置noatime参数可以防止更新atime ，但不会影响ctime和mtime</u>。

3. 网络

   默认情况下，系统内核没有针对快速的大流量网络传输进行优化， 所以对于应用程序来说，一般需要对Linux 系统的网络技进行调优，以实现对大流量的支持。实际上，调整Kafka 的网络配置与调整其他大部分Web服务器和网络应用程序的网络配置是一样的。首先<u>可以对分配给socket读写缓冲区的内存大小作出调整，这样可以显著提升网络的传输性能</u>。socket 读写缓冲区对应的参数分别是`net.core.wmem_default`和`net.core.rmem_default`，合理的值是131 072 （ 也就是128 KB ）。读写缓冲区最大值对应的参数分别是`net.core.wmem_max`和`net.core.rmem_max`，合理的值是2 097 152 （ 也就是2 MB ）。要注意，最大值井不意味着每个socket 一定要有这么大的缓冲空间，只是说在必要的情况下才会达到这个值。

   除了设置socket 外，还需要设置TCP socket 的读写缓冲区，它们的参数分别是`net.ipv4.tcp_wmem`和`net.ipv4 .tcp_rmem`。这些参数的值由3 个整数组成，它们使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于`net.core.wmem_max`和`net.core.rmem_max`指定的大小。例如，“4096 65536 204800。”表示最小值是4KB、默认值是64KB、最大值是2MB 。<u>根据Kafka 服务器接收流量的实际情况，可能需要设置更高的最大值，为网络连接提供更大的缓冲空间</u>。

   还有其他一些有用的网络参数。例如， 把`net.ipv4.tcp_window_scaling`设为1 ，启用TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据可以在服务器端进行缓冲。把`net.ipv4.tcp_max_syn_backlog`设为比默认值1024 更大的值，可以接受更多的井发连接。把`net.core.netdev_max_backlog`设为比默认值1000 更大的值，有助于应对网络流量的爆发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理。

## 2.7 生产环境的注意事项

### 2.7.1 垃圾回收器选项

​	Java7的G1垃圾回收器会自动根据工作负载情况进行自我调节，而且它的停顿时间是恒定的。它可以轻松地处理大块的堆内存，把堆内存分为若干小块的区域，每次停顿时井不会对整个堆空间进行回收。

​	正常情况下， G1 只需要很少的配置就能完成这些工作。以下是G1的两个调整参数。

+ MaxGCPauseMills

  该参数指定每次垃圾回收默认的停顿时间。该值不是固定的， G1可以根据需要使用更长的时间。它的默认值是200ms 。也就是说， <u>G1会决定垃圾回收的频率以及每一轮需要回收多少个区域，这样算下来， 每一轮垃圾回收大概需要200ms 的时间</u>。

+ InitiatingHeapOccupancyPercent

  该参数指定了在G1启动新一轮垃坡回收之前可以使用的堆内存百分比，默认值是45 。也就是况，在堆内存的使用率达到45%之前，G1不会启动垃圾回收。<u>这个百分比包括新生代和老年代的内存</u>。

​	**Kafka 对堆内存的使用率非常高，容易产生垃圾对象，所以可以把这些值设得小一些**。如果一台服务器有 64GB 内存，并且使用 5GB 堆内存来运行 Kafka，那么可以参考以下的配置：`MaxGCPauseMillis` 可以设为 20ms；`InitiatingHeapOccupancyPercent` 可以设为 35，这样可以让垃圾回收比默认的要早一些启动。

​	Kafka 的启动脚本并没有启用 G1 回收器，而是使用了 Parallel New 和 CMS（ Concurrent Mark-Sweep，并发标记和清除）垃圾回收器。不过它可以通过环境变量来修改。本章前面的内容使用 start 命令来修改它：

```shell
# export JAVA_HOME=/usr/java/jdk1.8.0_51
# export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC
-XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35
-XX:+DisableExplicitGC -Djava.awt.headless=true"
# /usr/local/kafka/bin/kafka-server-start.sh -daemon
/usr/local/kafka/config/server.properties
#
```

### 2.7.2 数据中心布局

​	在为broker 增加新的分区时， broker 并无法获知机架的信息。也就是说，两个broker 有可能是在同一个机架上，或者在同一个可用区域里（如果运行在像AWS 这样的的云服务上），所以，在为分区添加副本的时候，这些副本很可能被分配给同一个机架上的broker，它们使用相同的电源和网络连接。如果该机架出了问题，这些分区就会离线，客户端就无挂访问到它们。**更糟糕的是， 如果发生不完整的主节点选举，那么在恢复时就有可能丢失数据（第6 章将介绍更多细节）**。

​	所以，最好把集群的broker 安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。也就是说，部署服务器需要至少两个电源连接（两个不罔的回路）和两个网络交换器（保证可以进行无缝的故障切换）。除了这些以外，最好还要把broker 安放在不同的机架上。因为随着时间的推移，机架也需要进行维护，而这会导致机器离线（比如移动机器或者重新连接电源）。

### * 2.7.3 共享Zookeeper

​	**Kafka 使用 Zookeeper 来保存 broker、主题和分区的元数据信息**。<u>对于一个包含多个节点的 Zookeeper 群组来说，Kafka 集群的这些流量并不算多，那些写操作只是用于构造消费者群组或集群本身。实际上，在很多部署环境里，会让多个 Kafka 集群共享一个 Zookeeper 群组（每个集群使用一个 chroot 路径）</u>。

> Kafka消费者和Zookeeper
>
> 在 Kafka 0.9.0.0 版本之前，除了 broker 之外，消费者也会使用 Zookeeper 来保存一些信息，比如消费者群组的信息、主题信息、消费分区的偏移量（在消费者群组里发生失效转移时会用到）。到了 0.9.0.0 版本，Kafka 引入了一个新的消费者接口，<u>允许 broker 直接维护这些信息</u>。这个新的消费者接口将在第 4 章介绍。

​	不过，消费者和 Zookeeper 之间还是有一个值得注意的地方，**消费者可以选择将偏移量提交到 Zookeeper 或 Kafka，还可以选择提交偏移量的时间间隔**。如果消费者将偏移量提交到 Zookeeper，那么在每个提交时间点上，消费者将会为每一个消费的分区往 Zookeeper 写入一次偏移量。<u>合理的提交间隔是 1 分钟，因为这刚好是消费者群组的某个消费者发生失效时能够读取到重复消息的时间</u>。值得注意的是，这些提交对于 Zookeeper 来说流量不算小，特别是当集群里有多个消费者的时候。<u>如果 Zookeeper 群组无法处理太大的流量，就有必要使用长一点的提交时间间隔</u>。**不过不管怎样，还是建议使用最新版本的 Kafka，让消费者把偏移量提交到 Kafka 服务器上，消除对 Zookeeper 的依赖**。

​	**虽然多个 Kafka 集群可以共享一个 Zookeeper 群组，但如果有可能的话，不建议把 Zookeeper 共享给其他应用程序**。<u>Kafka 对 Zookeeper 的延迟和超时比较敏感，与 Zookeeper 群组之间的一个通信异常就可能导致 Kafka 服务器出现无法预测的行为。这样很容易让多个 broker 同时离线，如果它们与 Zookeeper 之间断开连接，也会导致分区离线</u>。这也会给集群控制器带来压力，在服务器离线一段时间之后，当控制器尝试关闭一个服务器时，会表现出一些细小的错误。其他的应用程序因重度使用或进行不恰当的操作给 Zookeeper 群组带来压力，所以最好让它们使用自己的 Zookeeper 群组。

## 2.8 总结

​	在这一章，我们学习了如何运行 Kafka，同时也讨论了如何为 Kafka 选择合适的硬件，以及在生产环境中使用 Kafka 需要注意的事项。有了 Kafka 集群之后，接下来要介绍基本的客户端应用程序。后面两章将介绍如何创建客户端，并用它们向 Kafka 生产消息（第 3 章）以及从 Kafka 读取这些消息（第 4 章）。

# 3. Kafka生产者——向Kafka写入数据

​	不管是把Kafka作为消息队列、消息总线还是数据存储平台来使用，总是需要有一个可以往Kafka 写入数据的生产者和一个可以从Kafka 读取数据的消费者，或者一个<u>兼具两种角色</u>的应用程序。

> 第三方客户端
>
> **除了内置的客户端外， Kafka 还提供了二进制连接协议， 也就是说，我们直接向Kafka网络端口发送适当的字节序列，就可以实现从Kafka 读取消息或往Kafka写入消息**。还有很多用其他语言实现的Kafka客户端，比如C++、Python、Go语言等，它们都实现了Kafka的连接协议，使得Kafka 不仅仅局限于在Java 里使用。这些客户端不属于Kafka 项目，不过Kafka 项目wiki上提供了一个清单，列出了所有可用的客户端。连接协议和第三方客户端超出了本章的讨论范围。

## * 3.1 生产者概览

​	多样的使用场景意味着多样的需求：是否每个消息都很重要？是否允许丢失一小部分消息？偶尔出现重复消息是否可以接受？是否有严格的延迟和吞吐量要求？

​	在之前提到的信用卡事务处理系统里，消息丢失或消息重复是不允许的，可以接受的延迟最大为500ms ，对吞吐量要求较高——我们希望每秒钟可以处理一百万个消息。

​	保存网站的点击信息是另一种使用场景。在这个场景里，允许丢失少量的消息或出现少量的消息重复，延迟可以高一些，只要不影响用户体验就行。换句话说，只要用户点击链接后可以马上加载页面，那么我们并不介意消息要在几秒钟之后才能到达Kafka服务器。吞吐量则取决于网站用户使用网站的频度。

​	不同的使用场景对生产者API 的使用和配置会有直接的影响。

​	尽管生产者API使用起来很简单， 但消息的发送过程还是有点复杂的。图3-1 展示了向Kafka 发送消息的主要步骤。

![img](https://upload-images.jianshu.io/upload_images/8365118-e4a8a315ce0b61bb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1128/format/webp)

​	图3-1：Kafka 生产者组件图

​	我们从创建一个ProducerRecord对象开始，ProducerRecord对象需要包含目标主题和要发送的内容。我们还可以指定键或分区。在发送 ProducerRecord 对象时，<u>生产者要先把键和值对象序列化成字节数组，这样它们才能够在网络上传输</u>。

​	接下来，数据被传给分区器。<u>如果之前在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回</u>。如果没有指定分区，那么分区器会根据ProducerRecord 对象的键来选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条记录了。紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。<u>有一个独立的线程负责把这些记录批次发送到相应的broker上</u>。
​	服务器在收到这些消息时会返回一个响应。**如果消息成功写入 Kafka，就返回一个RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量**。<u>如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息</u>。

## * 3.2 创建Kafka生产者

​	要往 Kafka 写入消息，首先要创建一个生产者对象，并设置一些属性。Kafka 生产者有 3个必选的属性。

+ bootstrap.servers

  该属性指定 broker 的地址清单，地址的格式为 host:port 。<u>清单里不需要包含所有的broker 地址，生产者会从给定的 broker 里查找到其他 broker 的信息</u>。**不过建议至少要提供两个 broker 的信息，一旦其中一个宕机，生产者仍然能够连接到集群上**。

+ key.serializer

  **broker 希望接收到的消息的键和值都是<u>字节数组</u>**。生产者接口允许使用参数化类型，因此可以把 Java 对象作为键和值发送给 broker。这样的代码具有良好的可读性，不过生产者需要知道如何把这些 Java 对象转换成字节数组。 key.serializer 必须被设置为一个实现了`org.apache.kafka.common.serialization.Serializer` 接口的类，生产者会使用这个类把键对象序列化成字节数组。Kafka 客户端默认提供了ByteArraySerializer（这个只做很少的事情）、 StringSerializer 和 IntegerSerializer ，因此，如果你只使用常见的几种 Java 对象类型，那么就没必要实现自己的序列化器。**要注意， key.serializer 是必须设置的，就算你打算只发送值内容**。

+ value.serializer

  与 key.serializer 一样， value.serializer 指定的类会将值序列化。如果键和值都是字符串，可以使用与 key.serializer 一样的序列化器。如果键是整数类型而值是字符串，那么需要使用不同的序列化器。

​	下面的代码片段演示了如何创建一个新的生产者，这里只指定了必要的属性，其他使用默认设置。

```java
private Properties kafkaProps = new Properties(); // ➊
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer"); // ➋
kafkaProps.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
producer = new KafkaProducer<String, String>(kafkaProps); // ➌
```

➊ 新建一个 Properties 对象。

➋ 因为我们打算把键和值定义成字符串类型，所以使用内置的 StringSerializer 。

➌ 在这里我们创建了一个新的生产者对象，并为键和值设置了恰当的类型，然后把Properties对象传给它。

​	这个接口很简单，通过配置生产者的不同属性就可以很大程度地控制它的行为。Kafka 的文档涵盖了所有的配置参数，我们将在这一章的后面部分介绍其中几个比较重要的参数。

​	实例化生产者对象后，接下来就可以开始发送消息了。发送消息主要有以下 3 种方式。

+ **发送并忘记（fire-and-forget）**

  我们把消息发送给服务器，但并不关心它是否正常到达。**大多数情况下，消息会正常到达，因为 Kafka 是高可用的**，而且<u>生产者会自动尝试重发</u>。不过，使用这种方式有时候也会丢失一些消息。

+ **同步发送**

  我们使用 send() 方法发送消息，它会返回一个 Future 对象，调用 get() 方法进行等待，就可以知道消息是否发送成功。

+ **异步发送**

  我们调用 send() 方法，并指定一个回调函数，服务器在返回响应时调用该函数。

​	在下面的几个例子中，我们会介绍如何使用上述几种方式来发送消息，以及如何处理可能发生的异常情况。

​	本章的所有例子都使用单线程，但其实<u>生产者是可以使用多线程来发送消息的</u>。刚开始的时候可以使用单个消费者和单个线程。如果需要更高的吞吐量，可以在生产者数量不变的前提下增加线程数量。如果这样做还不够，可以增加生产者数量。

## * 3.3 发送消息到Kafka

​	最简单的消息发送方式如下所示。

```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products","France");// ➊
try {
  producer.send(record);// ➋
} catch (Exception e) {
  e.printStackTrace();// ➌
}
```

➊ 生产者的 send() 方法将 ProducerRecord 对象作为参数，所以我们要先创建一个ProducerRecord 对象。 ProducerRecord 有多个构造函数，稍后我们会详细讨论。这里使用其中一个构造函数，它需要目标主题的名字和要发送的键和值对象，它们都是字符串。**键和值对象的类型必须与序列化器和生产者对象相匹配**。

➋ 我们使用生产者的 send() 方法发送 ProducerRecord 对象。**从生产者的架构图里可以看到，消息先是被放进缓冲区，然后使用单独的线程发送到服务器端**。 send() 方法会返回一个包含 RecordMetadata 的 Future 对象，不过因为我们会忽略返回值，所以无法知道消息是否发送成功。如果不关心发送结果，那么可以使用这种发送方式。比如，记录Twitter 消息日志，或记录不太重要的应用程序日志。

➌ 我们可以忽略发送消息时可能发生的错误或在服务器端可能发生的错误，但在发送消息之前，生产者还是有可能发生其他的异常。<u>这些异常有可能是 SerializationException（说明**序列化消息失败**）、BufferExhaustedException 或 TimeoutException（说明**缓冲区已满**），又或者是 InterruptException（说明**发送线程被中断**）</u>。

### 3.3.1 同步发送消息

最简单的同步发送消息方式如下所示。

```java
ProducerRecord<String, String> record =
  new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
  producer.send(record).get();// ➊
} catch (Exception e) {
  e.printStackTrace();// ➋
}
```

➊ 在这里， producer.send() 方法先返回一个 Future 对象，然后调用 Future 对象的get()方法等待 Kafka 响应。如果服务器返回错误， get() 方法会抛出异常。如果没有发生错误，我们会得到一个 RecordMetadata 对象，可以用它获取消息的偏移量。

➋ 如果在发送数据之前或者在发送过程中发生了任何错误，比如 broker 返回了一个不允许重发消息的异常或者已经超过了重发的次数，那么就会抛出异常。我们只是简单地把异常信息打印出来。

​	KafkaProducer 一般会发生两类错误。<u>其中一类是**可重试错误**，这类错误可以通过重发消息来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可以通过重新为分区选举首领来解决</u>。 KafkaProducer 可以被配置成自动重试，如果在多次重试后仍无法解决问题，应用程序会收到一个重试异常。**另一类错误无法通过重试解决，比如“消息太大”异常。对于这类错误， KafkaProducer 不会进行任何重试，直接抛出异常**。

### * 3.3.2 异步发送消息

​	假设消息在应用程序和 Kafka 集群之间一个来回需要 10ms。如果在发送完每个消息后都等待回应，那么发送 100 个消息需要 1 秒。但如果只发送消息而不等待响应，那么发送100 个消息所需要的时间会少很多。<u>大多数时候，我们并不需要等待响应——尽管 Kafka会把目标主题、分区信息和消息的偏移量发送回来，但对于发送端的应用程序来说不是必需的。不过在遇到消息发送失败时，我们需要抛出异常、记录错误日志，或者把消息写入“错误消息”文件以便日后分析</u>。

​	为了在异步发送消息的同时能够对异常情况进行处理，生产者提供了回调支持。下面是使用回调的一个例子。

```java
private class DemoProducerCallback implements Callback {// ➊
  @Override
  public void onCompletion(RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace();// ➋
    }
  }
}
ProducerRecord<String, String> record =
  new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");// ➌
producer.send(record, new DemoProducerCallback());// ➍

```

➊ 为了使用回调，需要一个实现了 org.apache.kafka.clients.producer.Callback 接口的类，这个接口只有一个 onCompletion 方法。

➋ 如果 Kafka 返回一个错误， onCompletion 方法会抛出一个非空（non null）异常。这里我们只是简单地把它打印出来，但是在生产环境应该有更好的处理方式。

➌ 记录与之前的一样。

➍ 在发送消息时传进去一个回调对象。

## * 3.4 生产者的配置

​	到目前为止，我们只介绍了生产者的几个必要配置参数——bootstrap.servers API 以及序列化器。生产者还有很多可配置的参数，在 Kafka 文档里都有说明，它们大部分都有合理的默认值，所以没有必要去修改它们。不过有几个参数在内存使用、性能和可靠性方面对生产者影响比较大，接下来我们会一一说明。

1. acks

   **<u>acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的</u>**。

   这个参数对消息丢失的可能性有重要影响。该参数有如下选项。

   + 如果 acks=0 ，生产者在成功写入消息之前不会等待任何来自服务器的响应。也就是说，如果当中出现了问题，导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了。不过，<u>因为生产者不需要等待服务器的响应，所以它可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量</u>。
   + 如果 acks=1 ，<u>只要集群的**首领节点**收到消息，生产者就会收到一个来自服务器的成功响应</u>。如果消息无法到达首领节点（比如首领节点崩溃，新的首领还没有被选举出来），生产者会收到一个错误响应，<u>为了避免数据丢失，生产者会重发消息。不过，**如果一个没有收到消息的节点成为新首领，消息还是会丢失**</u>。这个时候的吞吐量取决于使用的是同步发送还是异步发送。如果让发送客户端等待服务器的响应（通过调用 Future 对象的 get() 方法），显然会增加延迟（在网络上传输一个来回的延迟）。如果客户端使用回调，延迟问题就可以得到缓解，不过吞吐量还是会受发送中消息数量的限制（比如，生产者在收到服务器响应之前可以发送多少个消息）。
   + 如果 acks=all ，只有当<u>所有参与复制的节点</u>全部收到消息时，生产者才会收到一个来自服务器的成功响应。**这种模式是最安全的，它可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群仍然可以运行（第 5 章将讨论更多的细节）**。不过，它的延迟比 acks=1 时更高，因为我们要等待不只一个服务器节点接收消息。

2. buffer.memory

   **该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。<u>如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足</u>**。这个时候，send() 方法调用要么被阻塞，要么抛出异常，取决于如何设置 `block.on.buffer.full`参数（在 0.9.0.0 版本里被替换成了 `max.block.ms` ，表示在抛出异常之前可以阻塞一段时间）。

3. **compression.type**

   **默认情况下，消息发送时不会被压缩**。该参数可以设置为 snappy 、 gzip 或 lz4 ，它指定了消息被发送给 broker 之前使用哪一种压缩算法进行压缩。snappy 压缩算法由 Google 发明，它占用较少的 CPU，却能提供较好的性能和相当可观的压缩比，如果比较关注性能和网络带宽，可以使用这种算法。gzip 压缩算法一般会占用较多的 CPU，但会提供更高的压缩比，所以如果网络带宽比较有限，可以使用这种算法。**使用压缩可以降低网络传输开销和存储开销，而这往往是向 Kafka 发送消息的瓶颈所在**。

4. retries

   **生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）**。在这种情况下， retries 参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过`retry.backoff.ms`参数来改变这个时间间隔。<u>建议在设置重试次数和重试时间间隔之前，先测试一下恢复一个崩溃节点需要多少时间（比如所有分区选举出首领需要多长时间），**让总的重试时间比 Kafka 集群从崩溃中恢复的时间长，否则生产者会过早地放弃重试**</u>。

   <u>不过有些错误不是临时性错误，没办法通过重试来解决（比如“消息太大”错误）。一般情况下，因为生产者会自动进行重试，所以就没必要在代码逻辑里处理那些可重试的错误</u>。**你只需要处理那些不可重试的错误或重试次数超出上限的情况**。

5. **batch.size**

   **当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里**。<u>该参数指定了一个批次可以使用的内存大小，**按照字节数计算（而不是消息个数）**</u>。当批次被填满，批次里的所有消息会被发送出去。

   <u>不过生产者并不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。所以就算把批次大小设置得很大，也不会造成延迟，只是会占用更多的内存而已</u>。**但如果设置得太小，因为生产者需要更频繁地发送消息，会增加一些额外的开销**。

6. **linger.ms**

   **该参数指定了生产者在发送批次之前等待更多消息加入批次的时间**。

   <u>KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息</u>。

   把 linger.ms 设置成比 0 大的数，让生产者在发送批次之前等待一会儿，使更多的消息加入到这个批次。虽然这样会增加延迟，但也会提升吞吐量（因为一次性发送更多的消息，每个消息的开销就变小了）。

7. client.id

   该参数可以是任意的字符串，服务器会用它来识别消息的来源，还可以用在日志和配额指标里。

8. max.in.flight.requests.per.connection

   **该参数指定了生产者在收到服务器响应之前可以发送多少个消息**。它的值越高，就会占用越多的内存，不过也会提升吞吐量。**把它设为 1 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试**。

9. timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms

   request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间， metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待响应超时，那么生产者要么重试发送数据，要么返回一个错误（抛出异常或执行回调）。 <u>timeout.ms 指定了 broker 等待**同步副本**返回消息确认的时间，与asks 的配置相匹配——如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误</u>。

10. max.block.ms

    该参数指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。<u>当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞</u>。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。

11. max.request.size

    <u>该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小</u>。例如，假设这个值为 1MB，那么可以发送的单个最大消息为 1MB，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1KB。**另外，broker 对可接收的消息最大值也有自己的限制（ message.max.bytes ），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝**。

12. receive.buffer.bytes 和 send.buffer.bytes

    这两个参数分别指定了 TCP socket 接收和发送数据包的缓冲区大小。<u>如果它们被设为 -1，就使用操作系统的默认值</u>。**如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽**。

> **顺序保证**
>
> **Kafka 可以保证同一个分区里的消息是有序的。也就是说，如果生产者按照一定的顺序发送消息，broker 就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们**。在某些情况下，顺序是非常重要的。例如，往一个账户存入 100 元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。
>
> <u>如果把 retries 设为非零整数，同时把 max.in.flight.requests.per.connection设为比 1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功，broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了</u>。
>
> **一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把 retries 设为 0。可以把 max.in.flight.requests.per.connection 设为 1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给 broker**。<u>不过这样会严重影响生产者的吞吐量，所以只有在对消息的顺序有严格要求的情况下才能这么做</u>。

## 3.5 序列化器

​	我们已经在之前的例子里看到， 创建一个生产者对象必须指定序列化器。我们已经知道如何使用默认的字符串序列化器， Kafka 还提供了整型和字节数组序列化器，不过它们还不足以满足大部分场景的需求。

### 3.5.1 自定义序列化器

​	**我们强烈建议使用通用的序列化框架**。不过，为了了解序列化器的工作原理，也为了说明为什么要使用序列化框架， 让我们一起来看看如何自定义一个序列化器。

​	现有如下客户类：

```java
public class Customer {
    private int customerID;
    private String customerName;

    public Customer(int ID, String name) {
        this.customerID = ID;
        this.customerName = name;
    }

    // getter and setter
}
```

```java
public class CustomerSerializer implements Serializer<Customer> {
  @Override
  public void configure(Map configs, boolean isKey) { 
    //不做任何配置
  }

  /**
   Customer 对象被序列化成：
   表示customerID的4字节整数
   表示customerName长度的4字节整数（如果customerName为空，则长度为0）
   表示customerName的N个字节
   */
  @Override
  public byte[] serialize(String topic, Customer data) {
    try {
      byte[] serializedName;
      int stringSize;
      if(data == null)
        return null;
      else {
        if (data.getName() != null) {
          serialiedName = data.getName().getBytes("UTF-8");
          stringSize = serializedName.length;
        } else {
          serializedName = new byte[0];
          stringSize = 0;
        }
      }
      ByteBuffer buffer = ByteBuffer.allocate(4+4+stringSize);
      buffer.putInt(data.getID());
      buffer.putInt(stringSize);
      buffer.put(serializedName);
    } catch(Exception e) {
      throw new SerializationException("序列化失败: " + e);
    }
  }

  @Override
  public void close() {
    //不需要关闭任何东西
  }
}
```

​	只要使用这个CustomerSerializer， 就可以把消息记录定义成ProducerRecord<String, Customer>，并且可以直接把Customer对象传给生产者。这个例子很简单，不过代码看起来太脆弱了一一如果我们有多种类型的消费者，可能需要把customerID字段变成长整型，或者为Customer添加startDate字段，这样就会出现新旧悄息的兼容性问题。**在不同版本的序列化器和反序列化器之间调试兼容性问题着实是个挑战你需要比较原始的字节数组**。更糟糕的是， 如果同一个公司的不同团队都需要往Kafka 写入Customer 数据，那么他们就需要使用相同的序列化器，如果序列化器发生改动， 他们几乎要在同一时间修改代码。

​	基于以上几点原因，我们不建议使用自定义序列化器，而是使用已有的序列化器和反序列化器， 比如JSON 、Avro 、Thrift或Protobuf 。下面我们将会介绍Avro ，然后演示如何序列化Avro 记录并发送给Kafka。

### 3.5.2 使用Avro 序列化

​	Avro 数据通过与语言无关的schema 来定义。**schema 通过JSON 来描述，数据被序列化成二进制文件或JSON 文件，不过一般会使用二进制文件**。Avro在读写文件时需要用到schema，schema 一般会被内嵌在数据文件里。

​	**Avro 有一个很有意思的特性是，当负责写消息的应用程序使用了新的schema ，负责读消息的应用程序可以继续处理消息而无需做任何改动，这个特性使得它特别适合用在像Kafka 这样的消息系统上**。

```json
{
    "namespace": "customerManagement.avro"，
    "type": "record"，
    "name": "Customer"，
    "fields": [
        {"name":"id","type":"int"},
        {"name":"name","type":"string"},
        {"name":"faxNumber","type": ["null", "string"], "default": "null"}
    ]
}
// id 和name 字段是必需的， faxNumber是可选的，默认为null 。
```

现在 schema 发生了变化，faxNumber 不再使用，而使用 email 字段

```json
{
    "namespace": "customerManagement.avro"，
    "type": "record"，
    "name": "Customer"，
    "fields": [
        {"name":"id","type":"int"},
        {"name":"name","type":"string"},
        {"name":"email","type": ["null", "string"], "default": "null"}
    ]
}
```

​	在应用程序升级之后， `getEmail()` 方法取代了 `getFaxNumber()` 方法。如果碰到一个使用旧 schema 构建的消息，那么 `getEmail()` 方法会返回 null。

​	使用 Avro 的好处：修改了消息的 schema，但并没有更新所有负责读取数据的应用程序，而这样仍然不会出现异常或阻断性错误，也不需要对现有数据进行大幅更新。

不过有以下两个需要注意的地方。

- **用于写入数据和读取数据的 schema 必须是相互兼容的**。Avro 文档提到了一些兼容性原则。
- **反序列化器需要用到用于写入数据的 schema，即使它可能与用于读取数据的 schema 不一样**。Avro 数据文件里就包含了用于写入数据的 schema，不过在 Kafka 里有一种更好的处理方式。

### 3.5.3 在Kafka里使用Avro

​	Avro 的数据文件里包含了整个schema ，不过这样的开销是可接受的。<u>但是如果在每条Kafka 记录里都嵌入schema ，会让记录的大小成倍地增加</u>。不过不管怎样，在读取记录时仍然需要用到整个schema ，所以要先找到schema 。我们遵循通用的结构模式并使用“ schema 注册表”来达到目的。schema注册表并不属于Kafka ，现在已经有一些开糠的schema 注册表实现。在这个例子里，我们使用的是Confluent Schema Registry。该注册表的代码可以在GitHub 上找到，你也可以把它作为Confluent 平台的一部分进行安装。如果你决定使用这个注册表，可以参考它的文档。

​	<u>我们把所有写入数据需要用到的schema 保存在注册表里，然后在记录里引用schema 的标识符。负责读取数据的应用程序使用标识符从注册表里拉取schema 来反序列化记录。序列化器和反序列化器分别负责处理schema的注册和拉取</u>。Avro 序列化器的使用方怯与其他序列化器是一样的。

![img](https://img-blog.csdnimg.cn/img_convert/8d5d56df54516c1d8dce737c052d3c73.png)

​	图3- 2：Avro 记录的序列化相反序列化流程图

> 具体的代码示例可以看原书

## * 3.6 分区

​	在之前的例子里，ProducerRecord 包含了 topic、key 和 value。Kafka 的消息是 一个个键值对，<u>ProducerRecord 可以只包含 topic 和 value，key 可以设置为默认的 null</u>。键有两个用途：可以作为消息的附加信息，也可以用来决定消息该被写到主题的哪个分区。**拥有相同键的消息将被写到同一个分区**。也就是说，如果一个进程只从一个主题的分区读取数据（第4 章会介绍更多细节），那么具有相同键的所有记录都会被该进程读取。

​	**如果键值为null ， 井且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上**。<u>分区器使用轮询（ Round Robin ）算法将消息均衡地分布到各个分区上</u>。

​	**如果键不为空，并且使用了默认的分区器，那么Kafka 会对键进行散列（使用Kafka 自己的散列算法，即使升级Java 版本，散列值也不会发生变化），然后根据散列值把消息映射到特定的分区上**。这<u>里的关键之处在于，**同一个键总是被映射到同一个分区上**，所以在进行映射时，我们会使用主题所有的分区，而不仅仅是可用的分区。这也意味着，如果写入数据的分区是不可用的，那么就会发生错误</u>。但这种情况很少发生。我们将在第6章讨论Kafka 的复制功能和可用性。

​	**只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变**。举个例子，在分区数量保持不变的情况下，可以保证用户045189 的记录总是被写到分区34 。在从分区读取数据肘，可以进行各种优化。不过，<u>一旦主题增加了新的分区，这些就无法保证了—— 旧数据仍然留在分区34 ，但新的记录可能被写到其他分区上</u>。

​	**如果要使用键来映射分区，那么最好在创建主题的时候就把分区规划好（第2 章介绍了如何确定合适的分区数量），而且永远不要增加新分区**。

### 实现自定义分区策略

​	我们已经讨论了默认分区器的特点，它是使用次数最多的分区器。不过，除了散列分区之外，有时候也需要对数据进行不一样的分区。例如有少部分用户的数据量占据数据总量的份额很大，那么可以考虑为这部分用户的数据分配单独的分区，然后对其他用户的数据采用散列分区算法。

> 具体的代码示例，有需要直接看原书即可

## 3.7 旧版的生产者API

​	在这一章，我们讨论了生产者的Java 客户端，它是org.apache.kafka.clients包的一部分。在写到这一章的时候， Kafka 还有两个旧版的Scala客户端，它们是Kafka.producer包的一部分，同时也是Kafka 的核心模块，它们是SyncProducer（根据acks 参数的具体配置情况，在发送更多的消息之前，它会等待服务器对已发消息或批次进行确认）和AsyncProducer （在后台将消息分为不同的批次，使用单独的线程发送这些批次，不为客户端提供发送结果）。

​	因为当前版本的生产者API同时支持上述两种发送方式，而且为开发者提供了更高的可靠性和灵活性，所以我们不再讨论旧版的API 。如果你想使用它们，那么在使用之前请再三考虑，如果确定要使用，可以从Kafka 文档中了解更多的信息。

## 3.8 总结

+ 发送消息到Kafka示例
+ 同步、异步发送
+ 生产者重要配置、参数
+ 序列化器和影响
+ 分区机制

# 4. Kafka消费者一一从Kafka读取数据

​	应用程序使用KafkaConsumer向Kafka 订阅主题，并从订阅的主题上接收消息。

## 4.1 KafkaConsumer概念

​	要想知道如何从Kafka 读取消息，需要先了解消费者和消费者群组的概念。以下章节将解释这些概念。

### * 4.1.1 消费者和消费者群组

​	<u>Kafka生产者产生数据的速度大于Kafka消费者消费速度时，可以考虑横向伸缩，就像多个生产者可以向相同的主题写入消息一样，我们也可以使用多个消费者从同一个主题读取消息，对消息进行分流</u>。

​	**Kafka 消费者从属于消费者群组**。<u>一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息</u>。

​	假设主题T1有4 个分区，我们创建了消费者C1，它是群组G1里唯一的消费者，我们用它订阅主题T1 。消费者C1 将收到主题T1全部4个分区的消息，如图4-1 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019012214094094.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYwMzU2Nw==,size_16,color_FFFFFF,t_70)

​	图片4-1: 1 个消费者收到4个分区的淌患

​	如果在群组 G1 里新增一个消费者 C2 ，那么每个消费者将分别从两个分区接收消息。我们假设消费者 C1 接收分区 0 和分区 2 的消息，消费者 C2 接收分区 1 和分区 3 的消息，如图1-2 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190122141030858.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYwMzU2Nw==,size_16,color_FFFFFF,t_70)

​	图4-2: 2 个消费者收到4 个分区的消息

​	如果群组G1 有4 个消费者，那么每个消费者可以分配到一个分区，如图4-3 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190122141050196.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYwMzU2Nw==,size_16,color_FFFFFF,t_70)

​	图4-3: 4 个消费者收到4 个分区的淌患

​	**如果我们往群组里添加更多的消费者，超过主题的分区数量，那么有一部分消费者就会被闲置，不会接收到任何消息**，如图4-4 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190122141110299.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYwMzU2Nw==,size_16,color_FFFFFF,t_70)

​	图4-4: 5 个消费者收到4 个分区的淌患

​	往群组里增加消费者是横向伸缩消费能力的主要方式。Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或HDFS ，或者使用数据进行比较耗时的计算。在这些情况下，单个消费者无法跟上数据生成的速度，所以可以增加更多的消费者，让它们分担负载，每个消费者只处理部分分区的消息，这就是横向伸缩的主要手段。我们有必要为主题创建大量的分区，在负载增长时可以加入更多的消费者。不过要注意，**<u>不要让消费者的数量超过主题分区的数量，多余的消费者只会被闲置</u>**。第2章介绍了如何为主题选择合适的分区数量。

​	<u>除了通过增加消费者来横向伸缩单个应用程序外，还经常出现多个应用程序从同一个主题读取数据的情况</u>。实际上， Kafka 设计的主要目标之一，就是要让Kafka 主题里的数据能够满足企业各种应用场景的需求。在这些场景里，每个应用程序可以获取到所有的消息，而不只是其中的一部分。**<u>只要保证每个应用程序有自己的消费者群组，就可以让它们获取到主题所有的消息</u>**。**不同于传统的消息系统，横向伸缩Kafka 消费者和消费者群组并不会对性能造成负面影响**。

​	在上面的例子里，如果新增一个只包含一个消费者的群组G2 ，那么这个消费者将从主题T1上接收所有的消息，与群组G1之间互不影响。群组G2 可以增加更多的消费者，每个消费者可以消费若干个分区，就像群组G1那样，如图4-5 所示。总的来说，群组G2 还是会接收到所有消息，不管有没有其他群组存在。

​	**简而言之，为每一个需要获取一个或多个主题全部消息的应用程序创建一个消费者群组，然后往群组里添加消费者来伸缩读取能力和处理能力，群组里的每个消费者只处理一部分消息**。

![kafka：(3) 消费者_应用程序_05](https://s2.51cto.com/images/blog/202110/19170212_616e899459b9250967.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

​	图4-5 ：两个消费者群组对应一个主题

### * 4.1.2 消费者群组和分区再均衡

​	我们已经从上一个小节了解到，群组里的消费者共同读取主题的分区。<u>一个新的消费者加入群组时，它读取的是原本由其他消费者读取的消息。当一个消费者被关闭或发生崩溃时，它就离开群组，原本由它读取的分区将由群组里的其他消费者来读取</u>。在主题发生变化时， 比如管理员添加了新的分区，会发生分区重分配。

​	<u>**分区的所有权**从一个消费者转移到另一个消费者，这样的行为被称为**再均衡**</u>。再均衡非常重要， 它为消费者群组带来了高可用性和伸缩性（我们可以放心地添加或移除消费者），不过在正常情况下，我们并不希望发生这样的行为。**<u>在再均衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用</u>**。**另外，当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序**。我们将在本章讨论如何进行安全的再均衡，以及如何避免不必要的再均衡。

​	<u>消费者通过向被指派为**群组协调器**的broker （**不同的群组可以有不同的协调器**）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系</u>。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。<u>消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳</u>。**如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡**。	

​	<u>如果一个消费者发生崩溃，井停止读取消息，群组协调器会等待几秒钟，确认它死亡了才会触发**再均衡**</u>。在这几秒钟时间里，死掉的消费者不会读取分区里的消息。**在清理消费者时，消费者会通知协调器它将要离开群组，协调器会立即触发一次再均衡，尽量降低处理停顿**。在本章的后续部分，我们将讨论一些用于控制发送心跳频率和会话过期时间的配置参数，以及如何根据实际需要来配置这些参数。

> 心跳行为在最近版本中的变化
>
> 在0.10.1 版本里， Kafka 社区引入了一个<u>独立的心跳线程</u>，<u>可以在轮均消息的空档发送心跳</u>。这样一来，发送心跳的频率（也就是消费者群组用于检测发生崩溃的消费者或不再发送心跳的消费者的时间）与消息轮询的频率（由处理消息所花费的时间未确定）之间就是相互独立的。<u>在新版本的Kafka 里，可以指定消费者在离开群组并触发再均衡之前可以有多长时间不进行消息轮询，这样可以避免出现活锁(livelock）</u> ，比如有时候应用程序并没有崩溃，只是由于某些原因导致无法正常运行。这个配直与session.timeout.ms是相互独立的，后者用于控制检测消费者发生崩溃的时间和停止发送心跳的时间。
>
> 本章的剩余部分将会讨论使用旧版本Kafka 会面临的一些问题，以及如何解决这些问题。本章还包括如何应对需要较长时间来处理消息的情况的讨论，这些与1.10.1或史高版本的Kafka 没有太大关系。<u>如果你使用的是较新版本的Kafka ，并且需要处理耗费较长时间的消息，只需要加大max.poll.interval.ms的值来增加轮均间隔的时长</u>。

#### 分配分区是怎样的一个过程

​	**当消费者要加入群组时，它会向群组协调器发送一个JoinGroup请求。第一个加入群组的消费者将成为“群主”。**群主从<u>协调器</u>那里获得群组的成员列表（列表中包含了所有最近发送过心跳的消费者，它们被认为是活跃的），并负责<u>给每一个消费者分配分区</u>。它使用一个实现了PartitionAssignor接口的类来决定哪些分区应该被分配给哪个消费者。

​	Kafka内置了两种分配策略，在后面的配置参数小节我们将深入讨论。**分配完毕之后，群主把分配情况列表发送给<u>群组协调器</u>，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息。<u>这个过程会在每次再均衡时重复发生</u>**。

## 4.2 创建Kafka 消费者

​	在读取消息之前，需要先创建 一个 KafkaConsumer对象 。 创建 KafkaConsumer 对象与创建 KafkaProducer对象非常相似——把想要传给消费者的属性放在 Properties 对象里。本章 后续部分会深入讨论所有的属性。在这里，我们只需要使用 3个必要的属性: `bootstrap.servers`、`key.deserializer`、 `value.deserializer`。

​	*第1个属性`bootstrap.servers`指定了Kaka集群的连接字符串。它的用途与在KafkaProducer中的用途是一样的，可以参考第3章了解它的详细定义。另外两个属性`key.deserializer`、 `value.deserializer`与生产者的 serializer定义也很类似，不过它们不是使用指定的类把Java对象转成字节数组，而是使用指定的类把字节数组转成Java对象。*

​	第4个属性`group.id`不是必需的，不过我们现在姑且认为它是必需的。它指定了 KafkaConsumer 属于哪一个消费者群组。创建不属于任何一个群组的消费者也是可以的，只是这样做不太常见。

```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9002");
props.put("group.id","CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```

​	如果在第3 章看过如何创建生产者，就应该很熟悉上面的这段代码。我们假设消费的键和值都是字符串类型，所以使用的是内置的StringDeserializer， 井且使用字符串类型创建了KafkaConsumer对象。唯一不同的是新增了group.id属性，它指定了消费者所属群组的名字。

## 4.3 订阅主题

​	创建好消费者之后，下一步可以开始订阅主题了。subscribe()方法接受一个主题列表作为参数，使用起来很简单：

```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```

​	我们也可以在调用subscribe()方法时传入一个正则表达式。<u>正则表达式可以匹配多个主题， 如果有人创建了新的主题，并且主题的名字与正则表达式匹配，那么会立即触发一次**再均衡**，消费者就可以读取新添加的主题</u>。如果应用程序需要读取多个主题，井且可以处理不同类型的数据，那么这种订阅方式就很管用。在Kafka 和其他系统之间复制数据时，使用正则表达式的方式订阅多个主题是很常见的做注。要订阅所有与test 相关的主题，可以这样做：

```java
consumer.subscribe("test.*");
```

## * 4.4 轮询

​	消息轮询是消费者API的核心，通过一个简单的轮询向服务器请求数据。一旦消费者订阅了主题，轮询就会处理所有的细节，包括**群组协调**、**分区再均衡**、**发送心跳**和**获取数据**，开发者只需要使用一组简单的API来处理从分区返回的数据。消费者代码的主要部分如下所示：

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy85MDMzMDg1LTcxNzc3ODAwZjg0ZDU4NDUucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXB8aW1hZ2VWaWV3Mi8yL3cvMTA4Ni9mb3JtYXQvd2VicA?x-oss-process=image/format,png)

​	轮询不只是获取数据那么简单。在第一次调用新消费者的poll()方法时，它会负责查找GroupCoordinator ， 然后加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行的。当然，心跳也是从轮询里发迭出去的。所以，我们要确保在轮询期间所做的任何处理工作都应该尽快完成。

> **线程安全**
>
> **在同一个群组里，我们无法让一个线程运行多个消费者，也无法让多个线程安全地共享一个消费者。**<u>按照规则， 一个消费者使用一个线程。如果要在同一个消费者群组里运行多个消费者，需要让每个消费者运行在自己的线程里</u>。最好是把消费者的逻辑封装在自己的对象里，然后使用Java的ExecutorService启动多个线程，使每个消费者运行在自己的线程上。Confluent的博客（https://www.confluent.io/blog/)上有一个教程介绍如何处理这种情况。

## 4.5 消费者的配置

​	Kafka 的文档列出了所有与消费者相关的配置说明。大部分参数都有合理的默认值，一般不需要修改它们，不过有一些参数与消费者的性能和可用性有很大关系。接下来介绍这些重要的属性。

1. fetch.min.bytes

   **该属性指定了消费者从服务器获取记录的最小字节数**。<u>broker在收到消费者的数据请求时，如果可用的数据量小于fetch.min.bytes指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者</u>。这样可以降低消费者和broker的工作负载，因为它们在主题不是很活跃的时候（或者一天里的低谷时段）就不需要来来回回地处理消息。<u>如果没有很多可用数据，但消费者的CPU使用率却很高，那么就需要把该属性的值设得比默认值大。如果消费者的数量比较多，把该属性的值设置得大一点可以降低broker的工作负载</u>。

2. fetch.max.wait.ms

   我们通过fetch.min.bytes告诉Kafka ，等到有足够的数据时才把它返回给消费者。而fetch.max.wait.ms则用于指定broker的等待时间，默认是500ms 。<u>如果没有足够的数据流入Kafka ，消费者获取最小数据量的要求就得不到满足，最终导致500ms 的延迟</u>。如果要降低潜在的延迟（为了满足SLA ），可以把该参数值设置得小一些。如果fetch.min.bytes被设为100ms ，并且fetch.max.wait.ms被设为1MB ，那么Kafka 在收到消费者的请求后，要么返回1MB 数据，要么在100ms 后返回所有可用的数据， 就看哪个条件先得到满足。

3. **max.partition.fetch.bytes**

   <u>该属性指定了服务器从每个分区里返回给消费者的最大字节数</u>。它的默认值是1MB ， 也就是说， KafkaConsumer.poll()方法从每个分区里返回的记录最多不超过max.partition.fetch.bytes指定的字节。<u>如果一个主题有20个分区和5个消费者，那么每个消费者需要至少4MB 的可用内存来接收记录</u>。

   **在为消费者分配内存时，可以给它们多分配一些，因为如果群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区**。

   **<u>max.partition.fetch.bytes的值必须比broker能够接收的最大消息的字节数（通过max.message.size属性配置）大， 否则消费者可能无法读取这些消息，导致消费者一直挂起重试</u>**。

   <u>在设置该属性时，另一个需要考虑的因素是消费者处理数据的时间。消费者需要频繁调用poll()方法来避免会话过期和发生分区再均衡，如果单次调用poll()返回的数据太多，消费者需要更多的时间来处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况， 可以把max.partition.fetch.bytes值改小，或者延长会话过期时间</u>。

4. session.timeout.ms

   该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是3s 。<u>如果消费者没有在session.timeout.ms指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，把它的分区分配给群组里的其他消费者</u>。

   **该属性与hearbeat.interval.ms紧密相关**。hearbeat.interval.ms指定了poll()方住向协调器发送心跳的频率， session.timeout.ms则指定了消费者可以多久不发送心跳。所以， 一般需要同时修改这两个属性，hearbeat.interval.ms必须比session.timeout.ms小， 一般是session.timeout.ms的三分之一。如果session.timeout.ms是3s ，那么hearbeat.interval.ms应该是1s 。

   <u>把session.timeout.ms 值设得比默认值小，可以更快地检测和恢复崩溃的节点，不过长时间的轮询或垃圾收集可能导致非预期的再均衡。把该属性的值设置得大一些，可以减少意外的再均衡，不过检测节点崩溃需要更长的时间</u>。

5. **auto.offset.reset**

   **该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时井被删除）该作何处理**。

   <u>它的默认值是latest ， 意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）</u>。另一个值是earliest，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。

6. enable.auto.commit

   我们稍后将介绍几种不同的提交偏移量的方式。该属性指定了消费者是否自动提交偏移量，默认值是true。<u>为了尽量避免出现重复数据和数据丢失，可以把它设为false ，由自己控制何时提交偏移量。如果把它设为true ，还可以通过配置auto.commit.interval.ms属性来控制提交的频率</u>。

7. partition.assignment.strategy

   我们知道，分区会被分配给群组里的消费者。PartitionAssignor根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者。Kafka 有两个默认的分配策略。

   + Range

     **该策略会把主题的若干个连续的分区分配给消费者**。假设消费者C1 和消费者C2 同时订阅了主题T1和主题T2 ，井且每个主题有3 个分区。那么消费者C1有可能分配到过两个主题的分区0 和分区1，而消费者C2 分配到这两个主题的分区2。因为每个主题拥有奇数个分区，而**分配是在主题内独立完成的**，第一个消费者最后分配到比第二个消费者更多的分区。<u>只要使用了Range 策略，而且分区数量无法被消费者数量整除，就会出现这种情况</u>。

   + RoundRobin

     **该策略把主题的所有分区逐个分配给消费者**。如果使用 RoundRobin策略来给消费者C1和消费者C2分配分区，那么消费者C1将分到主题T1的分区0和分区2以及主题T2的分区1，消费者C2将分配到主题T1的分区1以及主题T2的分区0和分区2。<u>一般来说，如果所有消费者都订阅相同的主题(这种情况很常见)，RoundRobin策略会给所有消费者分配相同数量的分区(或最多就差一个分区)</u>。

8. client.id

   该属性可以是任意字符串，broker用它来标识从客户端发送过来的消息，通常被用在日志度量指标和配额里。

9. max.poll.records

   该属性用于控制单次调用call()方法能够返回的记录数量，可以帮你控制在轮询里需要处理的数据量。

10. receive.buffer.bytes和send.buffer.bytes

    <u>socket在读写数据时用到的TCP缓冲区也可以设置大小。如果它们被设为-1，就使用操作系统的默认值</u>。**如果生产者或消费者与broker处于不同的数据中心内，可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽**。

## * 4.6 提交和偏移量

​	**每次调用poll() 方法，它总是返回由生产者写入Kafka 但还没有被消费者读取过的记录，我们因此可以追踪到哪些记录是被群组里的哪个消费者读取的**。之前已经讨论过， Kafka不会像其他JMS 队列那样需要得到消费者的确认，这是Kafka 的一个独特之处。相反，<u>消费者可以使用Kafka 来追踪消息在分区里的位置（偏移量）</u>。

​	<u>我们把更新分区当前位置的操作叫作**提交**</u>。

​	**<u>那么消费者是如何提交偏移量的呢？消费者往一个叫作`_consumer_offset`的特殊主题发送消息，消息里包含每个分区的偏移量</u>**。如果消费者一直处于运行状态，那么偏移量就没有什么用处。不过，如果消费者发生崩溃或者有新的消费者加入群组，就会触发再均衡，完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。

​	<u>如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理</u>，如图4-6 所示。

![img](https://img2020.cnblogs.com/blog/1000464/202008/1000464-20200803213742395-1392463710.png)

​	图4-6 ：握交的偏移量小于客户端处理的最后一个消息的偏移量

​	<u>如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失</u>，如图4-7 所示。

![img](https://img2020.cnblogs.com/blog/1000464/202008/1000464-20200803213809177-1975268731.png)

​	图4-7 ：提交的偏移量大于客户端处理的最后一个消息的偏移量

​	所以，处理偏移量的方式对客户端会有很大的影响。KafkaConsumer API提供了很多种方式来提交偏移量。

### * 4.6.1 自动提交

​	**最简单的提交方式是让消费者自动提交偏移量。如果enable.auto.commit被设为true ，那么每过5s，消费者会自动把从poll()方法接收到的最大偏移量提交上去**。提交时间间隔由auto.commit.interval.ms控制，默认值是5s 。与消费者里的其他东西一样，<u>自动提交也是在轮询里进行的</u>。**消费者每次在进行轮询时会检查是否该提交偏移量了，如果是，那么就会提交从上一次轮询返回的偏移量**。

​	不过，在使用这种简便的方式之前，需要知道它将会带来怎样的结果。

​	<u>假设我们仍然使用默认的5s 提交时间间隔，在最近一次提交之后的3s 发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了3s ，所以在这3s 内到达的消息会被**重复处理**</u>。

​	**可以通过修改提交时间间隔来更频繁地提交偏移量，减小可能出现重复消息的时间窗，不过这种情况是无也完全避免的**。

​	<u>在使用自动提交时，每次调用轮询方法都会把上一次调用返回的偏移量提交上去，**它并不知道具体哪些消息已经被处理了**，所以在再次调用之前最好确保所有当前调用返回的消息都已经处理完毕</u>（**<u>在调用close()方法之前也会进行自动提交</u>**）。**一般情况下不会有什么问题，不过在处理异常或提前退出轮询时要格外小心**。

​	自动提交虽然方便， 不过并没有为开发者留有余地来避免重复处理消息。

### * 4.6.2 提交当前偏移量

​	**大部分开发者通过控制偏移量提交时间来消除丢失消息的可能性，井在发生再均衡时减少重复消息的数量**。消费者API提供了另一种提交偏移量的方式， <u>开发者可以在必要的时候提交当前偏移盘，而不是基于时间间隔</u>。

​	把auto.commit.offset 设为false，让应用程序决定何时提交偏移量。使用commitSync()提交偏移量最简单也最可靠。<u>这个API会提交由poll()方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常</u>。

​	要记住，commitSync()将会提交由poll()返回的最新偏移量， 所以**在处理完所有记录后要确保调用了commitSync()，否则还是会有丢失消息的风险**。

​	**如果发生了再均衡，从最近一批消息到发生再均衡之间的所有消息都将被重复处理**。

​	下面是我们在处理完最近一批消息后使用commitSync()方怯提交偏移量的例子。

```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records)
  {
    System.out.printf("topic = %s, partition = %s, offset =
                      %d, customer = %s, country = %s\n",
                      record.topic(), record.partition(),
                      record.offset(), record.key(), record.value()); // 1
  }
  try {
    consumer.commitSync(); // 2
  } catch (CommitFailedException e) {
    log.error("commit failed", e) // 3
  }
}
```

1. 我们假设把记录内容打印出来就算处理完毕，这个是由应用程序根据具体的使用场景来决定的。
2. <u>处理完当前批次的消息，在轮询更多的消息之前， 调用commitSync()方法提交**当前**批次最新的偏移量</u>。
3. **只要没有发生不可恢复的错误，commitSync()方法会一直尝试直至提交成功**。如果提交失败， 我们也只能把异常记录到错误日志里。

### * 4.6.3 异步提交

​	手动提交有一个不足之处，在broker对提交请求作出回应之前，应用程序会一直**阻塞**，这样会限制应用程序的吞吐量。我们可以通过降低提交频率来提升吞吐量，但如果发生了再均衡， 会增加重复消息的数量。

​	这个时候可以使用异步提交API 。我们只管发送提交请求，无需等待broker的响应。

```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records)
  {
    System.out.printf("topic = %s, partition = %s,
                      offset = %d, customer = %s, country = %s\n",
                      record.topic(), record.partition(), record.offset(),
                      record.key(), record.value());
  }
  consumer.commitAsync(); // 1 提交最后一个偏移量，然后继续做其他事情。
}
```

​	**在成功提交或碰到无怯恢复的错误之前，commitSync() 会一直重试，但是commitAsync()不会**，这也是commitAsync()不好的一个地方。**<u>它之所以不进行重试，是因为在它收到服务器响应的时候，可能有一个更大的偏移量已经提交成功</u>**。

​	假设我们发出一个请求用于提交偏移量2000 ，这个时候发生了短暂的通信问题，服务器收不到请求，自然也不会作出任何响应。与此同时，我们处理了另外一批消息，并成功提交了偏移量3000 。如果commitAsync()重新尝试提交偏移量2000 ，它有可能在偏移量3000 之后提交成功。这个时候如果发生再均衡，就会出现重复消息。

​	我们之所以提到这个问题的复杂性和提交顺序的重要性，是因为**commitAsync()也支持回调，在broker作出响应时会执行回调**。<u>回调经常被用于记录提交错误或生成度量指标， 不过如果你要用它来进行重试， 一定要注意提交的顺序</u>。

```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records) {
    System.out.printf("topic = %s, partition = %s,
                      offset = %d, customer = %s, country = %s\n",
                      record.topic(), record.partition(), record.offset(),
                      record.key(), record.value());
  }
  consumer.commitAsync(new OffsetCommitCallback() {
    public void onComplete(Map<TopicPartition,
                           OffsetAndMetadata> offsets, Exception e) {
      if (e != null)
        log.error("Commit failed for offsets {}", offsets, e);
    }
  }); // 1 发送提交请求然后继续做其他事情，如果提交失败，错误信息和偏移量会被记录下来。
}
```

> **重试异步提交**
>
> 我们可以使用一个单调递增的序列号来维护异步提交的顺序。在每次提交偏移量之后或在回调里提交偏移量时递增序列号。在进行重试前，先检查回调的序列号和即将提交的偏移量是否相等，如果相等，说明没有新的提交，那么可以安全地进行重试。如果序列号比较大，说明有一个新的提交已经发送出去了，应该停止重试。

### * 4.6.4 同步和异步组合提交

​	一般情况下，针对偶尔出现的提交失败，不进行重试不会有太大问题，因为如果提交失败是因为临时问题导致的，那么后续的提交总会有成功的<u>。但如果这是发生在关闭消费者或再均衡前的最后一次提交，就要确保能够提交成功</u>。

​	**因此，在消费者关闭前一般会组合使用commitAsync()和commitSync()**。它们的工作原理如下（后面讲到再均衡监听器时，我们会讨论如何在发生再均衡前提交偏移量）：

```java
try {
  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(100);
    for (ConsumerRecord<String, String> record : records) {
      System.out.println("topic = %s, partition = %s, offset = %d,
                         customer = %s, country = %s\n",
                         record.topic(), record.partition(),
                         record.offset(), record.key(), record.value());
    }
    consumer.commitAsync(); // 1. 如果一切正常，我们使用commitAsync()方法来提交。这样速度更快，而且即使这次提交失败，下一次提交很可能会成功。
  }
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  try {
    consumer.commitSync(); // 2. 如果直接关闭消费者，就没有所谓的“下一次提交”了。使用commitSync()方法会一直重试，直到提交成功或发生无法恢复的错误。
  } finally {
    consumer.close();
  }
}
```

### 4.6.5 提交特定的偏移量

​	**提交偏移量的频率与处理消息批次的频率是一样的**。

​	如果poll()方法返回一大批数据，为了避免因再均衡引起的重复处理整批消息，想要在批次中间提交偏移量该怎么办？这种情况无法通过调用commitSync()或commitAsync()来实现，因为它们只会提交最后一个偏移量，而此时该批次里的消息还没有处理完。

​	幸运的是，<u>消费者API允许在调用commitSync()和commitAsync()方法时传进去希望提交的分区和偏移量的map</u> 。假设你处理了半个批次的消息， 最后一个来自主题"customers"分区3 的消息的偏移量是5000 ， 你可以调用commitSync()方法来提交它。<u>不过，因为消费者可能不只读取一个分区， f尔需要跟踪所有分区的偏移量，所以在这个层面上控制偏移量的提交会让代码变复杂</u>。

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets =
  new HashMap<>(); // 1. 用于跟踪偏移量的map
int count = 0;

// ...

while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records)
  {
    System.out.printf("topic = %s, partition = %s, offset = %d,
                      customer = %s, country = %s\n",
                      record.topic(), record.partition(), record.offset(),
                      record.key(), record.value());
    currentOffsets.put(new TopicPartition(record.topic(),
                                          record.partition()), new
                       OffsetAndMetadata(record.offset()+1, "no metadata")); // 2. 在读取每条记录之后，使用期望处理的下一个消息的偏移量更新map里的偏移量。下一次就从这里开始读取消息。
    if (count % 1000 == 0) // 3. 每处理1000条记录就提交一次偏移量。在实际应用中，你可以根据时间或记录的内容进行提交。
      consumer.commitAsync(currentOffsets,null); // 4. 调用commitSync()也是完全可以的。在提交特定偏移量时，仍然要处理可能发生的错误。
    count++;
  }
}
```

## * 4.7 再均衡监听器

​	在提交偏移量一节中提到过，消费者在退出和进行分区再均衡之前，会做一些清理工作。

​	你会在消费者失去对一个分区的所有权之前提交最后一个已处理记录的偏移量。如果消费者准备了一个缓冲区用于处理偶发的事件，那么在失去分区所有权之前， 需要处理在缓冲区累积下来的记录。你可能还需要关闭文件句柄、数据库连接等。

​	在为消费者分配新分区或移除旧分区时，可以通过消费者 API 执行一些应用程序代码，在调用 subscribe() 方法时传进去一个 ConsumerRebalanceListener 实例就可以了。 ConsumerRebalanceListener 有两个需要实现的方法。

1. `public void onPartitionsRevoked(Collection<TopicPartitio> partitions)` 方法会<u>在再均衡开始之前和消费者停止读取消息之后被调用</u>。如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取了。
2. `public void onPartitionsAssigned(Collection<TopicPartitio> partitions)` 方法会<u>在重新分配分区之后和消费者开始读取消息之前</u>被调用。

​	下面的例子将演示如何<u>在失去分区所有权之前通过onPartitionsRevoked()方法来提交偏移量</u>。在下一节，我们会演示另一个同时使用了onPartitionsAssigned()方法的例子。

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets=
  new HashMap<>();

private class HandleRebalance implements ConsumerRebalanceListener { // 1. 首先实现ConsumerRebalanceListener接口
    public void onPartitionsAssigned(Collection<TopicPartition>
      partitions) { // 2. 在获得新分区后开始读取消息，不需要做其他事情
    }

    public void onPartitionsRevoked(Collection<TopicPartition>
      partitions) {
        System.out.println("Lost partitions in rebalance.
          Committing current
        offsets:" + currentOffsets);
        consumer.commitSync(currentOffsets); // 3. 如果发生再均衡，我们要在即将失去分区所有权时提交偏移量。要注意，提交的是最近处理过的偏移量，而不是批次中还在处理的最后一个偏移量。因为分区有可能在我们还在处理消息的时候被撤回。我们要提交所有分区的偏移量，而不只是那些即将失去所有权的分区的偏移量——因为提交的偏移量是已经处理过的，所以不会有什么问题。调用 commitSync() 方法，确保在再均衡发生之前提交偏移量
    }
}

try {
    consumer.subscribe(topics, new HandleRebalance()); // 4. 重要的一步

    while (true) {
        ConsumerRecords<String, String> records =
          consumer.poll(100);
        for (ConsumerRecord<String, String> record : records)
        {
            System.out.println("topic = %s, partition = %s, offset = %d,
             customer = %s, country = %s\n",
             record.topic(), record.partition(), record.offset(),
             record.key(), record.value());
             currentOffsets.put(new TopicPartition(record.topic(),
             record.partition()), new
             OffsetAndMetadata(record.offset()+1, "no metadata"));
        }
        consumer.commitAsync(currentOffsets, null);
    }
} catch (WakeupException e) {
    // 忽略异常，正在关闭消费者
} catch (Exception e) {
    log.error("Unexpected error", e);
} finally {
    try {
        consumer.commitSync(currentOffsets);
    } finally {
        consumer.close();
        System.out.println("Closed consumer and we are done");
    }
}
```

## * 4.8 从特定偏移量处开始处理记录

​	到目前为止，我们知道了如何使用 poll() 方法从各个分区的最新偏移量处开始处理消息。 不过，有时候我们也需要从特定的偏移量处开始读取消息。

​	果你想从分区的起始位置开始读取消息，或者直接跳到分区的末尾开始读取消息，可以使用`seekToBeginning(Collection<TopicPartition> tp)`和`seekToEnd(Collection<TopicPartition> tp)`这两个方法。

​	<u>不过，Kafka也为我们提供了用于查找特定偏移量的 API。 它有很多用途，比如向后回退几个消息或者向前跳过几个消息(对时间比较敏感的应用程序在处理滞后的情况下希望能够向前跳过若干个消息)</u>。在使用 Kafka 以外的系统来存储偏移量时，它将给我们带来更大的惊喜。

​	试想一下这样的场景：应用程序从 Kafka读取事件(可能是网站的用户点击事件流 )，对它们进行处理(可能是使用自动程序清理点击操作井添加会话信息)，然后把结果保存到数据库、 NoSQL 存储引擎或 Hadoop。假设我们真的不想丢失任何数据，也不想在数据库里多次保存相同的结果。

​	这种情况下，消费者的代码可能是这样的 :

```java
while(true) {
  ConsumerRecord<String, String> records = consumer.poll(100);
  for(ConsumerRecord<String, String> record: records) {
    currentOffsets.put(new TopicPartition(record.topic(), record.partition()),
                       new OffsetAndMetadata(record.offset()+1);
                       processRecord(record);
                       storeRecordInDB(record);
                       consumer.commitAsync(currentOffsets);
  }
}
```

​	<u>在这个例子里，每处理一条记录就提交一次偏移量。尽管如此， 在记录被保存到数据库之后以及偏移量被提交之前 ，应用程序仍然有可能发生崩溃，导致重复处理数据，数据库里就会出现重复记录</u>。

​	如果保存记录和偏移量可以在一个原子操作里完成，就可以避免出现上述情况。记录和偏移量要么都被成功提交，要么都不提交。**如果记录是保存在数据库里而偏移量是提交到 Kafka 上，那么就无法实现原子操作**。

​	不过 ，如果在同一个事务里把记录和偏移量都写到数据库里会怎样呢？那么我们就会知道记录和偏移量要么都成功提交，要么都没有，然后重新处理记录。

​	现在的问题是：如果偏移量是保存在数据库里而不是 Kafka里，那么消费者在得到新分区 时怎么知道该从哪里开始读取？这个时候可以使用 seek() 方法。**在消费者启动或分配到新分区时 ，可以使用 seek()方法查找保存在数据库里的偏移量**。

​	下面的例子大致说明了如何使用这个 API。 使用 ConsumerRebalancelistener和 seek() 方法确保我们是从数据库里保存的偏移量所指定的位置开始处理消息的。

![img](https://cdnimg.copyfuture.com/imagesLocal/201906/06/2019060608364159144uls65hbjmzgvl_10.png)

![img](https://cdnimg.copyfuture.com/imagesLocal/201906/06/2019060608364159144uls65hbjmzgvl_7.png)

​	**通过把偏移量和记录保存到同一个外部系统来实现单次语义可以有很多种方式，不过它们都需要结合使用 ConsumerRebalancelistener和 seek() 方法来确保能够及时保存偏移量， 井保证消费者总是能够从正确的位置开始读取消息**。

## 4.9 如何退出

​	在之前讨论轮询时就说过，不需要担心消费者会在一个无限循环里轮询消息，我们会告诉消费者如何优雅地退出循环。

​	如果确定要退出循环，需要通过另一个线程调用consumer.wakeup()方法。如果循环运行在主线程里，可以在ShutdownHook 里调用该方法。要记住，**consumer.wakeup()是消费者唯一一个可以从其他线程里安全调用的方法**。调用consumer.wakeup()可以退出poll()，并抛出WakeupException 异常，或者如果调用consumer.wakeup()时线程没有等待轮询， 那么异常将在下一轮调用poll()时抛出。我们不需要处理WakeupException，因为它只是用于跳出循环的一种方式。不过， 在退出线程之前调用consumer.close()是很有必要的， 它会提交任何还没有提交的东西， 并向群组协调器发送消息，告知自己要离开群组，接下来就会触发再均衡，而不需要等待会话超时。

## 4.10 反序列化器

​	在之前的章节里提到过，生产者需要用**序列化器**把对象转换成字节数组再发送给Kafka。类似地，消费者需要用**反序列化器**把从Kafka 接收到的字节数组转换成Java对象。在前面的例子里，我们假设每个消息的键值对都是字符串，所以我们使用了默认的String.Deserializer。

## 4.11 独立消费者一一为什么以及怎样使用没有群组的消费者

​	到目前为止， 我们讨论了消费者群组， 分区被自动分配给群组里的消费者， 在群组里新增或移除消费者时自动触发再均衡。通常情况下，这些行为刚好是你所需要的，不过有时候你需要一些更简单的东西。比如，你可能只需要一个消费者从一个主题的所有分区或者个特定的分区读取数据。这个时候就不需要消费者群组和再均衡了， 只需要把主题或者分区分配给消费者，然后开始读取消息井提交偏移量。

​	如果是这样的话，就不需要订阅主题， 取而代之的是为自己分配分区。<u>一个消费者可以订阅主题（井加入消费者群组），或者为自己分配分区， 但不能同时做这两件事情</u>。

​	下面的例子演示了一个消费者是如何为自己分配分区并从分区里读取消息的：

![img](https://bbsmax.ikafan.com/static/L3Byb3h5L2h0dHBzL2ltZzIwMTguY25ibG9ncy5jb20vYmxvZy82ODczMDAvMjAxODA5LzY4NzMwMC0yMDE4MDkyNzIwMTgyODUzMS0yMTIwNzIxMjQwLnBuZw==.jpg)

​	除了不会发生再均衡，也不需要手动查找分区， 其他的看起来一切正常。<u>不过要记住，如果主题增加了新的分区，消费者并不会收到通知。所以，要么周期性地调用consumer.partitionsFor()方法来检查是否有新分区加入， 要么在添加新分区后重启应用程序</u>。

## 4.12 旧版的消费者API

​	我们在这一章讨论的Java KafkaConsumer客户端是org.apache.kafka.cllents包的一部分。在本书写到这一章的时候， Kafka 还有两个旧版本的Scala 消费者客户端， 它们是kafka.consumer包的一部分，属于Kafka 核心模块。它们分别被叫作SimpleConsumer简单消费者， 实际上也不是那么简单，它们是对Kafka API 的轻度包装，可以用于从特定的分区和偏移量开始读取消息）和高级消费者。高级消费者指的就是ZookeeperConsumerConnect，它有点像现在的消费者，有消费者群组，有分区再均衡，不过它使用Zookeeper 来管理消费者群组，并不具备提交偏移量和再均衡的可操控性。

​	因为现在的消费者同时支持以上两种行为，井且为开发人员提供了更高的可靠性和可操控性，所以我们不打算讨论旧版API 。如果你想使用它们，那么请三思，如果确定要使用，可以从Kafka 文档中了解更多的信息。

## 4.13 总结

+ Kafka消费群组
+ 消费者分区再均衡
+ 消费者配置
+ 消费者管理偏移量
+ 消费者API

# 5. 深入Kafka

​	了解Kafka 的内部工作原理有助于理解Kafka 的行为，也有助于诊断问题。本章井不会涵盖Kafka 的每一个设计和实现细节，而是集中讨论以下3 个有意思的话题：

+ **Kafka 如何进行复制**

+ **Kafka 如何处理来自生产者和消费者的请求**

+ **Kafka 的存储细节，比如文件格式和索引**

​	在对Kafka 进行调优时，深入理解这些问题是很有必要的。了解了内部机制，可以更有目的性地进行深入的调优，而不只是停留在表面，隔靴搔痒。

## * 5.1 集群成员关系

​	Kafka使用Zookeeper来维护集群成员的信息。每个broker都有一个唯一标识符，这个标识符可以在配置文件里指定，也可以自动生成。<u>在broker启动的时候，它通过创建**临时节点**把自己的ID注册到Zookeeper。Kafka组件订阅Zookeeper的`/brokers/ids`路径(broker在Zookeeper上的注册路径），当有broker加入集群或退出集群时，这些组件就可以获得通知</u>。

​	<u>如果你要启动另一个具有相同ID的broker，会得到一个错误一一新broker会试着进行注册，但不会成功，因为Zookeeper里已经有一个具有相同ID的broker</u>。

​	**在broker停机、出现网络分区或长时间垃圾回收停顿时， broker会从Zookeeper上断开连接，此时broker 在启动时创建的临时节点会自动从Zookeeper上移除。监听broker列表的Kafka组件会被告知该broker已移除**。

​	<u>**在关闭broker时，它对应的节点也会消失，不过它的ID会继续存在于其他数据结构中**</u>。<u>例如，主题的副本列表（下面会介绍）里就可能包含这些ID</u>。**在完全关闭一个broker之后，如果使用相同的ID启动另一个全新的broker，它会立即加入集群，井拥有与旧broker相同的分区和主题**。

## * 5.2 控制器

​	**控制器其实就是一个broker ，只不过它除了具有一般broker的功能之外，还负责分区首领的选举（我们将在5.3 节讨论分区首领选举）**。

​	<u>**集群里第一个启动的broker通过在Zookeeper里创建一个临时节点`/controller`让自己成为控制器**。其他broker在启动时也会尝试创建这个节点，不过它们会收到一个"节点已存在"的异常，然后“意识”到控制器节点已存在，也就是说集群里已经有一个控制器了。其他broker在控制器节点上创建Zookeeper watch对象，这样它们就可以收到这个节点的变更通知。这种方式可以确保集群里一次只有一个控制器存在</u>。

​	**如果控制器被关闭或者与Zookeeper 断开连接， Zookeeper 上的临时节点就会消失**。<u>集群里的其他broker 通过watch 对象得到控制器节点消失的通知，它们会尝试让自己成为新的控制器。第一个在Zookeeper 里成功创建控制器节点的broker 就会成为新的控制器，其他节点会收到“节点已存在”的异常，然后在新的控制器节点上再次创建watch 对象</u>。**每个新选出的控制器通过Zookeeper 的条件递增操作获得一个全新的、<u>数值更大</u>的controller epoch**。**其他broker在知道当前controller epoch后，如果收到由控制器发出的包含较旧epoch的消息，就会忽略它们**。

​	**当控制器发现一个broker已经离开集群（通过观察相关的Zookeeper 路径），它就知道，那些失去首领的分区需要一个新首领（这些分区的首领刚好是在这个broker 上）**。<u>控制器遍历这些分区，并确定谁应该成为新首领（简单来说就是分区副本列表里的下一个副本），然后向所有包含新首领或现有跟随者的broker发送请求。该请求消息包含了谁是新首领以及谁是分区跟随者的信息。随后，新首领开始处理来自生产者和消费者的请求，而跟随者开始从新首领那里复制消息</u>。

​	**当控制器发现一个broker加入集群时，它会使用broker ID来检查新加入的broker是否包含现有分区的副本。如果有，控制器就把变更通知发送给新加入的broker和其他broker，新broker上的副本开始从首领那里复制消息**。

​	简而言之， 

+ Kafka使用Zookeeper的临时节点来选举控制器， 并**在节点加入集群或退出<u>集群</u>时通知控制器**。
+ **控制器负责在节点加入或离开<u>集群</u>时进行分区首领选举**。
+ **控制器使用epoch来避免“脑裂”** 。“脑裂”是指两个节点同时认为自己是当前的控制器。

## * 5.3 复制

​	复制功能是Kafka架构的核心。在Kafka的文档里， Kafka把自己描述成“一个分布式的、可分区的、可复制的提交日志服务”。**复制之所以这么关键，是因为它可以在个别节点失效时仍能保证Kafka的可用性和持久性**。

​	**Kafka使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本**。那些副本被保存在broker上，每个broker可以保存成百上千个属于不同主题和分区的副本。

​	副本有以下两种类型。

+ **首领副本**

  **每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本**。

+ **跟随者副本**

  首领以外的副本都是跟随者副本。**跟随者副本不处理来自客户端的请求**，<u>它们唯一的任务就是从首领那里复制消息，保持与首领一致的状态</u>。**如果首领发生崩溃，其中的一个跟随者会被提升为新首领**。

​	<u>首领的另一个任务是搞清楚哪个跟随者的状态与自己是一致的</u>。跟随者为了保持与首领的状态一致、在有新消息到达时尝试从首领那里复制消息，不过有各种原因会导致同步失败。例如，网络拥塞导致复制变慢， broker发生崩溃导致复制滞后，直到重启broker后复制才会继续。

​	**为了与首领保持同步，跟随者向首领发送获取数据的请求，<u>这种请求与消费者为了读取消息而发送的请求是一样的</u>**。首领将响应消息发给跟随者。请求消息里包含了跟随者想要获取消息的偏移量，而且这些偏移量总是有序的。

​	<u>一个跟随者副本先请求消息1 ，接着请求消息2 ，然后请求消息3 ，在收到这3个请求的响应之前，它是不会发送第4个请求消息的。如果跟随者发送了请求消息4 ，那么首领就知道它已经收到了前面3个请求的响应</u>。**通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度**。

​		<u>如果跟随者在10s内没有请求任何消息，或者虽然在请求消息，但在10s内没有请求最新的数据，那么它就会被认为是不同步的</u>。**<u>如果一个副本无法与首领保持一致，在首领发生失效时，它就不可能成为新首领一一毕竟它没有包含全部的消息</u>**。

​	<u>相反，持续请求得到的最新悄息副本被称为**同步的副本**。**在首领发生失效时，只有同步副本才有可能被选为新首领**</u>。

​	跟随者的正常不活跃时间或在成为不同步副本之前的时间是通过replica.lag.time.max.ms参数来配置的。这个时间间隔直接影响着首领选举期间的客户端行为和数据保留机制。我们将在第6章讨论可靠性保证， 到时候会深入讨论这个问题。

​	<u>除了当前首领之外，每个分区都有一个**首选首领**——创建主题时选定的首领就是分区的首选首领</u>。之所以把它叫作首选首领，是因为在创建分区时，需要在broker之间均衡首领（后面会介绍在broker间分布副本和首领的算法）。因此，我们希望首选首领在成为真正的首领时， broker间的负载最终会得到均衡。<u>默认情况下， Kafka的auto.leader.rebalance.enable被设为true，它会检查首选首领是不是当前首领，如果不是，并且该副本是同步的，那么就会触发首领选举，让首选首领成为当前首领</u>。

> 找到首选首领
>
> 从分区的副本清单里可以很容易找到首选首领（可以使用kafka.topics.sh 工具查看副本和分区的详细信息，我们将在第10章介绍管理工具）。<u>清单里的第一个副本一般就是首选首领</u>。不管当前首领是哪一个副本，都不会改变这个事实，即使使用副本分配工具将副本重新分配给其他broker 。要记住，<u>如果你手动进行副本分配，第一个指定的副本就是首选首领，所以要确保首选首领被传播到其他broker 上，避免让包含了首领的broker负载过重，而其他broker却无法为它们分担负载</u>。

## * 5.4 处理请求

​	 <u>broker的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求</u>。 Kafka 提供了一个二进制协议(基于 TCP)，指定了请求消息的格式以及 broker 如何对请求作出响应——包括成功处理请求或在处理请求过程中遇到错误。客户端发起连接并发送请求，broker 处理请求并作出响应。 **broker 按照请求到达的顺序来处理它们**——这种顺序保证让 Kaka 具有了消息队列的特性，同时保证保存的消息也是有序的。

​	所有的请求消息都包含一个标准消息头：

+ Request type （也就是API key)
+ Request version (broker 可以处理不同版本的客户端请求，井根据客户端版本作出不同的响应）
+ Correlation ID：一个具有唯一性的数字， 用于标识请求消息，同时也会出现在响应消息和错误日志里（用于诊断问题）
+ Client ID：用于标识发送请求的客户端

​	我们不打算在这里描述该协议，因为在Kafka 文档里已经有很详细的说明。不过，了解broker 如何处理请求还是有必要的一一后面在我们讨论Kafka 监控和各种配置选项时，你就会了解到那些与队列和线程有关的度量指标和配置参数。

​	<u>broker 会在它所监听的每一个端口上运行一个Acceptor线程，这个线程会创建一个连接，并把它交给Processor线程去处理。Processor线程（也被叫作“网络线程”）的数量是可配置的。网络线程负责从客户端获取请求消息，把它们放进**请求队列**，然后从**响应队列**获取响应消息，把它们发送给客户端</u>。图5-1为Kafka 处理请求的内部流程。

​	<u>请求消息被放到请求队列后，**IO线程**会负责处理它们</u>。下面是几种最常见的请求类型。

+ 生产请求

  生产者发送的请求，它包含客户端要写入broker的消息。

+ 获取请求

  在消费者和跟随者副本需要从broker读取消息时发送的请求。

![img](https://img-blog.csdnimg.cn/20210528084750259.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hzeHkwNTA2,size_16,color_FFFFFF,t_70)

​	图5-1: Kafka 处理请求的内部流程

​	<u>生产请求和获取请求都必须发送给分区的**首领副本**</u>。

+ 如果broker收到一个针对特定分区的请求，而该分区的首领在另一个broker 上，那么发送请求的客户端会收到一个<u>“非分区首领”的错误响应</u>。
+ 当针对特定分区的获取请求被发送到一个不含有该分区首领的broker上，也会出现同样的错误。

​	**Kafka客户端要自己负责把生产请求和获取请求发送到正确的broker 上**。

​	**那么客户端怎么知道该往哪里发送请求呢？客户端使用了另一种请求类型，也就是<u>元数据请求</u>**。

​	<u>这种请求包含了客户端感兴趣的主题列表。服务器端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本， 以及哪个副本是首领。**元数据请求可以发送给任意一个broker ，因为所有broker 都缓存了这些信息**</u>。

​	**一般情况下，客户端会把这些信息缓存起来，并直接往目标broker上发送生产请求和获取请求**。<u>它们需要时不时地通过发送元数据请求来刷新这些信息</u>（刷新的时间间隔通过metadata.max.age.ms参数来配置），从而知道元数据是否发生了变更一一比如，在新broker 加入集群时，部分副本会被移动到新的broker 上（如图5-2 所示）。**另外，如果客户端收到“非首领”错误，它会在尝试重发请求之前先刷新元数据，因为这个错误说明了客户端正在使用过期的元数据信息，之前的请求被发到了错误的broker上**。

![img](https://img-blog.csdnimg.cn/20210528084816207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hzeHkwNTA2,size_16,color_FFFFFF,t_70)

​	图5-2 ：客户端路由请求

### * 5.4.1 生产请求

​	我们在第3章讨论如何配置生产者的时候，提到过acks这个配置参数一一该参数指定了需要多少个broker确认才可以认为一个消息写入是成功的。不同的配置对“写入成功”的界定是不一样的，<u>如果acks=1 ，那么只要首领收到消息就认为写入成功；如果acks=all ，那么需要所有同步副本收到消息才算写入成功；如果acks=0，那么生产者在把消息发出去之后，完全不需要等待broker的响应</u>。

​	<u>包含首领副本的broker 在收到生产请求时，会对请求做一些验证</u>。

+ 发送数据的用户是否有主题写入权限？

+ 请求里包含的acks值是否有效（只允许出现。0、1 或all) ?

+ 如果acks=all ， 是否有足够多的同步副本保证消息已经被安全写入？ （我们可以对broker 进行配置，如果同步副本的数量不足， broker可以拒绝处理新消息。在第6章介绍Kafka 持久性和可靠性保证时，我们会讨论更多这方面的细节。）

​	之后，消息被写入本地磁盘。在Linux 系统上，消息会被写到文件系统缓存里，并不保证它们何时会被刷新到磁盘上。<u>Kafka 不会一直等待数据被写到磁盘上一一它依赖复制功能来保证消息的持久性</u>。

​	在消息被写入分区的首领之后， broker 开始检查acks配置参数一一如果acks 被设为0或1，那么broker 立即返回响应；<u>如果acks被设为all，那么请求会被保存在一个叫作**炼狱**的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端</u>。

### * 5.4.2 获取请求

​	broker处理获取请求的方式与处理生产请求的方式很相似。客户端发送请求，向broker 请求主题分区里具有特定偏移量的消息，好像在说： “请把主题Test分区0偏移量从53开始的消息以及主题Test分区3偏移量从64开始的消息发给我。”<u>客户端还可以指定broker最多可以从一个分区里返回多少数据。这个限制是非常重要的，因为客户端需要为broker 返回的数据分配足够的内存。如果没有这个限制， broker 返回的大量数据有可能耗尽客户端的内存</u>。

​	我们之前讨论过，请求需要先到达指定的分区首领上，然后客户端通过查询元数据来确保请求的路由是正确的。首领在收到请求时，它会先检查请求是否有效一一比如，指定的偏移量在分区上是否存在？<u>如果客户端请求的是已经被删除的数据，或者请求的偏移量不存在，那么broker将返回一个错误</u>。

​	如果请求的偏移量存在， broker 将按照客户端指定的数量上限从分区里读取消息，再把消息返回给客户端。**<u>Kafka 使用零复制技术向客户端发送消息一一也就是说， Kafka 直接把消息从文件（或者更确切地说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区</u>**。这是Kafka 与其他大部分数据库系统不一样的地方，其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。

​	客户端除了可以设置broker 返回数据的上限，也可以设置下限。例如，如果把下限设置为10KB，就好像是在告诉broker ：“等到有10KB 数据的时候再把它们发送给我。”在主题消息流量不是很大的情况下，这样可以减少CPU 和网络开销。客户端发送一个请求， broker等到有足够的数据时才把它们返回给客户端，然后客户端再发出请求，而不是让客户端每隔几毫秒就发送一次请求，每次只能得到很少的数据甚至没有数据。（如图5-3 所示。）对比这两种情况，它们最终读取的数据总量是一样的，但前者的来回传送次数更少，因此开销也更小。

![img](https://img-blog.csdnimg.cn/20210528085131996.png)

​	图5-3: broker 延迟作出响应以便累积足够的数据

​	当然，我们不会让客户端一直等待broker 累积数据。在等待了一段时间之后，就可以把可用的数据拿回处理，而不是一直等待下去。所以，客户端可以定义一个超时时间，告诉broker ：“如果你无法在X毫秒内累积满足要求的数据量，那么就把当前这些数据返回给我。“

​	**<u>有意思的是，并不是所有保存在分区首领上的数据都可以被客户端读取。大部分客户端只能读取已经被写入所有同步副本的消息（跟随者副本也不行，尽管它们也是消费者否则复制功能就无法工作）</u>**。

​	<u>分区首领知道每个消息会被复制到哪个副本上，在消息还没有被写入所有同步副本之前，是不会发送给消费者的一一尝试获取这些消息的请求会得到空的响应而不是错误</u>。

​	**因为还没有被足够多副本复制的消息被认为是“不安全”的一一如果首领发生崩溃，另一个副本成为新首领，那么这些消息就丢失了**。<u>如果我们允许消费者读取这些消息，可能就会破坏一致性</u>。试想， 一个消费者读取并处理了这样的一个消息，而另一个消费者发现这个消息其实并不存在。所以，我们会等到所有同步副本复制了这些消息，才允许消费者读取它们（如图5-4 所示） 。这也意味着，<u>如果broker间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）</u>。延迟时间可以通过参数replica.lag.time.max.ms来配置，它指定了副本在复制消息时可被允许的最大延迟时间。

![img](http://5b0988e595225.cdn.sohucs.com/images/20200430/47ae1e49635c4cf2995bec0702e12d05.jpeg)

图5-4 ：消费者只能看到已经复制到ISR 的消息

### 5.4.3 其他请求

​	到此为止，我们讨论了Kafka最为常见的几种请求类型：元数据请求、生产请求和获取请求。重要的是，我们讨论的是客户揣在网络上使用的通用二进制协议。Kafka 内置了由开源社区贡献者实现和维护的Java客户端，同时也有用其他语言实现的客户端，如C、Python、Go语言等。Kafka网站上有它们的完整清单，这些客户端就是使用这个二进制协议与broker通信的。

​	另外，broker之间也使用同样的通信协议。它们之间的请求发生在Kafka 内部，客户端不应该使用这些请求。例如，<u>当一个新首领被选举出来，控制器会发送LeaderAndIsr请求给新首领（这样它就可以开始接收来自客户端的请求）和跟随者（这样它们就知道要开始跟随新首领）</u>。

​	在我们写这本书的时候， Kafka 协议可以处理20种不同类型的请求，而且会有更多的类型加入进来。协议在持续演化一一随着客户端功能的不断增加，我们需要改进协议来满足需求。例如，之前的Kafka 消费者使用Zookeeper 来跟踪偏移量，在消费者启动的时候，它通过检查保存在Zookeeper上的偏移量就可以知道从哪里开始处理消息。<u>因为各种原因，我们决定不再使用Zookeeper 来保存偏移量，而是把偏移量保存在特定的Kafka 主题上。为了达到这个目的，我们不得不往协议里增加几种请求类型：OffsetCommitRequest、OffsetFetchRequest和ListOffsetsRequest。现在，在应用程序调用commitOffset()方法时，客户端不再把偏移量写入Zookeeper，而是往Kafka发送OffsetCommitRequest请求</u>。

​	主题的创建仍然需要通过命令行工具来完成，命令行工具会直接更新Zookeeper里的主题列表， broker监听这些主题列表，在有新主题加入时，它们会收到通知。<u>我们正在改进Kafka，增加了CreateTopicRequest请求类型，这样客户端（包括那些不支持Zookeeper客户端的编程语言）就可以直接向broker请求创建新主题了</u>。

​	除了往协议里增加新的请求类型外，我们也会通过修改已有的请求类型来给它们增加新功能。例如，从Kafka0.9.0到Kafka0.10.0，我们希望能够让客户端知道谁是当前的控制器，于是把控制器信息添加到元数据响应消息里。我们还在元数据请求消息和响应消息里添加了一个新的version字段。现在，0.9.0版本的客户端发送的元数据请求里version 为0 (0.9.0 版本客户端的version不会是1）。不管是0.9.0版本的broker ，还是0.10.0版本的broker ，它们都知道应该返回version为0的响应， 也就是不包含控制器信息的响应。0.9.0 版本的客户端不需要控制器的信息，而且也没必要知道如何去解析它。0.10.0 版本的客户端会发送version为1的元数据请求，0.10.0 版本的broker 会返回version 为1的响应，里面包含了控制器的信息。<u>如果0.10.0 版本的客户端发送version 为1的请求给0.9.0 版本的broker ，这个版本的broker 不知道该如何处理这个请求，就会返回一个错误。这就是为什么我们建议在升级客户端之前先升级broker ，因为新的broker 知道如何处理旧的请求，反过来则不然</u>。

​	<u>我们在0.10.0版本的Kafka 里加入了ApiVersionRequest——客户端可以询问broker支持哪些版本的请求，然后使用正确的版本与broker通信。如果能够正确使用这个新功能，客户端就可以与旧版本的broker通信，只要broker支持这个版本的协议</u>。

## 5.5 物理存储

​	**Kafka 的基本存储单元是分区**。<u>分区无法在多个broker间进行再细分，也无法在同一个broker 的多个磁盘上进行再细分</u>。所以，分区的大小受到单个挂载点可用空间的限制（ 一个挂载点由单个磁盘或多个磁盘组成，如果配置了JBOD ，就是单个磁盘，如果配置了RAID ，就是多个磁盘。请参考第2 章）。

​	在配置Kafka的时候，管理员指定了一个用于存储分区的目录清单一一也就是log.dirs参数的值（不要把它与存放错误日志的目录混淆了，日志目录是配置在log4j.properties文件里的）。该参数一般会包含每个挂载点的目录。

​	接下来我们会介绍Kafka是如何使用这些目录来存储数据的。首先，我们要知道数据是如何被分配到集群的broker上以及broker的目录里的。然后，我们还要知道broker是如何管理这些文件的，特别是如何进行数据保留的。随后，我们会深入探讨文件和索引格式。最后，我们会讨论**日志压缩**及其工作原理。日志压缩是Kafka的一个高级特性，因为有了这个特性，Kafka可以用来长时间地保存数据。

### 5.5.1 分区分配

​	在创建主题时， Kafka首先会决定如何在broker间分配分区。假设你有6个broker，打算创建一个包含10个分区的主题，并且复制系数为3。那么Kafka 就会有30个分区副本，它们可以被分配给6个broker。在进行分区分配时，我们要达到如下的目标。

+ 在broker 间平均地分布分区副本。对于我们的例子来说，就是要保证每个broker 可以分到5个副本。

+ 确保每个分区的每个副本分布在不同的broker 上。假设分区0的首领副本在broker 2 上，那么可以把跟随者副本放在broker 3 和broker 4 上，但不能放在broker 2 上，也不能两个都放在broker 3 上。

+ <u>如果为broker 指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的broker上。这样做是为了保证一个机架的不可用不会导致整体的分区不可用</u>。

​	为了实现这个目标，我们先随机选择一个broker （假设是4 ），然后使用轮询的方式给每个broker 分配分区来确定首领分区的位置。于是，首领分区0 会在broker 4 上，首领分区1会在broker 5 上，首领分区2 会在broker0 上（只有6 个broker ），并以此类推。然后，我们从分区首领开始，依次分配跟随者副本。如果分区0 的首领在broker 4 上，那么它的第一个跟随者副本会在broker 5 上，第二个跟随者副本会在broker0上。分区1的首领在broker 5 上，那么它的第一个跟随者副本在broker0上，第二个跟随者副本在broker1上。

​	如果配置了机架信息，那么就不是按照数字顺序来选择broker 了，而是按照交替机架的方式来选择broker 。假设broker0、broker1和broker2放置在同一个机架上，broker3、broker4和broker5分别放置在其他不同的中几架上。我们不是按照从0 到5 的顺序来选择broker ，而是按照0, 3, 1, 4, 2, 5 的顺序来选择，这样每个相邻的broker 都在不同的机架上（如图5-5 所示）。于是，如果分区0 的首领在broker 4 上，那么第一个跟随者副本会在broker 2 上，这两个broker 在不同的机架上。如果第一个机架下线，还有其他副本仍然活跃着，所以分区仍然可用。这对所有副本来说都是一样的，因此在机架下线时仍然能够保证可用性。

![img](https://upload-images.jianshu.io/upload_images/11345047-831673d2accd52e5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp)

​	<u>为分区和副本选好合适的 broker之后，接下来要决定这些分区应该使用哪个目录。我们单独为每个分区分配目录，规则很简单 : 计算每个目录里的分区数量，新的分区总是被添加到数量最小的那个目录里</u>。也就是说，如果添加了 一个新磁盘，所有新的分区都会被创建 到这个磁盘上。因为在完成分配工作之前，新磁盘的分区数量总是最少的。

> 注意磁盘空间
>
> 要注意，在为broker 分配分区时并没有考虑可用空间和工作负载问题，但**在将分区分配到磁盘上时会考虑分区数量，不过不考虑分区大小**。也就是说，如果有些broker 的磁盘空间比其他broker 要大（有可能是因为集群同时使用了旧服务器和新服务器），有些分区异常大，或者同一个broker 上有大小不同的磁盘，那么在分配分区时要格外小心。在后面的章节中，我们会讨论Kafka 管理员该如何解决这种broker 负载不均衡的问题。

### 5.5.2 文件管理

​	保留数据是Kafka 的一个基本特性， Kafka 不会一直保留数据，也不会等到所有消费者都读取了消息之后才删除消息。相反， <u>Kafka 管理员为每个主题配置了数据保留期限，规定数据被删除之前可以保留多长时间，或者清理数据之前可以保留的数据量大小</u>。

​	<u>因为在一个大文件里查找和删除消息是很费时的，也很容易出错，所以我们把分区分成若干个**片段**</u>。默认情况下，每个片段包含1GB 或一周的数据，以较小的那个为准。<u>在broker往分区写入数据时，如果达到片段上限，就关闭当前文件，井打开一个新文件</u>。

​	当前正在写入数据的片段叫作**活跃片段**。**活动片段永远不会被删除**，所以如果你要保留数据1天，但片段里包含了5 天的数据，那么这些数据会被保留5 天，因为在片段被关闭之前这些数据无法被删除。如果你要保留数据一周，而且每天使用一个新片段，那么你就会看到，每天在使用一个新片段的同时会删除一个最老的片段——所以大部分时间该分区会有7个片段存在。

​	我们在第2章讲过， **<u>broker 会为分区里的每个片段打开一个文件句柄，哪怕片段是不活跃的</u>。这样会导致打开过多的文件句柄，所以操作系统必须根据实际情况做一些调优**。

### 5.5.3 文件格式

​	**我们把Kafka的消息和偏移量保存在文件里**。保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的。因为使用了相同的消息格式进行磁盘存储和网络传输， Kafka 可以使用零复制技术给消费者发送消息，同时避免了对生产者已经压缩过的消息进行解压和再压缩。

​	除了键、值和偏移量外， 消息里还包含了消息大小、校验和、消息格式版本号、压缩算能(Snappy 、GZip或LZ4）和时间戳（在0.10.0 版本里引入的）。<u>时间戳可以是生产者发送消息的时间，也可以是消息到达broker的时间，这个是可配置的</u>。

​	<u>如果生产者发送的是压缩过的消息，那么同一个批次的消息会被压缩在一起，被当作“包装消息”进行发送（如图5-6 所示）</u> 。于是， broker 就会收到一个这样的消息，然后再把它发应给消费者。消费者在解压这个消息之后，会看到整个批次的消息，它们都有自己的时间戳和偏移量。

![img](https://img-blog.csdnimg.cn/20200305202749423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poZW5nemhhb3lhbmcxMjI=,size_16,color_FFFFFF,t_70)

​	图5-6 ：普通消息和包装消息

​	<u>也就是说，如果在生产者端使用了压缩功能（极力推荐），那么发送的批次越大，就意味着在网络传输和磁盘存储方面会获得越好的压缩性能</u>，同时意味着如果修改了消费者使用的消息格式（例如，在消息里增加了时间戳），那么网络传输和磁盘存储的格式也要随之修改，而且broker 要知道如何处理包含了两种消息格式的文件。

​	Kafka 附带了一个叫DumpLogSegment的工具，可以用它查看片段的内容。它可以显示每个消息的偏移量、校验和、魔术数字节、消息大小和压缩算法。运行该工具的方能如下：

```shell
bin/kafka-run-class.sh kafka.tools.DumpLogSegments
```

​	如果使用了`--deep-iteration`参数，可以显示被压缩到包装消息里的消息。

### * 5.5.4 索引

​	消费者可以从Kafka 的任意可用偏移量位置开始读取消息。假设消费者要读取从偏移量100开始的1MB 消息，那么broker 必须立即定位到偏移量100 （可能是在分区的任意一个片段里），然后开始从这个位置读取消息。为了帮助broker 更快地定位到指定的偏移量， Kafka为每个分区维护了一个索引。**索引把偏移量映射到片段文件和偏移量在文件里的位置**。

+ **索引也被分成片段，所以在删除消息时，也可以删除相应的索引**。
+ Kafka不维护索引的校验和。**如果索引出现损坏， Kafka 会通过重新读取消息并录制偏移量和位置来重新生成索引**。
+ **如果有必要，管理员可以删除索引，这样做是绝对安全的， Kafka 会自动重新生成这些索引**。

### * 5.5.5 清理

​	一般情况下， Kafka 会根据设置的时间保留数据，把超过时效的旧数据删除掉。不过，试想一下这样的场景，如果你使用Kafka 保存客户的收货地址，那么保存客户的最新地址比保存客户上周甚至去年的地址要有意义得多，这样你就不用担心会用错旧地址，而且短时间内客户也不会修改新地址。另外一个场景， 一个应用程序使用Kafka 保存它的状态， 每次状态发生变化，它就把状态写入Kafka。在应用程序从崩愤中恢复时，它从Kafka 读取消息来恢复最近的状态。在这种情况下，应用程序只关心它在崩愤前的那个状态，而不关心运行过程中的那些状态。

​	<u>Kafka 通过改变主题的保留策略来满足这些使用场景。早于保留时间的旧事件会被删除，为每个键保留最新的值，从而达到清理的效果</u>。**很显然，只有当应用程序生成的事件里包含了键值对时，为这些主题设置compact策略才有意义**。**如果主题包含null 键， 清理就会失败**。

### * 5.5.6 清理的工作原理

​	每个日志片段可以分为以下两个部分。

+ 干净的部分

  这些消息之前被清理过，每个键只有一个对应的值，这个值是上一次清理时保留下来的。

+ 污浊的部分

  这些消息是在上一次清理之后写入的。

​	两个部分的日志片段示意如图5-7 所示。

![img](https://img2020.cnblogs.com/blog/1109757/202006/1109757-20200629223308508-587514956.png)

​	图5-7 ：包含干净和污浊两个部分的分区

​	<u>如果在Kafka 启动时启用了清理功能（通过配置log.cleaner.enabled参数），每个broker会启动一个清理管理器线程和多个清理线程，它们负责执行清理任务。这些线程会选择污浊率（污浊消息占分区总大小的比例）较高的分区进行清理</u>。

​	**为了清理分区，清理线程会读取分区的污浊部分，井在内存里创建一个map 。map 里的每个元素包含了消息键的散列值和消息的偏移量，键的散列值是16B ，加上偏移量总共是24B** 。如果要清理一个1GB 的日志片段，并假设每个消息大小为1KB，那么这个片段就包含一百万个消息，而我们只需要用24MB的map 就可以清理这个片段。（如果有重复的键，可以重用散列项，从而使用更少的内存。）这是非常高效的！

​	<u>管理员在配置Kafka 时可以对map 使用的内存大小进行配置。每个线程都有自己的map，而这个参数指的是所有线程可使用的内存总大小</u>。如果你为map 分配了1GB 内存，并使用了5个清理线程，那么每个线程可以使用200MB内存来创建自己的map 。**Kafka 井不要求分区的整个污浊部分来适应这个map的大小，但要求至少有一个完整的片段必须符合。如果不符合，那么Kafka 就会报错，管理员要么分配更多的内存，要么减少清理线程数**。如果只有少部分片段可以完全符合， Kafka 将从最旧的片段开始清理，等待下一次清理剩余的部分。

​	清理线程在创建好偏移量map 后，开始从干净的片段处读取消息，从最旧的消息开始，把它们的内容与map 里的内容进行比对。它会检查消息的键是否存在于map 中，如果不存在，那么说明消息的值是最新的，就把消息复制到替换片段上。如果键已存在，消息会被忽略，因为在分区的后部已经有一个具有相同键的消息存在。在复制完所有的消息之后，我们就将替换片段与原始片段进行交换，然后开始清理下一个片段。完成整个清理过程之后，每个键对应一个不同的消息——这些消息的值都是最新的。清理前后的分区片段如图5-8 所示。

![img](https://img2020.cnblogs.com/blog/1109757/202006/1109757-20200629223318223-1219218463.png)

​	图5-8 ：清理前后的分区片段

### * 5.5.7 被删除的事件

​	如果只为每个键保留最近的一个消息，那么当需要删除某个特定键所对应的所有消息时，我们该怎么办？这种情况是有可能发生的，比如一个用户不再使用我们的服务，那么完全可以把与这个用户相关的所有信息从系统中删除。

​	**为了彻底把一个键从系统里删除，应用程序必须发送一个包含该键且值为null 的消息。清理线程发现该消息时，会先进行常规的清理，只保留值为null 的消息**。该消息（被称为**墓碑消息**）会被保留一段时间，时间长短是可配置的。在这期间，消费者可以看到这个基碑悄息，井且发现它的值已经被删除。于是，如果消费者往数据库里复制Kafka 的数据， 当它看到这个墓碑消息时，就知道应该要把相关的用户信息从数据库里删除。在这个时间段过后，清理线程会移除这个墓碑消息，这个键也将从Kafka 分区里消失。<u>重要的是，要留给消费者足够多的时间，让他看到墓碑消息，因为如果消费者离线几个小时并错过了墓碑消息，就看不到这个键，也就不知道它已经从Kafka 里删除，从而也就不会去删除数据库里的相关数据了</u>。

### 5.5.8 何时会清理主题

​	<u>就像delete策略不会删除当前活跃的片段一样，compact策略也不会对当前片段进行清理。只有旧片段里的消息才会被清理</u>。

​	在0.10.0和更早的版本里， Kafka 会在包含脏记录的主题数量达到50% 时进行清理。这样做的目的是避免太过频繁的清理（因为清理会影响主题的读写性能），同时也避免存在太多脏记录（因为它们会占用磁盘空间）。浪费50% 的磁盘空间给主题存放脏记录，然后进行一次清理，这是个合理的折中，管理员也可以对它进行调整。

​	我们计划在未来的版本中加入宽限期，在宽限期内，我们保证消息不会被清理。对于想看到主题的每个消息的应用程序来说，它们就有了足够的时间，即使时间有点滞后。

## 5.9 总结

​	我们无法在这一章里涵盖所有的内容，但希望大家能够对我们在这个项目上所傲的设计和优化有所了解，同时本章也为大家解释了在使用Kafka 时可能碰到的一些晦涩难懂的现象和参数配置问题。

​	如果大家真的对Kafka 内部原理感兴趣，唯一的途径是阅读它的源代码。Kafka 开发者邮件组（dev@kafka.apache.org）是一个非常友好的社区，在那里会有人回答有关Kafka 工作原理的问题。或许你在阅读源代码时还能够修复一些缺陷一一开源社区的大门总是向贡献者敞开。

# 6. 可靠的数据传递

## 6.1 可靠性保证

​	在讨论可靠性时，我们一般会使用**保证**这个词，它是指确保系统在各种不同的环境下能够发生一致的行为。

​	了解系统的保证机制对于构建可靠的应用程序来说至关重要，这也是能够在不同条件下解释系统行为的前提。那么Kafka 可以在哪些方面作出保证呢？

+ **Kafka 可以保证分区消息的顺序**。如果使用同一个生产者往同一个分区写入消息，而且消息B 在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B 。

+ **只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“ 已提交”的**。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。

+ **只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。**
+ **<u>消费者只能读取已经提交的消息</u>**。

​	这些基本的保证机制可以用来构建可靠的系统，但仅仅依赖它们是无法保证系统完全可靠的。构建一个可靠的系统需要作出一些权衡， Kafka 管理员和开发者可以在配置参数上作出权衡，从而得到他们想要达到的可靠性。<u>这种权衡一般是指消息存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡</u>。下面将介绍Kafka 的复制机制，井探讨Kafka 是如何实现可靠性的，最后介绍一些重要的配置参数。

## * 6.2 复制

​	<u>Kafka 的**复制**机制和**分区的多副本**架构是Kafka 可靠性保证的核心</u>。把消息写入多个副本可以使Kafka 在发生崩溃时仍能保证消息的<u>持久性</u>。

​	我们已经在第5章深入解释了Kafka的复制机制，现在重新回顾一下主要内容。

​	Kafka 的主题被分为多个**分区**，<u>分区是基本的数据块</u>。分区存储在单个磁盘上， <u>Kafka 可以保证分区里的事件是有序的</u>，分区可以在线（可用），也可以离线（不可用） 。每个分区可以有多个副本，其中一个副本是首领。**所有的事件都直接发送给首领副本，或者直接从首领副本读取事件**。<u>其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个**同步副本**将成为新首领</u>。

​	**分区首领是同步副本**，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的。

+ <u>与Zookeeper之间有一个**活跃**的会话</u>，也就是说，它在过去的6s（可配置）内向Zookeeper 发送过心跳。

+ 在过去的10s 内（可配置）从首领那里获取过消息。

+ 在过去的10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，**它还必须是几乎零延迟的**。

​	如果跟随者副本不能满足以上任何一点，比如与Zookeeper断开连接，或者不再获取新消息，或者获取消息滞后了10s 以上，那么它就被认为是不同步的。**一个不同步的副本通过与Zookeeper 重新建立连接，井从首领那里获取最新消息，可以重新变成同步的**。<u>这个过程在网络出现临时问题井很快得到修复的情况下会很快完成，但如果broker发生崩溃就需要较长的时间</u>。

> 非同步副本
>
> <u>如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，**通常是Java不恰当的垃圾回收配置导致的**</u>。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker 与Zookeeper 之间断开连接，最后变成不同步的，进而发生状态切换。

​	**一个滞后的同步副本会导致生产者和消费者变慢，<u>因为在消息被认为已提交之前，客户端会等待所有同步副本接收消息</u>**。<u>而如果一个副本不再同步了，我们就不再关心它是否已经收到消息。虽然非同步副本同样滞后，但它并不会对性能产生任何影响。但是，更少的同步副本意味着更低的有效复制系数，在发生宕机时丢失数据的风险更大</u>。

​	我们将在下一节讲解在实际项目中这将意味着什么。

## 6.3 broker配置

​	broker 有3 个配置参数会影响Kafka 消息存储的可靠性。与其他配置参数一样，它们可以应用在<u>broker级别</u>，用于控制所有主题的行为，也可以应用在<u>主题级别</u>，用于控制个别主题的行为。

​	<u>在主题级别控制可靠性，意味着Kafka 集群可以同时拥有可靠的主题和非可靠的主题</u>。例如，在银行里，管理员可能把整个集群设置为可靠的，但把其中的一个主题设置为非可靠的，用于保存来自客户的投诉，因为这些消息是允许丢失的。

​	让我们来逐个介绍这些配置参数，看看它们如何影响消息存储的可靠性，以及Kafka 在哪些方面作出了权衡。

### * 6.3.1 复制系数

​	主题级别的配置参数是replication.factor，而在broker 级别则可以通过default.replication.factor来配置自动创建的主题。

​	<u>Kafka主题的默认复制系数为3，每个分区会被总共3个不同的broker复制3次</u>。

​	用户可以修改复制系数，或在主题创建后新增或移除副本来改变复制系数。

​	复制系数N，N-1个broker失效时仍能保证从主题读取或写入数据。高复制系数意味着更高的可用性，同时意味着需要占用更多的磁盘空间（N倍磁盘空间）。

​	*如果因broker重启导致的主题不可用是可接受的（这在集群里是很正常的行为），那么把复制系数设为1就可以了。在作出这个权衡的时候，要确保这样不会对你的组织和用户造成影响，因为你在节省了硬件成本的同时也降低了可用性。复制系数为2意味着可以容忍1个broker发生失效，看起来已经足够了。不过要记住，有时候1个broker发生失效会导致集群不稳定（通常是旧版的Kafka ），迫使你重启另一个broker——集群控制器。也就是说，如果将复制系数设为2，就有可能因为重启等问题导致集群不可用。所以这是一个两难的选择。*

​	**基于以上几点原因，我们建议在要求可用性的场景里把复制系数设为3** 。在大多数情况下，这已经足够安全了——不过我们也见过有些银行使用5个副本，以防不测。

​	**副本的分布也很重要**。如果所有副本在同一机架上，一旦机架交换机发生故障，分区就不可用。<u>为了避免机架级别的故障，我们建议把broker分布在多个不同的机架上，并使用broker.rack参数来为每个broker 配置所在机架的名字</u>。**如果配置了机架名字，Kafka会保证分区的副本被分布在多个机架上，从而获得更高的可用性**。我们已经在第5章介绍了如何在broker和机架上分布副本，如果你对此感兴趣，可以参考第5 章的内容。

### * 6.3.2 不完全的首领选举

​	unclean.leader.election只能在broker级别（实际上是在集群范围内）进行配置， 它的**默认值是true**。

​	我们之前提到过，当分区首领不可用时， 一个同步副本会被选为新首领。如果在选举过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是“完全”的。

​	**但如果在首领不可用时其他副本都是不同步的，我们该怎么办呢？**

​	这种情况会在以下两种场景里出现。

+ 分区有3个副本，其中的两个跟随者副本不可用（比如有两个broker 发生崩溃）。这个时候，如果生产者继续往首领写入数据，所有消息都会得到确认井被提交（因为此时首领是唯一的同步副本）。现在我们假设首领也不可用了（又一个broker 发生崩溃），这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。

+ 分区有3 个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接收消息。这个时候，如果首领变为不可用，另外两个副本就再也无桂变成同步的了。

​	对于这两种场景，我们要作出一个两难的选择。

+ <u>如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时（比如更换内存芯片）</u>。

+ **如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后写入旧首领的消息、会全部丢失，导致数据不一致**。为什么会这样呢？假设在副本0 和副本1 不可用时，偏移量100-200 的消息被写入副本2 （首领）。现在副本2 变为不可用的，而副本0 变为可用的。副本0 只包含偏移量0～ 100 的消息，不包含偏移量100～ 200 的消息。如果我们允许副本0 成为新首领，生产者就可以继续写入数据，消费者可以继续读取数据。于是，新首领就有了偏移量100 ～200 的新消息。这样，部分消费者会读取到偏移量100 ～200 的旧消息，部分消费者会读取到偏移量100～200 的新消息，还有部分消费者读取的是二者的混合。这样会导致非常不好的结果，比如生成不准确的报表。<u>另外，副本2 可能会重新变为可用，并成为新首领的跟随者。这个时候，**它会把比当前首领旧的消息全部删除**，而这些消息对于所有消费者来说都是不可用的</u>。

​	**<u>简而言之，如果我们允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一致的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为我们必须等待原先的首领恢复到可用状态</u>**。

​	<u>如果把unclean.leader.election.enable设为true，就是允许不同步的副本成为首领（也就是"不完全的选举"，那么我们将面临丢失消息的风险</u>。如果把这个参数设为false，就要等待原先的首领重新上线，从而降低了可用性。我们经常看到一些对数据质量和数据一致性要求较高的系统会禁用这种不完全的首领选举（ 把这个参数设为false ） 。银行系统是这方面最好的例子，大部分银行系统宁愿选择在几分钟甚至几个小时内不处理信用卡支付事务，也不会冒险处理错误的消息。<u>不过在对可用性要求较高的系统里，比如实时点击流分析系统， 一般会启用不完全的首领选举</u>。

### * 6.3.3 最少同步副本

​	在主题级别和broker级别上，这个参数都叫min.insync.replicas。

​	我们知道，尽管为一个主题配置了3 个副本，还是会出现只有一个同步副本的情况。如果这个同步副本变为不可用，我们必须在可用性和一致性之间作出选择一一这是一个两难的选择。**根据Kafka对可靠性保证的定义，消息只有在被写入到<u>所有同步副本</u>之后才被认为是已提交的**。但如果这里的“所有副本”只包含一个同步副本，那么在这个副本变为不可用时，数据就会丢失。

​	如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。对于一个包含3 个副本的主题，如果min.insync.replicas被设为2 ，那么至少要存在两个同步副本才能向分区写入数据。

​	如果3个副本都是同步的，或者其中一个副本变为不可用，都不会有什么问题。不过，如果有两个副本变为不可用，那么<u>broker 就会停止接受生产者的请求</u>。尝试发送数据的生产者会收到NotEnoughReplicasException异常。<u>消费者仍然可以继续读取已有的数据</u>。实际上，如果使用这样的配置，那么当只剩下一个同步副本时，它就变成**只读**了，这是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为。为了从只读状态中恢复，必须让两个不可用分区中的一个重新变为可用的（比如重启broker），并等待它变为同步的。

## 6.4 在可靠的系统里使用生产者

​	<u>即使我们尽可能把broker 配置得很可靠，但如果没有对生产者进行可靠性方面的配置， 整个系统仍然有可能出现突发性的数据丢失</u>。

​	请看以下两个例子。

+ 为broker 配置了3 个副本，井且<u>禁用了不完全首领选举</u>，这样应该可以保证万无一失。我们把生产者发送消息的<u>acks 设为1 （只要首领接收到消息就可以认为消息写入成功）</u>。生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有接收到这个消息。首领向生产者发送了一个响应，告诉它“消息写入成功”，然后它崩溃了，而此时消息还没有被其他副本复制过去。<u>另外两个副本此时仍然被认为是同步的（毕竟**判定一个副本不同步需要一小段时间**），而且其中的一个副本成了新的首领</u>。因为消息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功写入。因为消费者看不到丢失的消息，所以此时的系统仍然是一致的（因为副本没有收到这个消息，所以消息不算已提交），但从生产者角度来看，它丢失了一个消息。
+ 为broker 配置了3 个副本，并且<u>禁用了不完全首领选举</u>。我们接受了之前的教训， 把生产者的acks设为all 。假设现在往Kafka 发送消息，分区的首领刚好崩溃，新的首领正在选举当中， Kafka 会向生产者返回“首领不可用”的响应。<u>在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。这算不上是broker 的可靠性问题，因为broker 并没有收到这个消息。这也不是一致性问题，因为消费者井没有读到这个消息。问题在于如果生产者没能正确处理这些错误，弄丢消息的是它们自己</u>。

​	那么，我们该如何避免这些悲剧性的后果呢？从上面两个例子可以看出，每个使用Kafka的开发人员都要注意两件事情。

+ **根据可靠性需求配置恰当的acks 值**
+ **在参数配置和代码里正确处理错误**

​	第3 章已经深入讨论了生产者的几种模式，现在回顾几个要点。

### * 6.4.1 发送确认

​	生产者可以选择以下3种不同的确认模式。

+ **acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka**。

  在这种情况下还是有可能发生错误，比如发送的对象无法被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使是在发生完全首领选举的情况下，这种模式仍然会丢失消息，<u>因为在新首领选举过程中它并不知道首领已经不可用了</u>。在acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式， 一定会丢失一些消息。

+ acks=1 意味若<u>首领</u>在收到消息并把它写入到分区数据文件（<u>不一定同步到磁盘上</u>）时会返回确认或错误响应。

  在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个LeaderNotAvailableException异常，如果生产者能恰当地处理这个错误（参考6.4.2节），它会重试发送悄息，最终消息会安全到达新的首领那里。<u>不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃</u>。

+ **acks=all 意味着<u>首领</u>在返回确认或错误响应之前，会等待所有同步副本都收到消息**。

  如果和**min.insync.replicas**参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。这是最保险的做法一一**生产者会一直重试直到消息被成功提交**。不过这也是最慢的做法，<u>生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量</u>。

### 6.4.2 配置生产者的重试参数

​	生产者需要处理的错误包括两部分： 一部分是生产者可以自动处理的错误，还有一部分是需要开发者手动处理的错误。

​	<u>如果broker 返回的错误可以通过**重试**来解决，那么生产者会自动处理这些错误</u>。生产者向broker 发送消息时， broker 可以返回一个成功响应码或者一个错误响应码。<u>错误响应码可以分为两种， 一种是在重试之后可以解决的，还有一种是无法通过重试解决的</u>。例如，如果broker 返回的是`LEADER_NOT_AVAILABLE`错误，生产者可以尝试重新发送消息。也许在这个时候一个新的首领被选举出来了，那么这次发送就会成功。也就是说， `LEADER_NOT_AVAILABLE`是一个**可重试**错误。另一方面，如果broker 返回的是`INVALID_CONFIG`错误，即使通过重试也无能改变配置选项，所以这样的重试是没有意义的。这种错误是**不可重试**错误。

​	重试次数的配置，与如果对待失败消息息息相关。

+ 生产者放弃重试抛出异常后，如果希望继续重试，那么可以一开始就调大重试次数
+ 如果消息不重要，可以考虑抛弃，避免占用服务器吞吐量
+ 抑或可以考虑将失败消息存储到其他地方，暂停重试

​	Kafka 的跨数据中心复制工具（MirrorMaker ，我们将在第8 章介绍）默认会进行无限制的重试（例如retries=MAX_INT）。作为一个具有高可靠性的复制工具，它决不会丢失消息。

​	**要注意，重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复**。例如，生产者因为网络问题没有收到broker的确认，但实际上消息已经写入成功，生产者会认为网络出现了临时故障，就重试发送该消息（因为它不知道消息已经写入成功）。在这种情况下， broker 会收到两个相同的消息。重试和恰当的错误处理可以保证每个消息“至少被保存一次”，但当前的Kafka 版本（0.10.0）无法保证每个消息“只被保存一次”。<u>此时可以考虑将消息设计成带有“幂等”性质</u>。

### 6.4.3 额外的错误处理

​	使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松地处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：

+ 不可重试的broker 错误，例如消息大小错误、认证错误等
+ 在消息发送之前发生的错误，例如序列化错误

+ 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误

​	我们在第3章讨论了如何为同步发送消息和异步发送消息编写错误处理器。这些错误处理器的代码逻辑与具体的应用程序及其目标有关。丢弃“不合法的消息”？把错误记录下来？把这些消息保存在本地磁盘上？回调另一个应用程序？具体使用哪一种逻辑要根据具体的架构来决定。**<u>只要记住，如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制</u>**。

## 6.5 在可靠的系统里使用消费者

​	我们已经学习了如何在保证Kafka 可靠性的前提下生产数据，现在来看看如何在同样的前提下读取数据。

​	在本章的开始部分可以看到，<u>只有那些被提交到Kafka的数据，也就是那些已经被写入所有**同步副本**的数据，对消费者是可用的，这意味着**消费者得到的消息已经具备了一致性**</u>。消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有读取过的。这是在读取消息时不丢失消息的关键。

​	在从分区读取数据时，消费者会获取一批事件，检查这批事件里<u>最大</u>的偏移量，然后从这个偏移量开始读取另外一批事件。这样可以保证消费者总能以正确的顺序获取新数据， 不会错过任何事件。

​	<u>如果一个消费者退出，另一个消费者需要知道从什么地方开始继续处理，它需要知道前一个消费者在退出前处理的最后一个偏移量是多少。所谓的“另一个”消费者，也可能就是它自己重启之后重新回来工作。这也就是为什么消费者要“提交”它们的偏移量</u>。它们把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接手它们的工作。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。在这种情况下，如果其他消费者接手了工作，那些没有被处理完的消息就会被忽略，永远得不到处理。这就是为什么我们非常重视偏移量提交的时间点和提交的方式。

> **已提交消息与已提交偏移量**
>
> 要注意，此处的**己提交消息**与之前讨论过的已提交消息是不一样的，它是指已经被写入所有同步副本并且对消费者可见的消息，而**己提交偏移量**是指消费者发送给Kafka 的偏移量，用于确认它已经收到并处理好的消息位置。

​	我们在第4 章已经详细介绍了消费者API的使用，还介绍了多种提交偏移量的方式。下面会介绍一些关键的注意事项，如果要了解消费者API的使用细节，请参考第4章。

### 6.5.1 消费者的可靠性配置

​	为了保证消费者行为的可靠性，需要注意以下4个非常重要的配置参数。

​	第1个是group.id 。这个参数在第4 章已经详细解释过了，如果两个消费者具有相同的group.id，井且订阅了同一个主题，那么每个消费者会分到主题分区的一个子集， 也就是说它们只能读到所有消息的一个子集（不过群组会读取主题所有的消息）。如果你希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的group.id。

​	第2个是auto.offset.reset。这个参数指定了在没有偏移量可提交时（比如消费者第1次启动时）或者请求的偏移量在broker 上不存在时（第4 章已经解释过这种场景），消费者会做些什么。这个参数有两种配置。一种是earliest，如果选择了这种配置，消费者会从分区的开始位置读取数据，不管偏移量是否有效，这样会导致消费者读取大量的重复数据，但可以保证最少的数据丢失。一种是latest，如果选择了这种配置， 消费者会从分区的末尾开始读取数据，这样可以减少重复处理消息，但很有可能会错过一些消息。

​	第3个是enable.auto.commit。这是一个非常重要的配置参数，你可以让消费者基于任务调度自动提交偏移量，也可以在代码里手动提交偏移量。自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题。如果你在消费者轮询操作里处理所有的数据，那么自动提交可以保证只提交已经处理过的偏移量（如果忘了消费者轮询是什么，请回顾一下第4 章的内容）。<u>自动提交的主要缺点是，无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另外一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量</u>。

​	第4个配置参数auto.commit.interval.ms与第3个参数有直接的联系。如果选择了自动提交偏移盘，可以通过该参数配置提交的频度， 默认值是每5秒钟提交一次。一般来说，频繁提交会增加额外的开销，但也会降低重复处理消息的概率。

### 6.5.2 显式提交偏移量

​	这里我们不再重复说明这个机制以及如何使用相关的API ，因为第4 章里已经有很详细的介绍。相反，我们会着重说明几个在开发具有可靠性的消费者应用程序时需要注意的事项。我们先从简单的开始，再逐步深入。

1. 总是在处理完事件后再提交偏移量

   如果所有的处理都是在轮询里完成，并且不需要在轮询之间维护状态（比如为了实现聚合操作）， 那么可以使用自动提交，或者在轮询结束时进行手动提交。

2. 提交频度是性能和重复消息数量之间的权衡

   即使是在最简单的场景里，比如所有的处理都在轮询里完成，井且不需要在轮询之间维护状态，你仍然可以在一个循环里多次提交偏移量（甚至可以在每处理完一个事件之后），或者多个循环里只提交一次（与生产者的acks=all 配置有点类似），这完全取决于你在性能和重复处理消息之间作出的权衡。

3. 确保对提交的偏移量心里有数

   在轮询过程中提交偏移量有一个不好的地方，就是提交的偏移量有可能是读取到的最新偏移量，而不是处理过的最新偏移量。**要记住，在处理完消息后再提交偏移量是非常关键的否则会导致消费者错过消息**。我们已经在第4 章给出了示例。

4. **再均衡**

   在设计应用程序时要注意处理消费者的再均衡问题。我们在第4 章举了几个例子， 一般要在分区被撤销之前提交偏移量，井在分配到新分区时清理之前的状态。

5. 消费者可能需要重试

   有时候，在进行轮询之后，有些消息不会被完全处理，你想稍后再来处理。例如，假设要把Kafka 的数据写到数据库里，不过那个时候数据库不可用，于是你想稍后重试。要注意，你提交的是偏移量，而不是对消息的“确认”，这个与传统的发布和订阅消息系统不太一样。如果记录的#30处理失败，但记录的#31处理成功，那么你不应该提交#31， 否则导致的#31以内的偏移量都被提交，包括的#30在内，而这可能不是你想看到的结果。不过可以采用以下两种模式来解决这个问题。

   第一种模式，在遇到可重试错误时，提交最后一个处理成功的偏移量，然后把还没有处理好的消息保存到缓冲区里（这样下一个轮询就不会把它们覆盖掉），调<u>用消费者的`pause()`方法来确保其他的轮询不会返回数据（不需要担心在重试时缓冲区溢出），在保持轮询的同时尝试重新处理（关于为什么不能停止轮询，请参考第4 章）。如果重试成功，或者重试次数达到上限井决定放弃，那么把错误记录下来井丢弃消息，然后调用`resume()`方法让消费者继续从轮询里获取新数据</u>。

   第二种模式，在遇到可重试错误时，把错误写入一个独立的主题，然后继续。一个独立的消费者群组负责从该主题上读取错误消息，井进行重试，或者使用其中的一个消费者同时从该主题上读取错误消息并进行重试，<u>不过在重试时需要暂停该主题。这种模式有点像其他消息系统里的dead-letter-queue</u>。

6. 消费者可能需要维护状态

   有时候你希望在多个轮询之间维护状态，例如，你想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果。如果进程重启，你不仅需要从上一个偏移量开始处理数据，还要恢复移动平均数。有一种办怯是在提交偏移量的同时把最近计算的平均数写到一个“结果”主题上。消费者线程在重新启动之后，它就可以拿到最近的平均数并接着计算。不过这并不能完全地解决问题，因为Kafka 并没有提供事务支持。消费者有可能在写入平均数之后来不及提交偏移量就崩溃了，或者反过来也一样。这是一个很复杂的问题，你不应该尝试自己去解决这个问题，建议尝试一下KafkfaStreams 这个类库，它为聚合、连接、时间窗和其他复杂的分析提供了高级的DSL API 。

7. 长时间处理

   有时候处理数据需要很长时间：你可能会从发生阻塞的外部系统获取信息，或者把数据写到外部系统，或者进行一个非常复杂的计算。**要记住，暂停轮询的时间不能超过几秒钟。即使不想获取更多的数据，也要保持轮询，这样客户端才能往broker 发送心跳**。在这种情况下， 一种常见的做法是使用一个线程地来处理数据，因为使用多个线程可以进行并行处理，从而加快处理速度。在把数据移交给线程地去处理之后，你就可以暂停消费者，然后保持轮询，但不获取新数据，直到工作线程处理完成。在工作线程处理完成之后，可以让消费者继续获取新数据。因为消费者一直保持轮询，心跳会正常发送，就不会发生再均衡。

8. **仅一次传递**

   有些应用程序不仅仅需要“至少一次”（at-least-once）语义（意味着没有数据丢失），还需要“仅一次”（exactly-once）语义。尽管Kafka 现在还不能完全支持仅一次语义，消费者还是有一些办越可以保证Kafka 里的每个消息只被写到外部系统一次（但不会处理向Kafka 写入数据时可能出现的重复数据） 。

   <u>实现仅一次处理最简单且最常用的办能是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ElasticSearch 或其他数据存储引擎</u>。在这种情况下，要么消息本身包含一个唯一键（通常都是这样），要么使用主题、分区和偏移量的组合来创建唯一键一一它们的组合可以唯一标识一个Kafka 记录。如果你把消息和一个唯一键写入系统，然后碰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可。数据存储引擎会覆盖已经存在的键值对，就像没有出现过重复数据一样。这个模式被叫作**幂等性**写入，它是一种很常见也很有用的模式。

   如果写入消息的系统支持事务， 那么就可以使用另一种方法。最简单的是使用关系型数据库，不过HDFS 里有一些被重新定义过的原子操作也经常用来达到相同的目的。我们把消息和偏移量放在同一个事务里，这样它们就能保持同步。在消费者启动时，它会获取最近处理过的消息偏移量，然后调用seek()方法从该偏移量位置继续读取数据。我们在第4章已经介绍了一个相关的例子。

## 6.6 验证系统可靠性

​	你经过了所有的流程，从确认可靠性需求，到配置broker ，再到配置客户端，并小心谨慎地使用AP......现在可以把所有东西都放到生产环境里去运行，然后高枕无忧，自信不丢失任何消息了，对吗？

​	你当然可以这么做，不过建议还是先对系统可靠性做一些验证。我们建议做3个层面的验证一一配置验证、应用程序验证以及生产环境的应用程序监控。让我们来看看每一步都要做些什么以及该怎么做。

### * 6.6.1 配置验证

​	从应用程序里可以很容易对broker 和客户端配置进行验证，我们之所以建议这么做，有以下两方面的原因。

+ 验证配置是否满足你的需求。

+ 帮助你理解系统的行为，了解系统的真正行为是什么，了解你对Kafka 基本准则的理解是否存在偏差，然后加以改进，同时了解这些准则是如何被应用到各种场景里的。这一章的内容偏重理论，所以要确保你能够理解这些理论是如何运用于实际当中的。

​	Kafka 提供了两个重要的工具用于验证配置： org.apache.kafka.tools包里的VerifiableProducer和VerifiableConsumer这两个类。我们可以从命令行运行这两个类，或者把它们嵌入到自动化测试框架里。

​	其思想是，VerifiableProducer生成一系列消息，这些消息包含从1到你指定的某个数字。你可以使用与生产者相同的方式来配置VerifiableProducer，比如配置相同的acks、重试次数和消息生成速度。在运行VerifiableProducer时，它会把每个消息是否成功发送到broker的结果打印出来。VerifiableConsumer执行的是另一个检查一一它读取事件（由VerifiableProducer生成）井按顺序打印出这些事件。它也会打印出已提交的偏移量和再均衡的相关信息。

​	你可以考虑运行以下一些测试。

+ 首领选举：如果我停掉首领会发生什么事情？生产者和消费者重新恢复正常状态需要多长时间？

+ 控制器选举： 重启控制器后系统需要多少时间来恢复状态？
+ 依次重启：可以依次重启broker 而不丢失任何数据吗？

+ 不完全首领选举测试：如果依次停止所有副本（确保每个副本都变为不同步的），然后启动一个不同步的broker 会发生什么？要怎样恢复正常？这样做是可接受的吗？

​	然后你从中选择一个场景，启动VerifiableProducer和VerifiableConsumer并开始测试这个场景，例如，停掉正在接收消息的分区首领。如果期望在一个短暂的暂停之后状态恢复正常并且没有任何数据丢失，那么只要确保生产者生成的数据个数与消费者读取的数据个数是匹配的就可以了。

​	Kafka 的代码库里包含了大量测试用例。它们大部分都遵循相同的准则一一使用VerifiableProducer和VerifiableConsumer来确保迭代的版本能够正常工作。

### 6.6.2 应用程序验证

​	在确定broker 和客户端的配置可以满足你的需求之后，接下来要验证应用程序是否能够保证达到你的期望。应用程序的验证包括检查自定义的错误处理代码、偏移量提交的方式、再均衡监听器以及其他使用了Kafka 客户端的地方。

​	因为应用程序是你自己的， 关于如何测试应用程序的逻辑，我们无怯提供更多的指导， 但愿你的开发流程里已经包含了集成测试。不管如何验证你的应用程序，我们都建议基于如下的故障条件做一些测试：

+ 客户端从服务器断开连接（系统管理员可以帮忙模拟网络故障）

+ 首领选举

+ 依次重启broker
+ 依次重启消费者
+ 依次重启生产者

​	你对每一个测试场景都会有**期望的行为**，也就是在开发应用程序时所期望看到的行为，然后运行测试看看真实的结果是否符合预期。例如，在测试“依次重启消费者”这一场景时，你期望看到“在短暂的再均衡之后出现的重复消息个数不超过1000 个”。测试结果会告诉我们应用程序提交偏移量的方式和处理再均衡的方式是否与预期的一样。

### 6.6.3 在生产环境监控可靠性

​	测试应用程序是很重要的，不过它无法代替生产环境的持续监控，这些监控是为了确保数据按照期望的方式流动。我们将会在第9 章详细介绍如何监控Kafka 集群，不过除了监控集群的健康状况之外，监控客户端和数据流也是很重要的。

​	首先， Kafka 的Java 客户端包含了JMX 度量指标，这些指标可以用于监控客户端的状态和事件。对于生产者来说，最重要的两个可靠性指标是消息的error-rate和retry-rate（聚合过的）。如果这两个指标上升，说明系统出现了问题。除此以外，还要监控生产者日志一一发送消息的错误日志被设为WARN 级别，可以在“Got error produce response with correlation id 5689 on topic-partition [topic-1,3], retrying (two attempts left). Error : ... ”中找到它们。如果你看到消息剩余的重试次数为0 ， 说明生产者已经没有多余的重试机会。就像我们在6.4 节所讨论的那样，你也许可以增加重试次数，或者把造成这个错误的问题先解决掉。

​	对于消费者来说，最重要的指标是consumer-lag ，该指标表明了消费者的处理速度与最近提交到分区里的偏移量之间还有多少差距。理想情况下，该指标总是为0 ，消费者总能读到最新的消息。不过在实际当中，因为poll()方法会返回很多消息，消费者在获取更多数据之前需要花一些时间来处理它们，所以该指标会有些波动。关键是要确保消费者最终会赶上去，而不是越落越远。因为该指标会正常波动，所以在告警系统里配置该指标有一定难度。Burrow 是Linkedln 公司开发的一个consumer-lag检测工具，它可以让这件事情变得容易一些。

​	监控数据流是为了确保所有生成的数据会被及时地读取（你的需求决定了“及时”的具体含义）。为了确保数据能够被及时读取，你需要知道数据是什么时候生成的。0.10.0 版本的Kafka 在消息里增加了时间戳，表明了消息的生成时间。如果你使用的是更早版本的客户端，我们建议自己在消息里加入时间戳、应用程序的名字和机器名，这样有助于将来诊断问题。

​	为了确保所有消息能够在合理的时间内被读取，应用程序需要记录生成消息的数量（ 一般用每秒多少个消息来表示），而消费者需要记录已读取消息的数量（ 也用每秒多少个消息来表示） 以及消息生成时间（生成消息的时间）到当前时间（读取消息的时间）之间的时间差。然后，你需要使用工具来比较生产者和消费者记录的消息数量（为了确保没有丢失消息），确保这两者之间的时间差不会超出我们允许的范围。为了做到更好的监控， 我们可以增加一个“监控消费者”，这个消费者订阅一个特别的主题，它只进行消息的计数操作，井把数值与生成的消息、数量进行对比，这样我们就可以在没有消费者的情况下仍然能够准确地监控生产者。这种端到端的监控系统实现起来很耗费时间， 具有一定挑战性。据我们所知，目前还没有开源的实现。Confluent 提供了一个商业的实现版本，它是Confluent Control Center 的一部分。

## 6.7 总结

​	正如我们在本章开头所说的，可靠性并不只是Kafka单方面的事情。我们应该从整个系统层面来考虑可靠性问题，包括应用程序的架构、生产者和消费者API的使用方式、生产者和消费者的配置、主题的配置以及broker的配置。系统的可靠性需要在许多方面作出权衡，比如复杂性、性能、可用性和磁盘空间的使用。掌握Kafka的各种配置和常用模式，对使用场景的需求做到心中有数，你就可以在应用程序和Kafka的可靠性程度以及各种权衡之间作出更好的选择。
