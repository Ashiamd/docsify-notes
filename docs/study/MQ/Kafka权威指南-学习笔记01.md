# Kafka权威指南-学习笔记01

# 1. 初识Kafka

## 1. 1 发布与订阅消息系统

### 1 .1 .1 如何开始

### 1.1.2 独立的队列系统

## 1.2 Kafka 登场

### 1.2.1 消息和批次

+ Kafka 的数据单元被称为**消息**
+ 为了提高效率，消息被分批次写入Kafka 。**批次**就是一组消息，这些消息属于同一个主题和分区

### 1.2.2 模式

​	对于Kafka 来说，消息不过是晦涩难懂的字节数组，所以有人建议用一些额外的结构来定义消息内容，让它们更易于理解。根据应用程序的需求，消息**模式**（ schema ）有许多可用的选项（JSON、XML、proto、Avro等）。

### * 1.2.3 主题和分区

​	Kafka 的消息通过**主题**进行分类。主题就好比数据库的表，或者文件系统里的文件夹。主题可以被分为若干个**分区**， 一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。<u>要注意，由于一个主题一般包含几个分区，因此**无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序**</u>。

​	图1-5 所示的主题有4个分区，消息被迫加写入<u>每个分区</u>的尾部。Kafka 通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说， 一个主题可以横跨多个服务器，以此来提供比单个服务器更强大的性能。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a4299ce6a~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1- 5：包含多个分区的主题表示

### * 1.2.4 生产者和消费者

​	<u>Kafka 的客户端</u>就是Kafka系统的用户，它们被分为两种基本类型：**生产者**和**消费者**。除此之外，还有其他高级客户端API —— 用于数据集成的Kafka Connect API 和用于流式处理的Kafka Streams 。这些高级客户端API使用生产者和消费者作为内部组件，提供了高级的功能。

+ **生产者**创建消息。在其他发布与订阅系统中，生产者可能被称为<u>发布者</u>或<u>写入者</u>。一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。第3章将详细介绍生产者。

+ **消费者**读取消息。在其他发布与订阅系统中，消费者可能被称为<u>订阅者</u>或<u>读者</u>。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。<u>消费者通过检查消息的偏移盘来区分已经读取过的消息</u>。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时， Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。<u>消费者把每个分区最后读取的消息偏移量保存在Zookeeper 或Kafka 上，如果消费者关闭或重启，它的读取状态不会丢失</u>。

​	消费者是**消费者群组**的一部分，也就是说，会有一个或多个消费者共同读取一个主题。<u>**群组保证每个分区只能被一个消费者使用**</u>。图1-6 所示的群组中，有3 个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。<u>消费者与分区之间的映射通常被称为消费者对分区的所有权关系</u>。

​	**通过这种方式，消费者可以消费包含大量消息的主题。而且，如果一个消费者失效，群组里的其他消费者可以接管失效消费者的工作**。第4章将详细介绍消费者和悄费者群组。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a4233c775~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1-6 ：消费者群组从主题读取消息

### * 1.2.5 broker和集群

​	**一个独立的<u>Kafka 服务器</u>被称为broker**。

+ broker接收来自生产者的消息，**为消息设置偏移量**，并提交消息到磁盘保存。
+ broker为消费者提供服务，对读取<u>分区</u>的请求作出响应，返回已经提交到磁盘上的消息。

​	<u>根据特定的硬件及其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级的消息量</u>。

​	broker 是**集群**的组成部分。<u>每个集群都有一个broker 同时充当了**集群控制器**的角色（自动从集群的活跃成员中选举出来）。**控制器负责管理工作，包括将分区分配给broker 和监控broker**</u>。

​	<u>在集群中， 一个分区从属于一个broker，该broker 被称为分区的**首领**</u>。

​	**一个分区可以分配给多个broker**，这个时候会发生**分区复制**（见图1-7）。**这种复制机制为分区提供了消息冗余，如果有一个broker 失效，其他broker 可以接管领导权。不过，<u>相关的消费者和生产者都要重新连接到新的首领</u>**。第6章将详细介绍集群的操作，包括分区复制。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/22/16add12a43368941~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图1-7 ：集群里的分区复制

​	**保留消息**（在一定期限内）是Kafka 的一个重要特性。

​	Kafka broker 默认的消息保留策略是这样的：

+ 要么保留一段时间（比如7 天）
+ 要么保留到消息达到一定大小的字节数（比如1GB ）。当消息数量达到这些上限时，旧消息就会过期井被删除。

​	所以在任何时刻， 可用消息的总量都不会超过配置参数所指定的大小。<u>主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止</u>。

​	例如，用于跟踪用户活动的数据可能需要保留几天，而应用程序的度量指标可能只需要保留几个小时。可以通过配置把主题当作**紧凑型日志**， 只有最后一个带有特定键的消息会被保留下来。这种情况对于变更日志类型的数据来说比较适用，因为人们只关心最后时刻发生的那个变更。

### * 1.2.6 多集群

​	随着Kafka 部署数量的增加，基于以下几点原因，最好使用多个集群。

+ 数据类型分离

+ 安全需求隔离

+ 多数据中心（灾难恢复）

​	**如果使用多个数据中心，就需要在它们之间复制消息**。这样，在线应用程序才可以访问到多个站点的用户活动信息。*例如，如果一个用户修改了他们的资料信息，不管从哪个数据中心都应该能看到这些改动。或者多个站点的监控数据可以被聚集到一个部署了分析程序和告警系统的中心位置*。不过， **<u>Kafka的消息复制机制只能在单个集群里进行，不能在多个集群之间进行</u>**。

​	Kafka 提供了一个叫作MirrorMaker 的工具，可以用它来实现集群间的消息复制。<u>MirrorMaker的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连</u>。**消费者从一个集群读取消息，生产者把消息发送到另一个集群上**。

​	![v2-8869847fc733df34a94a54d4d9076ee5_b.jpg](https://img-blog.csdnimg.cn/img_convert/e1e93adef38fa5a0084cb6e0b34d21e7.png)

​	图1-8 ： 多数据中的架构

​	图1-8 展示了一个使用MirrorMaker 的例子，两个“本地”集群的消息被聚集到一个“聚合”集群上，然后将该集群复制到其他数据中心。不过，这种方式在创建复杂的数据管道方面显得有点力不从心。第7章将详细讨论这些案例。

## 1.3 为什么选择Kafka

### 1.3.1 多个生产者

​	<u>Kafka可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题</u>。所以它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。例如， 一个包含了多个微服务的网站，可以为页面视图创建一个单独的主题，所有服务都以相同的消息格式向该主题写入数据。消费者应用程序会获得统一的页面视图，而无需协调来自不同生产者的数据流。

### * 1.3.2 多个消费者

​	<u>除了支持多个生产者外， Kafka 也支持多个消费者从一个单独的消息流上读取数据，而且**消费者之间互不影响**</u>。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。**另外，多个消费者可以组成一个群组，它们共享一个消息流，并<u>保证整个群组对每个给定的消息只处理一次</u>**。

### 1.3. 3 基于磁盘的数据存储

​	Kafka 不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于Kafka 的数据保留特性。消息被提交到磁盘，根据设置的保留规则进行保存。**每个主题可以设置单独的保留规则**，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息，而持久化数据可以保证数据不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。<u>消费者可以被关闭，但消息会继续保留在Kafka 里。消费者可以从上次中断的地方继续处理消息</u>。

### 1.3.4 伸缩性

​	为了能够轻松处理大量数据， Kafka 从一开始就被设计成一个具有灵活伸缩性的系统。用户在开发阶段可以先使用单个broker ，再扩展到包含3个broker 的小型开发集群，然后随着数据量不断增长，部署到生产环境的集群可能包含上百个broker 。<u>对在线集群进行扩展丝毫不影响整体系统的可用性。也就是说， 一个包含多个broker 的集群，即使个别broker失效，仍然可以持续地为客户提供服务</u>。<u>要提高集群的容错能力，需要配置较高的复制系数</u>。第6章将讨论关于复制的更多细节。

### 1.3.5 高性能

​	上面提到的所有特性，让Kafka 成为了一个高性能的**发布与订阅消息**系统。通过横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的消息流。在处理大量数据的同时，它还能保证**亚秒级**的消息延迟。

## 1.4 数据生态系统

​	Kafka 为数据生态系统带来了循环系统，如图1-9 所示。它在基础设施的各个组件之间传递消息，为所有客户端提供一致的接口。<u>当与提供消息模式的系统集成时，生产者和消费者之间不再有紧密的祸合，也**不需要在它们之间建立任何类型的直连**</u>。我们可以根据业务需要添加或移除组件．因为生产者不再关心谁在使用数据，也不关心有多少个消费者。

![v2-90d0e87bef7b3732cfd70a8c78710e95_b.jpg](https://img-blog.csdnimg.cn/img_convert/14b915f52caadd0f56ff37357dbce671.png)

​	圄1-9 ：大数据生态系统

​	使用场景：

1. 活动跟踪

2. 传递消息
3. 度量指标和日志记录
4. 提交日志
5. 流处理

## 1.5 起源故事

​	Kafka 是为了解决Linkedln数据管道问题应运而生的。<u>它的设计目的是提供一个高性能的消息系统，可以处理多种数据类型，并能够实时提供纯净且结构化的用户活动数据和系统度量指标</u>。

### 1.5.1 Linkedln的问题

​	最开始，我们调研了一些现成的开源解决方案，希望能够找到一个系统，可以实时访问数据，并通过横向扩展来处理大量的悄息。我们使用ActiveMQ 创建了一个原型系统，但它当时还无能满足横向扩展的需求。Linkedln 不得不使用这种脆弱的解决方案， 虽然ActiveMQ 有很多触陷会导致broker 暂停服务。客户端的连接因此被阻塞，处理用户请求的能力也受到影响。于是我们最后决定构建自己的基础设施。

### 1.5.2 Kafka 的诞生

​	Linkedln 的开发团队由Jay Kreps 领导。Jay Kreps 是Linkedln 的首席工程师，之前负责分布式键值存储系统Voldemort的开发。初建团队成员还包括Neha Narkhede ，不久之后，Jun Rao 也加入了进来。他们一起着手创建一个消息系统，可以同时满足上述的两种需求，并且可以在未来进行横向扩展。他们的主要目标如下：

+ 使用推送和拉取模型解耦生产者和消费者

+ 为消息传递系统中的消息提供数据持久化，以便支持多个消费者
+ 通过系统优化实现高吞吐量
+ 系统可以随着数据流的增长进行横向扩展

​	最后我们看到的这个发布与订阅消息系统具有典型的消息系统接口，但从存储层来看，它更像是一个日志聚合系统。Kafka 使用Avro作为消息序列化框架，每天高效地处理数十亿级别的度量指标和用户活动跟踪信息。Linkedln已经拥有超过万亿级别的消息使用量（截止到2015 年8 月），而且每天仍然需要处理超过千万亿字节的数据。

### 1.5.3 走向开源

​	2010 年底， Kafka 作为开源项目在GitHub 上发布。2011年7月，因为倍受开源社区的关注，它成为Apache软件基金会的孵化器项目。2012年10 月， Kafka 从孵化器项目毕业。	

### 1.5.4 命名

## 1.6 开始Kafka之旅

## 2. 安装Kafka

## 2.1 要事先行

### 2.1.1 选择操作系统

### 2.1.2 安装Java

​	在安装Zookeeper和Kafka之前，需要先安装Java环境。

### 2.1.3 安装Zookeeper

​	**Kafka 使用Zookeeper 保存集群的元数据信息和消费者信息**。Kafka 发行版自带了Zookeeper ，可以直接从脚本启动，不过安装一个完整版的Zookeeper 也并不费劲。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019112413373216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly94aWFvY2hlbmd4aW55aXpoYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)

图2-1 : Kafka 和Zookeeper

## 2.2 安装Kafka Broker

## 2.3 broker配置

### 2.3.1 常规配置

​	有一些配置选项，在单机安装时可以直接使用默认值，但在部署到其他环境时要格外小心。这些参数是单个服务器最基本的配置，它们中的大部分需要经过修改后才能用在集群里。

1. broker.id

   每个broker 都需要有一个标识符，使用broker.id 来表示。它的默认值是0 ，也可以被设置成其他任意整数。**这个值在整个Kafka 集群里必须是唯一的**。这个值可以任意选定，如果出于维护的需要，可以在服务器节点间交换使用这些ID 。建议把它们设置成与机器名具有相关性的整数，这样在进行维护时，将ID 号映射到机器名就没那么麻烦了。例如，如果机器名包含唯一性的数字（比如hostl . example.com 、host2.example.com），那么用这些数字来设置broker.id 就再好不过了。

2. port

   如果使用配置样本来启动Kafka ，它会监听9092 端口。修改port配置参数可以把它设置成其他任意可用的端口。要注意，如果使用1024以下的端口，需要使用root权限启动Kafka ，不过不建议这么做。

3. Zookeeper.connect

   **用于保存broker元数据的Zookeeper 地址是通过zookeeper.connect 来指定的**。`localhost:2181`表示这个Zookeeper 是运行在本地的2181端口上。该配置参数是用冒号分隔的一组`hostname:port/path`列表，每一部分的含义如下：

   + hostname 是Zookeeper 服务器的机器名或IP 地址

   + port 是Zookeeper 的客户端连接端口

   + /path 是可选的Zookeeper 路径，作为Kafka集群的chroot 环境。如果不指定，默认使用根路径。

   如果指定的chroot路径不存在， broker 会在启动的时候创建它。

   > 为什么使用chroot路径
   >
   > 在Kafka 集群里使用chroot 路径是一种最佳实践。Zookeeper 群组可以共享给其他应用程序，即使还有其他Kafka集群存在， 也不会产生冲突。最好是在配置文件里指定一组Zookeeper服务器，用分号把它们隔开。一旦有一个Zookeeper 服务器岩机， broker可以连接到Zookeeper群组的另一个节点上。

4. log.dirs

   **Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过log.dirs指定的**。它是一组用逗号分隔的本地文件系统路径。<u>如果指定了多个路径，那么broker 会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下</u>。要注意， broker 会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。

5. num.recovery.threads.per.data.dir

   对于如下3种情况， Kafka 会使用可配置的线程池来处理日志片段：

   + 服务器正常启动，用于打开每个分区的日志片段

   + 服务器崩愤后重启，用于检查和截短每个分区的日志片段
   + 服务器正常关闭，用于关闭日志片段

   <u>默认情况下，每个日志目录只使用一个线程</u>。因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程来达到井行操作的目的。特别是对于包含大量分区的服务器来说， 一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。设此参数时需要注意，所配置的数字对应的是log.dirs指定的单个日志目录。也就是说，如果num.recovery.threads.per.data.dir被设为8 ， 井且log.dir指定了3 个路径，那么总共需要24 个线程。

6. auto.create.topics.enable

   默认情况下， Kafka 会在如下几种情形下<u>自动创建主题</u>：

   + 当一个生产者开始往主题写入消息时

   + 当一个消费者开始从主题读取消息时

   + 当任意一个客户端向主题发送元数据请求时。

   很多时候，这些行为都是非预期的。而且，根据Kafka协议，如果一个主题不先被创建，根本无法知道它是否已经存在。如果显式地创建主题， 不管是手动创建还是通过其他配置系统来创建，都可以把auto.create.topics.enable设为false 。

### * 2.3.2 主题的默认配置

​	Kafka 为新创建的主题提供了很多默认配置参数。可以通过管理工具（将在第9 章介绍）为每个主题单独配置一部分参数，比如分区个数和数据保留策略。服务器提供的默认配置可以作为基准，它们适用于大部分主题。

> 使用主题配置覆盖（override)
>
> 之前的Kafka 版本允许主题覆盖服务器的默认配置，包括log.retention.hours.per.topic 、log.retention.bytes.per.topic和log.segment.bytes.per.topic 这几个参数。新版本不再支持这些参数，而且如果要对参数进行覆盖，需要使用管理工具。

1. num.paritions

   num.paritions参数指定了新创建的主题将包含多少个分区。如果启用了主题自动创建功能（该功能默认是启用的），主题分区的个数就是该参数指定的值。该参数的默认值是1。**要注意，我们可以增加主题分区的个数，但不能减少分区的个数**。所以，如果要让一个主题的分区个数少于num.partitions指定的值，需要手动创建该主题（将在第9章讨论）。

   第1章里已经提到， Kafka集群通过分区对主题进行横向扩展，所以当有新的broker 加入集群时，可以通过分区个数来实现集群的负载均衡。当然，这并不是说，在存在多个主题的情况下（它们分布在多个broker上），为了能让分区分布到所有broker上， 主题分区的个数必须要大于broker的个数。不过，<u>拥有大量消息的主题如果要进行负载分散，就需要大量的分区</u>。

   > 如何选定分区数量
   >
   > 为主题选定分区数量并不是一件可有可无的事情，在进行数量选择时，需要考虑如下几个因素。
   >
   > + 主题需要达到多大的吞吐量？例如，是希望每秒钟写入100KB 还是1GB?
   >
   > + 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果你知道消费者将数据写入数据库的速度不会超过每秒50MB ，那么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒50MB 。
   >
   > + 可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。
   >
   > + 每个broker 包含的分区个数、可用的磁盘空间和网络带宽。
   >
   > + <u>如果消息是按照不同的键来写入分区的，那么为已有的主题新增分区就会很困难</u>。
   >
   > + **单个broker 对分区个数是有限制的，因为分区越多，占用的内存越多，完成首领选举需要的时间也越长**。

   很显然，综合考虑以上几个因素，你需要很多分区，但不能太多。**如果你估算出主题的吞吐量和消费者吞吐量，可以用主题吞吐量除以消费者吞吐量算出分区的个数**。也就是说，如果每秒钟要从主题上写入和读取1GB 的数据，并且每个消费者每秒钟可以处理50MB的数据，那么至少需要20个分区。这样就可以让20 个消费者同时读取这些分区，从而达到每秒钟1GB 的吞吐量。

   如果不知道这些信息，那么<u>根据经验，把分区的大小限制在25GB以内可以得到比较理想的效果</u>。

2. log.retention.ms

   **Kafka 通常根据时间来决定数据可以被保留多久。默认使用log.retention.ms参数来配置时间，默认值为168小时，也就是一周**。除此以外，还有其他两个参数log.retention.minutes和log.retention.ms。这3个参数的作用是一样的，都是决定消息多久以后会被删除，不过还是推荐使用log.retention.ms。<u>如果指定了不止一个参数， Kafka会优先使用具有最小值的那个参数。</u>

   > 根据时间保留数据和最后修改时间
   >
   > **根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的**。<u>一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里最后一个消息的时间戳。不过，如果使用管理工具在服务器间移动分区，最后修改时间就不准确了</u>。时间误差可能导致这些分区过多地保留数据。在第9章讨论分区移动时会提到更多这方面的内容。

3. log.retention.bytes

   另一种方式是通过保留的消息字节数来判断消息是否过期。它的值通过参数log.retention.bytes来指定，**作用在每一个分区上**。也就是说，如果有一个包含8个分区的主题，井且log.retention.bytes被设为1GB ，那么这个主题最多可以保留8GB 的数据。所以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。

   > 根据字节大小和时间保留数据
   >
   > **如果同时指定了log.retention.bytes和log.retention.ms（或者另一个时间参数），只要任意一个条件得到满足，消息就会被删除**。例如，假设log.retention.ms设置为86 400 000 （也就是1 天），log.retention.bytes设置为1 000 000 000 （也就是1GB ），如果消息字节总数在不到一天的时间就超过了1GB ，那么<u>多出来的部分就会被删除</u>。相反，如果消息字节总数小于1GB ，那么一天之后这些消息也会被删除，尽管分区的数据总量小于1GB 。

4. log.segment.bytes

   **以上的设置都作用在日志片段上，而不是作用在单个消息上**。当消息到达broker 时，它们被迫加到分区的当前日志片段上。当日志片段大小达到log.segment.bytes指定的上限（默认是1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。<u>如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率</u>。

   如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。例如，如果一个主题每天只接收100MB 的消息，而log.retention.ms使用默认设置，那么需要10天时间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果log.retention.ms被设为604 800 000 （ 也就是1 周），那么日志片段最多需要17 天才会过期。<u>这是因为关闭日志片段需要10 天的时间，而根据配置的过期时间，还需要再保留7 天时间（要等到日志片段里的最后一个消息过期才能被删除）</u> 。

   > 使用时间戳获取偏移量
   >
   > 日志片段的大小会影响使用时间戳获取偏移量。在使用时间戳获取日志偏移量时， Kafka 会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小子指定时向戳。然后， Kafka 返回该日志片段（也就是文件名）开头的偏移量。**对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确**。

5. log.segment.ms

   **另一个可以控制日志片段关闭时间的参数是log.segment.ms时，它指定了多长时间之后日志片段会被关闭**。就像log.retention.bytes和log.retention.ms这两个参数一样，log.segment.bytes和log.segment.ms这两个参数之间也不存在互斥问题。日志片段会在大小或时间达到上限时被关闭，就看哪个条件先得到满足。<u>默认情况下，log.segment.ms没有设定值，所以只根据大小来关闭日志片段</u>。

   > 基于时间的日志片段对磁盘性能的影响
   >
   > 在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这种情况，因为broker 在启动之后就开始计算日志片段的过期时间，对于那些数据量小的分区来说，日志片段的关闭操作总是同时发生。

6. message.max.bytes

   **broker 通过设置message.max.bytes参数来限制单个消息的大小，默认值是1 000 000 ，也就是1MB** 。如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到broker 返回的错误信息。<u>跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息大小，也就是说，只要压缩后的消息小于message.max.bytes指定的值，消息的实际大小可以远大于这个值</u>。

   这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响IO吞吐量。

   > 在服务端和客户端之间协调消息大小的配置
   >
   > **消费者客户端设置的fetch.message.max.bytes必须与服务器端设置的消息大小进行协调。<u>如果这个值比message.max.bytes小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。在为集群里的broker 配置fetch.message.max.bytes参数时， 也遵循同样的原则</u>。**

## 2.4 硬件的选择

​	如果比较关注性能，那么就需要考虑几个会影响整体性能的因素：磁盘吞吐量和容量、内存、网络和CPU。

### * 2.4.1 磁盘吞吐量

​	**生产者客户端的性能直接受到服务器端磁盘吞吐量的影响**。<u>生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认悄息已经成功提交为止</u>。也就是说，**磁盘写入速度越快，生成消息的延迟就越低**。

> 在考虑硬盘类型对磁盘吞吐量的影响时，是选择传统的机械硬盘（HDD）还是固态硬盘(SSD），我们可以很容易地作出决定。固态硬盘的查找和访问速度都很快，提供了最好的性能。机械硬盘更便宜， 单块硬盘容量也更大。在同一个服务器上使用多个机械硬盘，可以设置多个数据目录，或者把它们设置成磁盘阵列，这样可以提升机械硬盘的性能。其他方面的因素，比如磁盘特定的技术（串行连接存储技术或SATA ），或者磁盘控制器的质量， 都会影响吞吐量。	

### 2.4.2 磁盘容量

​	磁盘容量是另一个值得讨论的话题。需要多大的磁盘容量取决于需要保留的消息数量。如果服务器每天会收到1TB 消息，并且保留7天，那么就需要7TB 的存储空间，而且还要为其他文件提供至少10%的额外空间。除此之外，还需要提供缓冲区，用于应付消息流量的增长和波动。

​	在决定扩展Kafka集群规模时，存储容量是一个需要考虑的因素。**通过让主题拥有多个分区， 集群的总流量可以被均衡到整个集群，而且如果单个broker无法支撑全部容量，可以让其他broker提供可用的容量**。<u>存储容量的选择同时受到集群复制策略的影响</u>（将在第6章讨论更多的细节） 。

### * 2.4.3 内存

​	除了磁盘性能外，服务器端可用的内存容量是影响客户端性能的主要因素。**磁盘性能影响生产者，而内存影响消费者**。<u>消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。在这种情况下，消费者读取的消息会直接存放在系统的页面缓存里，这比从磁盘上重新读取要快得多</u>。

​	<u>运行Kafka 的JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，或者用来缓存正在使用中的日志片段</u>。这也就是为什么不建议把Kafka 同其他重要的应用程序部署在一起的原因，它们需要共享页面缓存，最终会降低Kafka 消费者的性能。

 ### * 2.4.4 网络

​	**网络吞吐量决定了Kafka 能够处理的最大数据流量**。它和磁盘存储是制约Kafka扩展规模的主要因素。Kafka支持多个消费者，造成流入和流出的网络流量不平衡，从而让情况变得更加复杂。对于给定的主题， 一个生产者可能每秒钟写入1MB 数据，但可能同时有多个消费者瓜分网络流量。其他的操作，如集群复制（在第6章介绍）和镜像（在第8章介绍）也会占用网络流量。<u>如果网络接口出现饱和，那么集群的复制出现延时就在所难免，从而让集群不堪一击</u>。

### 2.4.5 CPU

​	与磁盘和内存相比， **Kafka 对计算处理能力的要求相对较低**，不过它在一定程度上还是会影响整体的性能。<u>**客户端为了优化网络和磁盘空间，会对消息进行压缩。服务器需要对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上**。这就是Kafka 对计算处理能力有所要求的地方</u>。不过不管怎样，这都不应该成为选择硬件的主要考虑因素。

## 2.5 云端的Kafka

## 2.6 Kafka集群

​	单个Kafka 服务器足以满足本地开发或POC 要求，不过集群也有它的强大之处。**使用集群最大的好处是可以跨服务器进行负载均衡，再则就是可以<u>使用复制功能来避免因单点故障造成的数据丢失</u>**。在维护Kafka 或底层系统时，使用集群可以确保为客户端提供高可用性。本节只是介绍如何配置Kafka 集群，第6章将介绍更多关于数据复制的内容。

![img](http://www.ituring.com.cn/figures/2017/Kafka/013.png)

### * 2.6.1 需要多少个broker

​	一个Kafka 集群需要多少个broker 取决于以下几个因素。首先，需要多少<u>磁盘空间</u>来保留数据，以及单个broker 有多少空间可用。如果整个集群需要保留10TB 的数据， 每个broker 可以存储2TB ，那么至少需要5个broker 。如果启用了数据复制，那么至少还需要一倍的空间，不过这要取决于配置的复制系数是多少（将在第6 章介绍）。也就是说，如果启用了数据复制，那么这个集群至少需要10 个broker 。

​	第二个要考虑的因素是集群处理请求的能力。这通常与<u>网络接口处理客户端流量的能力</u>有关，特别是当有多个消费者存在或者在数据保留期间流量发生波动（比如高峰时段的流量爆发）时。如果单个broker的网络接口在高峰时段可以达到80%的使用量，并且有两个消费者，那么消费者就无法保持峰值，除非有两个broker 。如果集群启用了复制功能，则要把这个额外的消费者考虑在内。<u>因磁盘吞吐量低和系统内存不足造成的性能问题，也可以通过扩展多个broker来解决</u>。

### 2.6.2 broker配置

​	要把一个broker 加入到集群里，只需要修改两个配置参数。

​	首先，所有broker 都必须配置相同的zookeeper.connect， 该参数指定了用于保存元数据的Zookeeper群组和路径。

​	其次，每个broker 都必须为broker.id参数设置唯一的值。<u>如果两个broker 使用相同的broker.id，那么第二个broker 就无法启动</u>。在运行集群时，还可以配置其他一些参数，特别是那些用于控制数据复制的参数，这些将在后续的章节介绍。

### 2.6.3 操作系统调优

​	大部分Linux发行版默认的内核调优参数配置已经能够满足大多数应用程序的运行需求，不过还是可以通过调整一些参数来进一步提升Kafka的性能。这些参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。这些参数一般配置在`/etc/sysctl.conf`文件里，不过在对内核参数进行调整时，最好参考操作系统的文挡。

1. 虚拟内存

   一般来说， Linux 的虚拟内存会根据系统的工作负荷进行自动调整。我们可以对交换分区的处理方式和内存脏页进行调整，从而让Kafka 更好地处理工作负载。

   **对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换**。内存页和磁盘之间的交换对Kafka 各方面的性能都有重大影响。Kafka大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，说明已经没有多余内存可以分配给页面缓存了。

   <u>一种避免内存交换的方告是不设置任何交换分区。内存交换不是必需的，不过它确实能够在系统发生灾难性错误时提供一些帮助</u>。进行内存交换可以防止操作系统由于内存不足而突然终止进程。基于上述原因，建议把vm.swappiness参数的值设置得小一点，比如1。该参数指明了虚拟机的子系统将如何使用交换分区，而不是只把内存页从页面缓存里移除。要优先考虑减小页面缓存，而不是进行内存交换。

   > 为什么不把vm.swappiness设为零
   >
   > 先前，人们建议尽量把vm.swappiness设为0 ，它意味着“除非发生内存溢出，否则不要进行内存交换”。直到Linux 内核3.5-rc1版本发布，这个值的意义才发生了变化。这个变化被移植到其他的发行版上，包括Red Hat 企业版内核2.6.32-303。在发生变化之后， 0 意味着“在任何情况下都不要发生交换”。所以现在建议把这个值设为1。

   脏页会被冲刷到磁盘上，调整内核对脏页的处理方式可以让我们从中获益。Kafka 依赖I/O性能为生产者提供快速的响应。这就是为什么日志片段一般要保存在快速磁盘上，不管是单个快速磁盘（如SSD）还是具有NVRAM 缓存的磁盘子系统（如RAID）。这样一来，在后台刷新进程将脏页写入磁盘之前，可以减少脏页的数量，这个可以通过将ratio设为小于10 的值来实现。该值指的是系统内存的百分比，大部分情况下设为5 就可以了。它不应该被设为0 ，因为那样会促使内核频繁地刷新页面，从而降低内核为底层设备的磁盘写入提供缓冲的能力。

   通过设置vm.dirty_ratio参数可以增加被内核进程刷新到磁盘之前的脏页数量，可以将它设为大于20 的值（这也是系统内存的百分比）。这个值可设置的范围很广， 60～80 是个比较合理的区间。不过调整这个参数会带来一些风险，包括未刷新磁盘操作的数量和同步刷新引起的长时间I/O等待。<u>如果该参数设置了较高的值，建议启用Kafka的复制功能，避免因系统崩溃造成数据丢失</u>。

   为了给这些参数设置合适的值，最好是在Kafka 集群运行期间检查脏页的数量，不管是在生存环境还是模拟环境。可以在`/proc/vmstat`文件里查看当前脏页数量。

   ```shell
   # cat /proc/vmstat | egrep "dirty|writeback"
   nr_dirty 3875
   nr_writeback 29
   nr_writeback_temp 0
   ```

2. 磁盘

   除了选择合适的磁盘硬件设备和使用RAID外，文件系统是影响性能的另一个重要因素。有很多种文件系统可供选择，不过对于本地文件系统来说，EXT4（第四代可扩展文件系统）和XFS 最为常见。近来，XFS成为很多Linux发行版默认的文件系统，因为它只需要做少量调优就可以承担大部分的工作负荷，比EXT4具有更好的表现。EXT4 也可以做得很好，但需要做更多的调优，存在较大的风险。其中就包括设置更长的提交间隔（默认是5 ），以便降低刷新的频率。<u>EXT4还引入了块分配延迟， 一旦系统崩愤，更容易造成数据丢失和文件系统毁坏。XFS也使用了分配延迟算撞，不过比EXT4的要安全些。XFS为Kafka 提供了更好的性能，除了由文件系统提供的自动调优之外，无需额外的调优。批量磁盘写入具有更高的效率，可以提升整体的I/O吞吐量</u>。

   不管使用哪一种文件系统来存储日志片段，最好要对挂载点的noatime参数进行合理的设置。**<u>文件元数据包含3 个时间戳： 创建时间（ctime）、最后修改时间（mtime）以及最后访问时间（atime）</u>**。**默认情况下，每次文件被读取后都会更新atime ，这会导致大量的磁盘写操作，而且atime属性的用处不大，除非某些应用程序想要知道某个文件在最近一次修改后有没有被访问过（这种情况可以使用realtime）**。<u>Kafka用不到该属性，所以完全可以把它禁用掉。为挂载点设置noatime参数可以防止更新atime ，但不会影响ctime和mtime</u>。

3. 网络

   默认情况下，系统内核没有针对快速的大流量网络传输进行优化， 所以对于应用程序来说，一般需要对Linux 系统的网络技进行调优，以实现对大流量的支持。实际上，调整Kafka 的网络配置与调整其他大部分Web服务器和网络应用程序的网络配置是一样的。首先<u>可以对分配给socket读写缓冲区的内存大小作出调整，这样可以显著提升网络的传输性能</u>。socket 读写缓冲区对应的参数分别是`net.core.wmem_default`和`net.core.rmem_default`，合理的值是131 072 （ 也就是128 KB ）。读写缓冲区最大值对应的参数分别是`net.core.wmem_max`和`net.core.rmem_max`，合理的值是2 097 152 （ 也就是2 MB ）。要注意，最大值井不意味着每个socket 一定要有这么大的缓冲空间，只是说在必要的情况下才会达到这个值。

   除了设置socket 外，还需要设置TCP socket 的读写缓冲区，它们的参数分别是`net.ipv4.tcp_wmem`和`net.ipv4 .tcp_rmem`。这些参数的值由3 个整数组成，它们使用空格分隔，分别表示最小值、默认值和最大值。最大值不能大于`net.core.wmem_max`和`net.core.rmem_max`指定的大小。例如，“4096 65536 204800。”表示最小值是4KB、默认值是64KB、最大值是2MB 。<u>根据Kafka 服务器接收流量的实际情况，可能需要设置更高的最大值，为网络连接提供更大的缓冲空间</u>。

   还有其他一些有用的网络参数。例如， 把`net.ipv4.tcp_window_scaling`设为1 ，启用TCP时间窗扩展，可以提升客户端传输数据的效率，传输的数据可以在服务器端进行缓冲。把`net.ipv4.tcp_max_syn_backlog`设为比默认值1024 更大的值，可以接受更多的井发连接。把`net.core.netdev_max_backlog`设为比默认值1000 更大的值，有助于应对网络流量的爆发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理。

## 2.7 生产环境的注意事项

### 2.7.1 垃圾回收器选项

​	Java7的G1垃圾回收器会自动根据工作负载情况进行自我调节，而且它的停顿时间是恒定的。它可以轻松地处理大块的堆内存，把堆内存分为若干小块的区域，每次停顿时井不会对整个堆空间进行回收。

​	正常情况下， G1 只需要很少的配置就能完成这些工作。以下是G1的两个调整参数。

+ MaxGCPauseMills

  该参数指定每次垃圾回收默认的停顿时间。该值不是固定的， G1可以根据需要使用更长的时间。它的默认值是200ms 。也就是说， <u>G1会决定垃圾回收的频率以及每一轮需要回收多少个区域，这样算下来， 每一轮垃圾回收大概需要200ms 的时间</u>。

+ InitiatingHeapOccupancyPercent

  该参数指定了在G1启动新一轮垃坡回收之前可以使用的堆内存百分比，默认值是45 。也就是况，在堆内存的使用率达到45%之前，G1不会启动垃圾回收。<u>这个百分比包括新生代和老年代的内存</u>。

​	**Kafka 对堆内存的使用率非常高，容易产生垃圾对象，所以可以把这些值设得小一些**。如果一台服务器有 64GB 内存，并且使用 5GB 堆内存来运行 Kafka，那么可以参考以下的配置：`MaxGCPauseMillis` 可以设为 20ms；`InitiatingHeapOccupancyPercent` 可以设为 35，这样可以让垃圾回收比默认的要早一些启动。

​	Kafka 的启动脚本并没有启用 G1 回收器，而是使用了 Parallel New 和 CMS（ Concurrent Mark-Sweep，并发标记和清除）垃圾回收器。不过它可以通过环境变量来修改。本章前面的内容使用 start 命令来修改它：

```shell
# export JAVA_HOME=/usr/java/jdk1.8.0_51
# export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC
-XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35
-XX:+DisableExplicitGC -Djava.awt.headless=true"
# /usr/local/kafka/bin/kafka-server-start.sh -daemon
/usr/local/kafka/config/server.properties
#
```

### 2.7.2 数据中心布局

​	在为broker 增加新的分区时， broker 并无法获知机架的信息。也就是说，两个broker 有可能是在同一个机架上，或者在同一个可用区域里（如果运行在像AWS 这样的的云服务上），所以，在为分区添加副本的时候，这些副本很可能被分配给同一个机架上的broker，它们使用相同的电源和网络连接。如果该机架出了问题，这些分区就会离线，客户端就无挂访问到它们。**更糟糕的是， 如果发生不完整的主节点选举，那么在恢复时就有可能丢失数据（第6 章将介绍更多细节）**。

​	所以，最好把集群的broker 安装在不同的机架上，至少不要让它们共享可能出现单点故障的基础设施，比如电源和网络。也就是说，部署服务器需要至少两个电源连接（两个不罔的回路）和两个网络交换器（保证可以进行无缝的故障切换）。除了这些以外，最好还要把broker 安放在不同的机架上。因为随着时间的推移，机架也需要进行维护，而这会导致机器离线（比如移动机器或者重新连接电源）。

### * 2.7.3 共享Zookeeper

​	**Kafka 使用 Zookeeper 来保存 broker、主题和分区的元数据信息**。<u>对于一个包含多个节点的 Zookeeper 群组来说，Kafka 集群的这些流量并不算多，那些写操作只是用于构造消费者群组或集群本身。实际上，在很多部署环境里，会让多个 Kafka 集群共享一个 Zookeeper 群组（每个集群使用一个 chroot 路径）</u>。

> Kafka消费者和Zookeeper
>
> 在 Kafka 0.9.0.0 版本之前，除了 broker 之外，消费者也会使用 Zookeeper 来保存一些信息，比如消费者群组的信息、主题信息、消费分区的偏移量（在消费者群组里发生失效转移时会用到）。到了 0.9.0.0 版本，Kafka 引入了一个新的消费者接口，<u>允许 broker 直接维护这些信息</u>。这个新的消费者接口将在第 4 章介绍。

​	不过，消费者和 Zookeeper 之间还是有一个值得注意的地方，**消费者可以选择将偏移量提交到 Zookeeper 或 Kafka，还可以选择提交偏移量的时间间隔**。如果消费者将偏移量提交到 Zookeeper，那么在每个提交时间点上，消费者将会为每一个消费的分区往 Zookeeper 写入一次偏移量。<u>合理的提交间隔是 1 分钟，因为这刚好是消费者群组的某个消费者发生失效时能够读取到重复消息的时间</u>。值得注意的是，这些提交对于 Zookeeper 来说流量不算小，特别是当集群里有多个消费者的时候。<u>如果 Zookeeper 群组无法处理太大的流量，就有必要使用长一点的提交时间间隔</u>。**不过不管怎样，还是建议使用最新版本的 Kafka，让消费者把偏移量提交到 Kafka 服务器上，消除对 Zookeeper 的依赖**。

​	**虽然多个 Kafka 集群可以共享一个 Zookeeper 群组，但如果有可能的话，不建议把 Zookeeper 共享给其他应用程序**。<u>Kafka 对 Zookeeper 的延迟和超时比较敏感，与 Zookeeper 群组之间的一个通信异常就可能导致 Kafka 服务器出现无法预测的行为。这样很容易让多个 broker 同时离线，如果它们与 Zookeeper 之间断开连接，也会导致分区离线</u>。这也会给集群控制器带来压力，在服务器离线一段时间之后，当控制器尝试关闭一个服务器时，会表现出一些细小的错误。其他的应用程序因重度使用或进行不恰当的操作给 Zookeeper 群组带来压力，所以最好让它们使用自己的 Zookeeper 群组。

## 2.8 总结

​	在这一章，我们学习了如何运行 Kafka，同时也讨论了如何为 Kafka 选择合适的硬件，以及在生产环境中使用 Kafka 需要注意的事项。有了 Kafka 集群之后，接下来要介绍基本的客户端应用程序。后面两章将介绍如何创建客户端，并用它们向 Kafka 生产消息（第 3 章）以及从 Kafka 读取这些消息（第 4 章）。

# 3. Kafka生产者——向Kafka写入数据

​	不管是把Kafka作为消息队列、消息总线还是数据存储平台来使用，总是需要有一个可以往Kafka 写入数据的生产者和一个可以从Kafka 读取数据的消费者，或者一个<u>兼具两种角色</u>的应用程序。

> 第三方客户端
>
> **除了内置的客户端外， Kafka 还提供了二进制连接协议， 也就是说，我们直接向Kafka网络端口发送适当的字节序列，就可以实现从Kafka 读取消息或往Kafka写入消息**。还有很多用其他语言实现的Kafka客户端，比如C++、Python、Go语言等，它们都实现了Kafka的连接协议，使得Kafka 不仅仅局限于在Java 里使用。这些客户端不属于Kafka 项目，不过Kafka 项目wiki上提供了一个清单，列出了所有可用的客户端。连接协议和第三方客户端超出了本章的讨论范围。

## * 3.1 生产者概览

​	多样的使用场景意味着多样的需求：是否每个消息都很重要？是否允许丢失一小部分消息？偶尔出现重复消息是否可以接受？是否有严格的延迟和吞吐量要求？

​	在之前提到的信用卡事务处理系统里，消息丢失或消息重复是不允许的，可以接受的延迟最大为500ms ，对吞吐量要求较高——我们希望每秒钟可以处理一百万个消息。

​	保存网站的点击信息是另一种使用场景。在这个场景里，允许丢失少量的消息或出现少量的消息重复，延迟可以高一些，只要不影响用户体验就行。换句话说，只要用户点击链接后可以马上加载页面，那么我们并不介意消息要在几秒钟之后才能到达Kafka服务器。吞吐量则取决于网站用户使用网站的频度。

​	不同的使用场景对生产者API 的使用和配置会有直接的影响。

​	尽管生产者API使用起来很简单， 但消息的发送过程还是有点复杂的。图3-1 展示了向Kafka 发送消息的主要步骤。

![img](https://upload-images.jianshu.io/upload_images/8365118-e4a8a315ce0b61bb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1128/format/webp)

​	图3-1：Kafka 生产者组件图

​	我们从创建一个ProducerRecord对象开始，ProducerRecord对象需要包含目标主题和要发送的内容。我们还可以指定键或分区。在发送 ProducerRecord 对象时，<u>生产者要先把键和值对象序列化成字节数组，这样它们才能够在网络上传输</u>。

​	接下来，数据被传给分区器。<u>如果之前在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回</u>。如果没有指定分区，那么分区器会根据ProducerRecord 对象的键来选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条记录了。紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。<u>有一个独立的线程负责把这些记录批次发送到相应的broker上</u>。
​	服务器在收到这些消息时会返回一个响应。**如果消息成功写入 Kafka，就返回一个RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量**。<u>如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息</u>。

## * 3.2 创建Kafka生产者

​	要往 Kafka 写入消息，首先要创建一个生产者对象，并设置一些属性。Kafka 生产者有 3个必选的属性。

+ bootstrap.servers

  该属性指定 broker 的地址清单，地址的格式为 host:port 。<u>清单里不需要包含所有的broker 地址，生产者会从给定的 broker 里查找到其他 broker 的信息</u>。**不过建议至少要提供两个 broker 的信息，一旦其中一个宕机，生产者仍然能够连接到集群上**。

+ key.serializer

  **broker 希望接收到的消息的键和值都是<u>字节数组</u>**。生产者接口允许使用参数化类型，因此可以把 Java 对象作为键和值发送给 broker。这样的代码具有良好的可读性，不过生产者需要知道如何把这些 Java 对象转换成字节数组。 key.serializer 必须被设置为一个实现了`org.apache.kafka.common.serialization.Serializer` 接口的类，生产者会使用这个类把键对象序列化成字节数组。Kafka 客户端默认提供了ByteArraySerializer（这个只做很少的事情）、 StringSerializer 和 IntegerSerializer ，因此，如果你只使用常见的几种 Java 对象类型，那么就没必要实现自己的序列化器。**要注意， key.serializer 是必须设置的，就算你打算只发送值内容**。

+ value.serializer

  与 key.serializer 一样， value.serializer 指定的类会将值序列化。如果键和值都是字符串，可以使用与 key.serializer 一样的序列化器。如果键是整数类型而值是字符串，那么需要使用不同的序列化器。

​	下面的代码片段演示了如何创建一个新的生产者，这里只指定了必要的属性，其他使用默认设置。

```java
private Properties kafkaProps = new Properties(); // ➊
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer"); // ➋
kafkaProps.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
producer = new KafkaProducer<String, String>(kafkaProps); // ➌
```

➊ 新建一个 Properties 对象。

➋ 因为我们打算把键和值定义成字符串类型，所以使用内置的 StringSerializer 。

➌ 在这里我们创建了一个新的生产者对象，并为键和值设置了恰当的类型，然后把Properties对象传给它。

​	这个接口很简单，通过配置生产者的不同属性就可以很大程度地控制它的行为。Kafka 的文档涵盖了所有的配置参数，我们将在这一章的后面部分介绍其中几个比较重要的参数。

​	实例化生产者对象后，接下来就可以开始发送消息了。发送消息主要有以下 3 种方式。

+ **发送并忘记（fire-and-forget）**

  我们把消息发送给服务器，但并不关心它是否正常到达。**大多数情况下，消息会正常到达，因为 Kafka 是高可用的**，而且<u>生产者会自动尝试重发</u>。不过，使用这种方式有时候也会丢失一些消息。

+ **同步发送**

  我们使用 send() 方法发送消息，它会返回一个 Future 对象，调用 get() 方法进行等待，就可以知道消息是否发送成功。

+ **异步发送**

  我们调用 send() 方法，并指定一个回调函数，服务器在返回响应时调用该函数。

​	在下面的几个例子中，我们会介绍如何使用上述几种方式来发送消息，以及如何处理可能发生的异常情况。

​	本章的所有例子都使用单线程，但其实<u>生产者是可以使用多线程来发送消息的</u>。刚开始的时候可以使用单个消费者和单个线程。如果需要更高的吞吐量，可以在生产者数量不变的前提下增加线程数量。如果这样做还不够，可以增加生产者数量。

## * 3.3 发送消息到Kafka

​	最简单的消息发送方式如下所示。

```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products","France");// ➊
try {
  producer.send(record);// ➋
} catch (Exception e) {
  e.printStackTrace();// ➌
}
```

➊ 生产者的 send() 方法将 ProducerRecord 对象作为参数，所以我们要先创建一个ProducerRecord 对象。 ProducerRecord 有多个构造函数，稍后我们会详细讨论。这里使用其中一个构造函数，它需要目标主题的名字和要发送的键和值对象，它们都是字符串。**键和值对象的类型必须与序列化器和生产者对象相匹配**。

➋ 我们使用生产者的 send() 方法发送 ProducerRecord 对象。**从生产者的架构图里可以看到，消息先是被放进缓冲区，然后使用单独的线程发送到服务器端**。 send() 方法会返回一个包含 RecordMetadata 的 Future 对象，不过因为我们会忽略返回值，所以无法知道消息是否发送成功。如果不关心发送结果，那么可以使用这种发送方式。比如，记录Twitter 消息日志，或记录不太重要的应用程序日志。

➌ 我们可以忽略发送消息时可能发生的错误或在服务器端可能发生的错误，但在发送消息之前，生产者还是有可能发生其他的异常。<u>这些异常有可能是 SerializationException（说明**序列化消息失败**）、BufferExhaustedException 或 TimeoutException（说明**缓冲区已满**），又或者是 InterruptException（说明**发送线程被中断**）</u>。

### 3.3.1 同步发送消息

最简单的同步发送消息方式如下所示。

```java
ProducerRecord<String, String> record =
  new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
  producer.send(record).get();// ➊
} catch (Exception e) {
  e.printStackTrace();// ➋
}
```

➊ 在这里， producer.send() 方法先返回一个 Future 对象，然后调用 Future 对象的get()方法等待 Kafka 响应。如果服务器返回错误， get() 方法会抛出异常。如果没有发生错误，我们会得到一个 RecordMetadata 对象，可以用它获取消息的偏移量。

➋ 如果在发送数据之前或者在发送过程中发生了任何错误，比如 broker 返回了一个不允许重发消息的异常或者已经超过了重发的次数，那么就会抛出异常。我们只是简单地把异常信息打印出来。

​	KafkaProducer 一般会发生两类错误。<u>其中一类是**可重试错误**，这类错误可以通过重发消息来解决。比如对于连接错误，可以通过再次建立连接来解决，“无主（no leader）”错误则可以通过重新为分区选举首领来解决</u>。 KafkaProducer 可以被配置成自动重试，如果在多次重试后仍无法解决问题，应用程序会收到一个重试异常。**另一类错误无法通过重试解决，比如“消息太大”异常。对于这类错误， KafkaProducer 不会进行任何重试，直接抛出异常**。

### * 3.3.2 异步发送消息

​	假设消息在应用程序和 Kafka 集群之间一个来回需要 10ms。如果在发送完每个消息后都等待回应，那么发送 100 个消息需要 1 秒。但如果只发送消息而不等待响应，那么发送100 个消息所需要的时间会少很多。<u>大多数时候，我们并不需要等待响应——尽管 Kafka会把目标主题、分区信息和消息的偏移量发送回来，但对于发送端的应用程序来说不是必需的。不过在遇到消息发送失败时，我们需要抛出异常、记录错误日志，或者把消息写入“错误消息”文件以便日后分析</u>。

​	为了在异步发送消息的同时能够对异常情况进行处理，生产者提供了回调支持。下面是使用回调的一个例子。

```java
private class DemoProducerCallback implements Callback {// ➊
  @Override
  public void onCompletion(RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace();// ➋
    }
  }
}
ProducerRecord<String, String> record =
  new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");// ➌
producer.send(record, new DemoProducerCallback());// ➍

```

➊ 为了使用回调，需要一个实现了 org.apache.kafka.clients.producer.Callback 接口的类，这个接口只有一个 onCompletion 方法。

➋ 如果 Kafka 返回一个错误， onCompletion 方法会抛出一个非空（non null）异常。这里我们只是简单地把它打印出来，但是在生产环境应该有更好的处理方式。

➌ 记录与之前的一样。

➍ 在发送消息时传进去一个回调对象。

## * 3.4 生产者的配置

​	到目前为止，我们只介绍了生产者的几个必要配置参数——bootstrap.servers API 以及序列化器。生产者还有很多可配置的参数，在 Kafka 文档里都有说明，它们大部分都有合理的默认值，所以没有必要去修改它们。不过有几个参数在内存使用、性能和可靠性方面对生产者影响比较大，接下来我们会一一说明。

1. acks

   **<u>acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的</u>**。

   这个参数对消息丢失的可能性有重要影响。该参数有如下选项。

   + 如果 acks=0 ，生产者在成功写入消息之前不会等待任何来自服务器的响应。也就是说，如果当中出现了问题，导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了。不过，<u>因为生产者不需要等待服务器的响应，所以它可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量</u>。
   + 如果 acks=1 ，<u>只要集群的**首领节点**收到消息，生产者就会收到一个来自服务器的成功响应</u>。如果消息无法到达首领节点（比如首领节点崩溃，新的首领还没有被选举出来），生产者会收到一个错误响应，<u>为了避免数据丢失，生产者会重发消息。不过，**如果一个没有收到消息的节点成为新首领，消息还是会丢失**</u>。这个时候的吞吐量取决于使用的是同步发送还是异步发送。如果让发送客户端等待服务器的响应（通过调用 Future 对象的 get() 方法），显然会增加延迟（在网络上传输一个来回的延迟）。如果客户端使用回调，延迟问题就可以得到缓解，不过吞吐量还是会受发送中消息数量的限制（比如，生产者在收到服务器响应之前可以发送多少个消息）。
   + 如果 acks=all ，只有当<u>所有参与复制的节点</u>全部收到消息时，生产者才会收到一个来自服务器的成功响应。**这种模式是最安全的，它可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群仍然可以运行（第 5 章将讨论更多的细节）**。不过，它的延迟比 acks=1 时更高，因为我们要等待不只一个服务器节点接收消息。

2. buffer.memory

   **该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。<u>如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足</u>**。这个时候，send() 方法调用要么被阻塞，要么抛出异常，取决于如何设置 `block.on.buffer.full`参数（在 0.9.0.0 版本里被替换成了 `max.block.ms` ，表示在抛出异常之前可以阻塞一段时间）。

3. **compression.type**

   **默认情况下，消息发送时不会被压缩**。该参数可以设置为 snappy 、 gzip 或 lz4 ，它指定了消息被发送给 broker 之前使用哪一种压缩算法进行压缩。snappy 压缩算法由 Google 发明，它占用较少的 CPU，却能提供较好的性能和相当可观的压缩比，如果比较关注性能和网络带宽，可以使用这种算法。gzip 压缩算法一般会占用较多的 CPU，但会提供更高的压缩比，所以如果网络带宽比较有限，可以使用这种算法。**使用压缩可以降低网络传输开销和存储开销，而这往往是向 Kafka 发送消息的瓶颈所在**。

4. retries

   **生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）**。在这种情况下， retries 参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过`retry.backoff.ms`参数来改变这个时间间隔。<u>建议在设置重试次数和重试时间间隔之前，先测试一下恢复一个崩溃节点需要多少时间（比如所有分区选举出首领需要多长时间），**让总的重试时间比 Kafka 集群从崩溃中恢复的时间长，否则生产者会过早地放弃重试**</u>。

   <u>不过有些错误不是临时性错误，没办法通过重试来解决（比如“消息太大”错误）。一般情况下，因为生产者会自动进行重试，所以就没必要在代码逻辑里处理那些可重试的错误</u>。**你只需要处理那些不可重试的错误或重试次数超出上限的情况**。

5. **batch.size**

   **当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里**。<u>该参数指定了一个批次可以使用的内存大小，**按照字节数计算（而不是消息个数）**</u>。当批次被填满，批次里的所有消息会被发送出去。

   <u>不过生产者并不一定都会等到批次被填满才发送，半满的批次，甚至只包含一个消息的批次也有可能被发送。所以就算把批次大小设置得很大，也不会造成延迟，只是会占用更多的内存而已</u>。**但如果设置得太小，因为生产者需要更频繁地发送消息，会增加一些额外的开销**。

6. **linger.ms**

   **该参数指定了生产者在发送批次之前等待更多消息加入批次的时间**。

   <u>KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息</u>。

   把 linger.ms 设置成比 0 大的数，让生产者在发送批次之前等待一会儿，使更多的消息加入到这个批次。虽然这样会增加延迟，但也会提升吞吐量（因为一次性发送更多的消息，每个消息的开销就变小了）。

7. client.id

   该参数可以是任意的字符串，服务器会用它来识别消息的来源，还可以用在日志和配额指标里。

8. max.in.flight.requests.per.connection

   **该参数指定了生产者在收到服务器响应之前可以发送多少个消息**。它的值越高，就会占用越多的内存，不过也会提升吞吐量。**把它设为 1 可以保证消息是按照发送的顺序写入服务器的，即使发生了重试**。

9. timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms

   request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间， metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待响应超时，那么生产者要么重试发送数据，要么返回一个错误（抛出异常或执行回调）。 <u>timeout.ms 指定了 broker 等待**同步副本**返回消息确认的时间，与asks 的配置相匹配——如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误</u>。

10. max.block.ms

    该参数指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。<u>当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞</u>。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。

11. max.request.size

    <u>该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小</u>。例如，假设这个值为 1MB，那么可以发送的单个最大消息为 1MB，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1KB。**另外，broker 对可接收的消息最大值也有自己的限制（ message.max.bytes ），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝**。

12. receive.buffer.bytes 和 send.buffer.bytes

    这两个参数分别指定了 TCP socket 接收和发送数据包的缓冲区大小。<u>如果它们被设为 -1，就使用操作系统的默认值</u>。**如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽**。

> **顺序保证**
>
> **Kafka 可以保证同一个分区里的消息是有序的。也就是说，如果生产者按照一定的顺序发送消息，broker 就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们**。在某些情况下，顺序是非常重要的。例如，往一个账户存入 100 元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。
>
> <u>如果把 retries 设为非零整数，同时把 max.in.flight.requests.per.connection设为比 1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功，broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了</u>。
>
> **一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把 retries 设为 0。可以把 max.in.flight.requests.per.connection 设为 1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给 broker**。<u>不过这样会严重影响生产者的吞吐量，所以只有在对消息的顺序有严格要求的情况下才能这么做</u>。

## 3.5 序列化器

P58
