# MySQL技术内幕-InnoDB存储引擎第2版-学习笔记-02

# 6. 锁

​	人们认为行级锁总会增加开销。实际上，只有当实现本身会增加开销时，行级锁才会增加开销。InnoDB 存储引擎不需要锁升级，因为一个锁和多个锁的开销是相同的。

## 6.1 什么是锁

​	锁机制用于管理对共享资源的并发访问。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。

## * 6.2 lock与latch

> [InnoDB学习笔记--锁_liushangzaibeijing的博客-CSDN博客](https://blog.csdn.net/liushangzaibeijing/article/details/124887880) <= 该博文对latch的说明更为完善，推荐阅读

+ latch：闩锁（轻量级锁），其要求锁定的时间必须非常短。<u>在InnoDB中，latch分为mutex（互斥量）和rwlock（读写锁）</u>。其目的是用来**保证并发线程操作临界资源的正确性**，并且**通常没有死锁检测的机制**。
+ lock：用于**锁定数据库中的对象：表、页、行**。**一般lock的对象仅在事务commit 或rollback 后进行释放**（不同事务隔离级别释放的时间可能不同）。此外， **lock有死锁机制**。

​	表6-1 lock与latch的比较

|          | lock                                                  | latch                                                        |
| -------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 对象     | 事务                                                  | **线程**                                                     |
| 保护     | 数据库内容                                            | **内存数据结构**                                             |
| 持续时间 | **整个事务过程**                                      | 临界资源                                                     |
| 模式     | 行锁、表锁、意向锁                                    | 读写锁、互斥量                                               |
| 死锁     | 通过waits-for graph、time out等机制进行死锁检测与处理 | 无死锁检测与处理机制、仅通过应用程序加锁的顺序（lock leveling）保证无死锁情况发生 |
| 存在于   | Lock Manager 的哈希表                                 | **每个数据结构的对象中**                                     |
| 查看方式 | SHOW ENGINE INNODB STATUS;                            | SHOW ENGINE INNODB MUTEX;                                    |

​	表6-2 命令SHOW ENGINE INNODB MUTEX输出结果说明

| 名称          | 说明                                                         |
| ------------- | ------------------------------------------------------------ |
| count         | mutex被请求的次数                                            |
| spin_waits    | spin lock(自旋锁)的次数，InnoDB存储引擎latch在不能获得锁时首先进行自旋，若自旋后还不能获得锁，则进入等待状态 |
| spin_rounds   | 自旋内部循环的总次数，每次自旋的内部循环是一个随机数。 spin_rounds/spain_waits表示平均每次自旋所需的内部循环次数 |
| os_waits      | 表示操作系统等待的次数。当 spin lock通过自旋还不能获得 latch时，则会进入操作系统等待状态，等待被唤醒 |
| os_yields     | 进行os_thread_yield唤醒操作的次数                            |
| os_wait_times | 操作系统等待的时间，单位是ms                                 |

> 上述所有的这些信息都是比较底层的，一般仅供开发人员参考。但是用户还是可以通过这些参数进行调优。

## * 6.3 lnnoDB 存储引擎中的锁

### * 6.3.1 锁的类型

行级锁

+ 共享锁S：允许**事务**读<u>一行</u>数据
+ 排他锁X：允许**事务**删除或更新<u>一行</u>数据

表级锁（意向锁）

+ 意向共享锁IS：**事务**想要获得一张**表**中<u>某几行</u>的**共享锁**
+ 意向排他锁IX：**事务**想要获得一张**表**中<u>某几行</u>的**排他锁**

<u>由于lnnoDB 存储引擎支持的是**行级别**的锁，因此**意向锁其实不会阻塞除全表扫以外的任何请求**</u>。

兼容性：

![在这里插入图片描述](https://img-blog.csdnimg.cn/dd414a4ad0ea462fa0cf6df3803a237b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

---

​	InnoDB 存储引擎实现了如下两种标准的**行级锁**：

+ **共享锁（S Lock）**，允许事务读一行数据。
+ **排他锁（X Lock）**，允许事务删除或更新一行数据。

​	如果一个事务T1已经获得了行r 的共享锁，那么另外的事务T2 可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为**锁兼容(Lock Compatible)** 。但若有其他的事务T3 想获得行r的排他锁，则其必须等待事务T1 、T2 释放行r上的共享锁——这种情况称为**锁不兼容**。

​	表6-3 显示了共享锁和排他锁的兼容性。	

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090616470191.png#pic_center)

​	从表6-3 可以发现X锁与任何的锁都不兼容，而S锁仅和S锁兼容。**<u>需要特别注意的是， S和X锁都是行锁，兼容是指对同一记录(row) 锁的兼容性情况</u>**。

​	此外， **InnoDB 存储引擎支持多粒度(granular) 锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在**。<u>为了支待在不同粒度上进行加锁操作， InnoDB 存储引擎支持一种额外的锁方式，称之为**意向锁(Intention Lock)**</u> 。

​	<u>意向锁是**将锁定的对象分为多个层次**，意向锁意味着**事务**希望在更细粒度(fine granularity) 上进行加锁</u>，如图6-3 所示。	

![在这里插入图片描述](https://img-blog.csdnimg.cn/3725f9da2739436e9ab95ce146706738.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	图6-3 层次结构

​	**若将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是<u>对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁</u>**。

​	**例如图6-3，如果需要对页上的记录r 进行上X 锁，那么分别需要对数据库A 、表、页上意向锁IX, 最后对记录r 上X 锁。<u>若其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成</u>**。

​	举例来说，<u>在对记录r 加X 锁之前，已经有事务对表1 进行了S 表锁，那么表1 上已存在S 锁，之后事务需要对记录r 在表1 上加上IX，由于**不兼容**，所以该事务需要**等待**表锁操作的完成</u>。

​	**lnnoDB 存储引擎支持意向锁设计比较简练，其意向锁即为表级别的锁**。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁：

1. **意向共享锁(IS Lock)** ，**事务**想要获得一张**表**中<u>某几行</u>的**共享锁**。

2. **意向排他锁(IX Lock)** ，**事务**想要获得一张**表**中<u>某几行</u>的**排他锁**。

​	<u>由于lnnoDB 存储引擎支持的是**行级别**的锁，因此**意向锁其实不会阻塞除全表扫以外的任何请求**</u>。

​	<u>故**表级**意向锁</u>与<u>**行级**锁</u>的兼容性如表6-4 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/dd414a4ad0ea462fa0cf6df3803a237b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

> 用户可以通过命令`SHOW ENGINE INNODB STATUS `命令来查看当前锁请求的信息。
>
> `locks rec but not gap`代表锁住的是一个索引，不是一个范围。

​	在InnoDB 1.0 版本之前，用户只能通过命令`SHOW FULL PROCESSLIST`，`SHOW ENGINE STATUS` 等来查看当前数据库中锁的请求，然后再判断事务锁的情况。从InnoDB 1.0 开始，在`INFORMATION_SCHEMA`架构下添加了表`INNODB_TRX` 、`INNODB_LOCKS`、`INNODB_LOCK_WAITS` 。通过这三张表，用户可以更简单地监控当前事务并分析可能存在的锁问题。我们将通过具体的示例来分析这三张表，在之前，首先了来看表6-5 中表INNODB_TRX 的定义，其由8 个字段组成。

![在这里插入图片描述](https://img-blog.csdnimg.cn/c2e768aae2884cbf81b92c5ea6b2c522.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	`INNODB_TRX`表只是显示了当前运行的InnoDB 事务，并不能直接判断锁的一些情况。如果需要查看锁，则还需要访问表`INNODB_LOCKS`， 该表的字段组成如表6-6 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/462eb8015d7f4f9aa6df7a81a7332704.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	**<u>另外需要特别注意的是，我发现lock_data这个值并非是“可信”的值。例如当用户运行一个范围查找时， `lock_data`可能只返回第一行的主键值</u>**。<u>与此同时，如果当前资源被锁住了，若锁住的页因为lnnoDB 存储引擎缓冲池的容量，导致该页从缓冲池中被刷出，则查看`INNODB_LOCKS` 表时，该值同样会显示为NULL，即InnoDB 存储引擎不会从磁盘进行再一次的查找</u>。

​	在通过表`INNODB_LOCKS` 查看了每张表上锁的情况后，用户就可以来判断由此引发的等待情况了。当事务较小时，用户就可以人为地、直观地进行判断了。但是当事务量非常大，其中锁和等待也时常发生，这个时候就不这么容易判断。但是**通过表`INNODB_LOCK_WAITS`，可以很直观地反映当前事务的等待**。表`INNODB_LOCK_WAITS` 由4 个字段组成，如表6-7 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/bd1ea3ddf6674565ad918d5960dbd60f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_16,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	如果需要，用户可以根据表`INNODB_TRX`、`INNODB_LOCKS`、`INNODB_LOCK_WAITS`得到更为直观的详细信息。例如，执行如下联合查询：

```sql
SELECT
	r.trx_id waiting_trx_id,
	r.trx_mysql_thread_id waiting_thread,
	r.trx_query waiting_query,
	b.trx_id blocking_trx_id,
	b.trx_mysql_thread_id blocking thread,
	b.trx_query blocking_query
FROM information_schema.innodb_lock_waits w
	INNER JOIN information_schema.innodb_trx b
	ON b.trx_id = w.blocking_trx_id
	INNER JOIN information_schema.innodb_trx r
	ON r.trx_id = w.requesting_trx_id
```

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/21/1719c22e084174a3~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

### * 6.3.2 一致性非锁定读

​	**一致性的非锁定读(consistent nonlocking read) 是指lnnoDB 存储引擎通过行<u>多版本控制(multi versioning)</u> 的方式来读取当前执行时间数据库中行的数据**。<u>如果读取的行正在执行DELETE 或UPDATE 操作，这时读取操作不会因此去等待行上锁的释放。相反地， InnoDB 存储引擎会去读取行的一个**快照数据**</u>。如图6-4 所示。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/21/1719c24d8a5ec5cc~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

​	图6-4 直观地展现了lnnoDB存储引擎一致性的非锁定读。**之所以称其为非锁定读，因为<u>不需要等待访问的行上X 锁的释放</u>**。<u>快照数据是指该行的之前版本的数据，该实现是通过undo 段来完成。而undo用来在事务中回滚数据，因此**快照数据本身是没有额外的开销**</u>。<u>此外，**读取快照数据是不需要上锁**的，因为没有事务需要对历史的数据进行修改操作</u>。

​	可以看到，非锁定读机制极大地提高了数据库的并发性。**在InnoDB 存储引擎的默认设置下，这是默认的读取方式，即读取不会占用和等待表上的锁**。<u>但是在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读。此外，即使都是使用非锁定的一致性读，但是对于快照数据的定义也各不相同</u>。

​	通过图6-4 可以知道，**快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本**。就图6-4 所显示的，<u>一个行记录可能有不止一个快照数据，一般称这种技术为**行多版本技术**</u>。由此带来的并发控制，称之为**多版本并发控制(Multi Version Concurrency Control，MVCC)** 。

​	**在事务隔离级别READ COMMITTED 和REPEATABLE READ (InnoDB 存储引擎的默认事务隔离级别）下， InnoDB 存储引擎使用非锁定的一致性读**。然而，对于快照数据的定义却不相同。

+ 在**READ COMMITTED 事务隔离级别**下，对于快照数据，非一致性读总是读取**被锁定行的最新一份快照数据**。
+ 在**REPEATABLE READ 事务隔离级别**下，对于快照数据，非一致性读总是读取**事务开始时的行数据版本**。

> 对于READ COMMITTED 的事务隔离级别而言，从数据库理论的角度来看，其违反了事务ACID 中的I 的特性，即隔离性。

### * 6.3.3 一致性锁定读

​	在前一小节中讲到，在默认配置下，即事务的隔离级别为REPEATABLE READ 模式下， InnoDB 存储引擎的SELECT 操作使用一致性非锁定读。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性。而这要求数据库支持加锁语句，即使是对于SELECT 的只读操作。

​	InnoDB 存储引擎对于SELECT语句支持两种**一致性的锁定读(locking read)** 操作：

+ SELECT…**FOR UPDATE**

  对读取的行记录加一个**X 锁**，其他事务不能对已锁定的行加上任何锁。

+ SELECT…**LOCK IN SHARE MODE**

  对读取的行记录加一个**S 锁**，其他事务可以向被锁定的行加S 锁，但是如果加X 锁，则会被阻塞。

​	<u>对于一致性非锁定读，即使读取的行已被执行了SELECT…FOR UPDATE，也是可以进行读取的，这和之前讨论的情况一样</u>。此外， **SELECT…FOR UPDATE, SELECT…LOCK IN SHARE MODE 必须在一个事务中，<u>当事务提交了，锁也就释放了</u>**。**因此在使用上述两句SELECT 锁定语句时，务必加上`BEGIN`, `START TRANSACTION` 或者`SET AUTOCOMMIT=0`** 。

### * 6.3.4 自增长与锁

​	自增长在数据库中是非常常见的一种属性，也是很多DBA 或开发人员首选的主键方式。<u>在InnoDB 存储引擎的内存结构中，对每个含有自增长值的表都有一个**自增长计数器(auto-increment counter)**</u> 。<u>当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化</u>，执行如下的语句来得到计数器的值：

```sql
SELECT MAX(auto_inc_col) FROM t FOR UPDATE;
```

​	**插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称做AUTO-INC Locking**。<u>这种锁其实是采用一种**特殊的表锁机制**，为了提高插入的性能，锁不是在一个事务完成后才释放，而是**在完成对自增长值插入的SQL 语句后立即释放**</u>。

​	虽然AUTO-INC Locking 从一定程度上提高了并发插入的效率，但还是存在一些性能上的问题。

+ 首先，对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成）。
+ <u>其次，对于INSERT… SELECT 的大数据量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞</u>。

​	<u>从MySQL 5.1.22 版本开始， InnoDB 存储引擎中提供了一种轻量级**互斥量**的自增长实现机制，这种机制大大提高了自增长值插入的性能</u>。并且从该版本开始， InnoDB 存储引擎提供了一个参数`innodb_autoinc_lock_mode` 来控制自增长的模式，该参数的默认值为1 。在继续讨论新的自增长实现方式之前，需要对自增长的插入进行分类，如表6-9所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/9ac561132fbe4840a0f38907dea17b18.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	接着来分析参数`innodb_ auto inc_lock_mode`以及各个设置下对自增的影响，其总共有三个有效值可供设定，即0 、1 、2, 具体说明如表6-10 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/b39c9914ec954507a79713a1795ab714.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAc2xvdyBpcyBmYXN0Lg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

​	此外，**还需要特别注意的是InnoDB 存储引擎中自增长的实现和MylSAM 不同，<u>MylSAM 存储引擎是表锁设计</u>，自增长不用考虑并发插入的问题**。<u>因此在master 上用InnoDB 存储引擎，在slave 上用MyISAM 存储引擎的replication 架构下，用户必须考虑这种情况</u>。

​	另外，**<u>在InnoDB 存储引擎中，自增长值的列必须是索引，同时必须是索引的第一个列。如果不是第一个列，则MySQL 数据库会抛出异常</u>，而MyISAM 存储引擎没有这个问题**。

### * 6.3.5 外键和锁

​	前面已经介绍了外键，外键主要用于引用完整性的约束检查。**在InnoDB 存储引擎中，对于一个外键列，如果没有显式地对这个列加索引， lnnoDB 存储引擎自动对其加一个索引，因为这样可以避免表锁**——这比Oracle 数据库做得好，Oracle数据库不会自动添加索引，用户必须自己手动添加，这也导致了Oracle数据库中可能产生死锁。

​	<u>对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT 父表。但是**对于父表的SELECT 操作，不是使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这时使用的是SELECT…LOCK IN SHARE MODE 方式，即主动对父表加一个S 锁**。如果这时父表上已经这样加X 锁，子表上的操作会被阻塞</u>，如表6-11 所示。

| 时间 | 会话A                          | 会话B                                                        |
| ---- | ------------------------------ | ------------------------------------------------------------ |
| 1    | BEGIN                          |                                                              |
| 2    | DELETE FROM parent WHERE id=3; |                                                              |
| 3    |                                | BEGIN                                                        |
| 4    |                                | INSERT INTO child SELECT 2, 3<br/>\#第二列是外键，执行该句时被阻塞(waiting) |

​	在上述的例子中，两个会话中的事务都没有进行COMMIT或ROLLBACK操作，而会话B 的操作会被阻塞。这是因为id 为3 的父表在会话A 中已经加了一个X 锁，而．此时在会话B 中用户又需要对父表中id 为3 的行加一个S 锁，这时INSERT 的操作会被阻塞。<u>设想如果访问父表时，使用的是一致性的非锁定读，这时Session B 会读到父表有id=3 的记录，可以进行插入操作。但是如果会话A 对事务提交了，则父表中就不存在id 为3 的记录。数据在父、子表就会存在不一致的情况</u>。若这时用户查询`INNODB_LOCKS`表，会看到如下结果：

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/4/21/1719c27faebf2ba8~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

## 6.4 锁的算法

### * 6.4.1 行锁的3种算法

​	InnoDB 存储引擎有3 种行锁的算法，其分别是：

+ Record Lock：单个行记录上的锁
+ **Gap Lock：间隙锁，锁定一个范围，但<u>不包含记录本身</u>**

+ **Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且<u>锁定记录本身</u>**

​	**Record Lock 总是会去锁住<u>索引记录</u>**，<u>如果lnnoDB 存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB 存储引擎会使用**隐式的主键**来进行锁定</u>。

​	Next-Key Lock 是结合了Gap Lock 和Record Lock 的一种锁定算法，**<u>在Next-Key Lock 算法下，InnoDB 对于行的查询都是采用这种锁定算法</u>**。例如一个索引有10, 11,13 和20 这四个值，那么该索引可能被Next-Key Locking 的区间为：

```shell
(-♾️,10]
(10, 11]
(11, 13]
(13, 20]
(20, +♾️)
```

​	**<u>采用Next-Key Lock 的锁定技术称为Next-Key Locking</u>。其设计的目的是为了解决Phantom Problem**，这将在下一小节中介绍。而利用这种锁定技术，锁定的不是单个值，而是一个范围，是**谓词锁(predict lock)** 的一种改进。除了next-key locking，还有previous-key locking 技术。同样上述的索引10 、11 、13 和20, 若采用previous-keylocking 技术，那么可锁定的区间为：

```shell
(-♾️,10)
[10, 11)
[11, 13)
[13, 20)
[20, +♾️)
```

​	若事务T1 已经通过next-key locking 锁定了如下范围：

```shell
(10, 11] 、(11, 13]
```

​	当插入新的记录12 时，则锁定的范围会变成：

```shell
(10, 11] 、(11,12] 、(12, 13]
```

​	然而，**当查询的索引含有<u>唯一属性</u>时， InnoDB 存储引擎会<u>对Next-Key Lock 进行优化，将其降级为Record Lock</u>，即仅锁住索引本身，而不是范围**。看下面的例子，首先根据如下代码创建测试表t:

```sql
DROP TABLE IF EXISTS t;
CREATE TABLE t (a INT PRIMARY KEY);
INSERT INTO t SELECT 1;
INSERT INTO t SELECT 2;
INSERT INTO t SELECT 5;
```

​	接着来执行表6-12 中的SQL 语句。

| 时间 | 事务A                                  | 事务B                      |
| ---- | -------------------------------------- | -------------------------- |
| 1    | begin；                                |                            |
| 2    | select * from t where a=5 for update； |                            |
| 3    |                                        | begin；                    |
| 4    |                                        | insert into t select 4;    |
| 5    |                                        | commit； #成功，不需要等待 |
| 6    | commit；                               |                            |

​	表t 共有1 、2 、5 三个值。在上面的例子中，在会话A 中首先对a=5 进行X锁定。而**由于a 是主键且唯一，因此锁定的仅是5 这个值，而不是(2, 5) 这个范围**，这样在会话B 中插入值4 而不会阻塞，可以立即插入并返回。即锁定由Next-Key Lock 算法降级为了Record Lock，从而提高应用的并发性。

​	正如前面所介绍的， **Next-Key Lock 降级为Record Lock 仅在查询的列是<u>唯一索引</u>的情况下**。若是辅助索引，则情况会完全不同。同样，首先根据如下代码创建测试表z:

```sql
CREATE TABLE z (a INT, b INT, PRIMARY KEY(a), KEY(b));
INSERT INTO z SELECT 1,1;
INSERT INTO z SELECT 3,1;
INSERT INTO z SELECT 5,3;
INSERT INTO z SELECT 7, 6;
INSERT INTO z SELECT 10,8;
```

​	表z 的列b 是辅助索引，若在会话A 中执行下面的SQL 语句：

```sql
SELECT * FROM z WHERE b=3 FOR UPDATE
```

​	很明显，这时SQL 语句通过索引列b 进行查询，因此其使用传统的Next-Key Locking 技术加锁，并且**由于有两个索引，其需要分别进行锁定**。

+ <u>对于聚集索引，其仅对列a 等于5 的索引加上Record Lock</u> 。
+ <u>而对于辅助索引，其加上的是Next-Key Lock，锁定的范围是(1, 3) ，**特别需要注意的是， InnoDB 存储引擎还会对辅助索引下一个键值加上gap lock**，即还有一个辅助索引范围为(3, 6) 的锁</u>。

​	因此，若在新会话B中运行下面的SQL 语句，都会被阻塞：

```sql
SELECT * FROM z WHERE a = 5 LOCK IN SHARE MODE;
INSERT INTO z SELECT 4, 2;
INSERT INTO z SELECT 6, 5;
```

+ 第一个SQL 语句不能执行，因为在会话A 中执行的SQL 语句已经对聚集索引中列a=5 的值加上X 锁，因此执行会被阻塞。
+ 第二个SQL 语句，主键插入4， 没有问题，但是插入的辅助索引值2 在锁定的范围(1, 3) 中，因此执行同样会被阻塞。
+ 第三个SQL 语句，插入的主键6 没有被锁定， 5 也不在范围(1, 3) 之间。但插人的值5 在另一个锁定的范围(3, 6) 中，故同样需要等待。

​	而下面的SQL 语句，不会被阻塞，可以立即执行：

```sql
INSERT INTO z SELECT 8, 6;
INSERT INTO z SELECT 2, 0;
INSERT INTO z SELECT 6,7;
```

​	从上面的例子中可以看到， **<u>Gap Lock 的作用是为了阻止多个事务将记录插入到同一范围内，而这会导致Phantom Problem 问题的产生</u>**。例如在上面的例子中，会话A 中用户已经锁定了b=3 的记录。若此时没有Gap Lock 锁定(3, 6) ，那么用户可以插入索引b 列为3 的记录，这会导致会话A 中的用户再次执行同样查询时会返回不同的记录，即导致Phantom Problem 问题的产生。

​	用户可以通过以下两种方式来显式地关闭Gap Lock：

+ 将事务的隔离级别设置为READ COMMITTED

+ 将参数`innodb_locks_unsafe_for_binlog`设置为1

​	<u>在上述的配置下，除了**外键约束**和**唯一性检查**依然需要的Gap Lock，其余情况仅使用Record Lock进行锁定</u>。**但需要牢记的是，上述设置破坏了事务的隔离性，并且对于replication，<u>可能会导致主从数据的不一致</u>。此外，<u>从性能上来看， READ COMMITTED也不会优于默认的事务隔离级别READ REPEATABLE</u>** 。

​	**<u>在InnoDB 存储引擎中，对于INSERT的操作，其会检查插入记录的下一条记录是否被锁定，若已经被锁定，则不允许查询</u>**。对于上面的例子，会话A 已经锁定了表z中b=3 的记录，即已经锁定了(1, 3) 的范围，这时若在其他会话中进行如下的插入同样会导致阻塞：

```sql
INSERT INTO z SELECT 2, 2;
```

​	<u>因为在辅助索引列b 上插入值为2 的记录时，会监测到下一个记录3已经被索引</u>。而将插入修改为如下的值，可以立即执行：

```sql
INSERT INTO z SELECT 2,0;
```

​	**最后需再次提醒的是，对于唯一键值的锁定， <u>Next-Key Lock 降级为Record Lock仅存在于查询所有的唯一索引列</u>**。

​	**<u>若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range 类型查询，而不是point 类型查询，故lnnoDB 存储引擎依然使用Next-Key Lock 进行锁定</u>**。

### * 6.4.2 解决Phantom Problem

​	**在默认的事务隔离级别下，即REPEATABLE READ 下， InnoDB 存储引擎采用Next-Key Locking 机制来避免Phantom Problem （幻像问题）**。这点可能不同于与其他的数据库，如Oracle 数据库，因为其可能需要在SERIALIZABLE 的事务隔离级别下才能解决Phantom Problem 。

​	**Phantom Problem 是指在同一事务下，连续执行两次同样的SQL 语句可能导致不同的结果，第二次的SQL 语句可能会返回之前不存在的行**。下面将演示这个例子，使用前一小节所创建的表t。表t 由1 、2 、5 这三个值组成，若这时事务T1 执行如下的SQL 语句：

```sql
SELECT * FROM t WHERE a>2 FOR UPDATE;
```

​	注意这时事务T1并没有进行提交操作，上述应该返回5 这个结果。若与此同时，另一个事务T2 插入了4 这个值，并且数据库允许该操作，那么事务T1 再次执行上述SQL 语句会得到结果4 和5 。这与第一次得到的结果不同，违反了事务的隔离性，即当前事务能够看到其他事务的结果。其过程如表6-13 所示。

|   时间   |                     会话A                                    |   会话B                          |
| ---- | ------------------------------------------------------ | -------------------------- |
| 1    | set sessi tx_isolation='read-committed';               |                            |
| 2    | begin;                                                 |                            |
| 3    | select * from t where a>2 for update;<br />结果为a:5   |                            |
| 4    |                                                        | begin;                     |
| 5    |                                                        | insert into t(a) select 4; |
| 6    |                                                        | commit                     |
| 7    | select * from t where a>2 for update;<br />结果为 a:4 和 a:5 |                            |

​	**lnnoDB 存储引擎采用Next-Key Locking 的算法避免Phantom Problem**。对于上述的SQL 语句`SELECT * FROM t WHERE a>2 FOR UPDATE`， 其锁住的不是5 这单个值，而是对(2, +♾️）这个范围加了X 锁。因此任何对于这个范围的插入都是不被允许的，从而避免Phantom Problem 。

​	**InnoDB 存储引擎默认的事务隔离级别是REPEATABLE READ，在该隔离级别下，其采用Next-Key Locking 的方式来加锁**。**而在事务隔离级别READ COMMITTED 下，其仅采用Record Lock**， 因此在上述的示例中，会话A需要将事务的隔离级别设置为READ COMMITTED。

​	此外，<u>**用户可以通过InnoDB 存储引擎的Next-Key Locking 机制在应用层面实现唯一性的检查**</u>。例如：

```sql
SELECT * FROM table WHERE col=xxx LOCK IN SHARE MODE:
If not found any row:
	# unique for insert value
	INSERT INTO table VALUES (...);
```

​	**<u>如果用户通过索引查询一个值，并对该行加上一个SLock，那么即使查询的值不在，其锁定的也是一个范图，因此若没有返回任何行，那么新插入的值一定是唯一的</u>**。

​	也许有读者会有疑问，<u>如果在进行第一步SELECT …LOCK IN SHARE MODE 操作时，有多个事务并发操作，那么这种唯一性检查机制是否存在问题。其实并不会，因为这时会导致死锁，**只有一个事务的插入操作会成功，而其余的事务会抛出死锁的错误**</u>，如表6-14所示。

​	表6-14 通过Next-Key Locking 实现应用程序的唯一性检查

![img](https://img-blog.csdnimg.cn/20210625171716631.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FpY2hvZ24=,size_16,color_FFFFFF,t_70)

## 6.5 锁问题

​	通过锁定机制可以实现事务的隔离性要求，使得事务可以并发地工作。锁提高了并发，但是却会带来潜在的问题。不过好在因为事务隔离性的要求，锁只会带来三种问题，如果可以防止这三种情况的发生，那将不会产生并发异常。

### * 6.5.1 脏读

​	在理解脏读(Dirty Read) 之前，需要理解脏数据的概念。但是脏数据和之前所介绍的脏页完全是两种不同的概念。

+ <u>脏页指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中</u>。
+ **而所谓脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交(commit)** 。

​	<u>对于脏页的读取，是非常正常的。脏页是因为数据库实例内存和磁盘的异步造成的，这并不影响数据的一致性（或者说两者最终会达到一致性，即当脏页都刷回到磁盘）。并且因为脏页的刷新是异步的，不影响数据库的可用性，因此可以带来性能的提高</u>。

​	**脏数据却截然不同，脏数据是指未提交的数据，如果读到了脏数据，即一个事务可以读到另外一个事务中未提交的数据，则显然违反了数据库的隔离性**。

​	**脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到脏数据**。表6-15 的例子显示了一个脏读的例子。

![在这里插入图片描述](https://img-blog.csdn.net/20181018062003714?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1bnphb3NpeWVjYW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​	表t 为我们之前在6.4.1 中创建的表，不同的是在上述例子中，事务的隔离级别进行了更换，由默认的REPEATABLE READ 换成了READ UNCOMMITTED 。因此在会话A中，在事务并没有提交的前提下，会话B中的两次SELECT 操作取得了不同的结果，并且2 这条记录是在会话A 中并未提交的数据，即产生了脏读，违反了事务的隔离性。

​	脏读现象在生产环境中并不常发生，从上面的例子中就可以发现，脏读发生的条件是需要事务的隔离级别为READ UNCOMMITTED，而目前绝大部分的数据库都至少设置成READ COMMITTED 。InnoDB 存储引擎默认的事务隔离级别为READ REPEATABLE，Microsoft SQL Server 数据库为READ COMMITTED，Oracle 数据库同样也是READ COMMITTED 。

​	**脏读隔离看似毫无用处，但在一些比较特殊的情况下还是可以将事务的隔离级别设置为READ UNCOMMITTED 。例如replication环境中的slave 节点，并且在该slave上的查询并不需要特别精确的返回值**。

### * 6.5.2 不可重复读

​	**不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML 操作。因此，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的情况，这种情况称为不可重复读**。

​	**不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求**。可以通过下面一个例子来观察不可重复读的情况，如表6-16 所示。

![在这里插入图片描述](https://img-blog.csdn.net/20181018062323572?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1bnphb3NpeWVjYW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​	在会话A 中开始一个事务，第一次读取到的记录是1， 在另一个会话B 中开始了另一个事务，插入一条为2 的记录，在没有提交之前，对会话A 中的事务进行再次读取时，读到的记录还是1, 没有发生脏读的现象。但会话B 中的事务提交后，在对会话A 中的事务进行读取时，这时读到是1和2 两条记录。这个例子的前提是，在事务开始前，会话A 和会话B 的事务隔离级别都调整为READ COMMITTED 。

​	<u>**一般来说，不可重复读的问题是可以接受的，因为其读到的是已经提交的数据，本身并不会带来很大的问题**。因此，很多数据库厂商（如Oracle、Microsoft SQL Server)将其数据库事务的默认隔离级别设置为 READ COMMITTED，在这种隔离级别下允许不可重复读的现象</u>。

​	**在InnoDB 存储引擎中，通过使用Next-Key Lock算法来避免不可重复读的问题。在MySQL 官方文档中将不可重复读的问题定义为Phantom Problem，即幻像问题**。<u>在Next-Key Lock 算法下，对于索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围(gap) 。因此在这个范围内的插入都是不允许的。这样就避免了另外的事务在这个范围内插入数据导致的不可重复读的问题</u>。因此， **lnnoDB 存储引擎的默认事务隔离级别是READ REPEATABLE，采用Next-Key Lock 算法，避免了不可重复读的现象**。

### * 6.5.3 丢失更新

​	**丢失更新是另一个锁导致的问题，简单来说其就是一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致**。例如：

1) 事务T1 将行记录r 更新为vi, 但是事务T1 并未提交。

2) 与此同时，事务T2 将行记录r 更新为v2，事务T2 未提交。

3) 事务T1 提交。

4) 事务T2 提交。

​	但是，在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是READ UNCOMMITTED 的事务隔离级别，对于行的DML 操作，需要对行或其他粗粒度级别的对象加锁。因此在上述步骤2) 中，事务T2 并不能对行记录r 进行更新操作，其会被阻塞，直到事务T1提交。

​	虽然数据库能阻止丢失更新问题的产生，但是在生产应用中还有另一个逻辑意义的丢失更新问题，而导致该问题的并不是因为数据库本身的问题。实际上，在所有多用户计算机系统环境下都有可能产生这个问题。简单地说来，出现下面的情况时，就会发生丢失更新：

1) 事务T1 查询一行数据，放入**本地内存**，并显示给一个终端用户User1 。

2) 事务T2 也查询该行数据，并将取得的数据显示给终端用户User2。

3) User1 修改这行记录，更新数据库并提交。

4) User2 修改这行记录，更新数据库并提交。

​	显然，这个过程中用户User1 的修改更新操作“丢失”了，而这可能会导致一个“恐怖＂的结果。设想银行发生丢失更新现象，例如一个用户账号中有10000元人民币，他用两个网上银行的客户端分别进行转账操作。第一次转账9000 人民币，因为网络和数据的关系，这时需要等待。但是这时用户操作另一个网上银行客户端，转账1元，如果最终两笔操作都成功了，用户的账号余款是9999 人民币，第一次转的9000 人民币并没有得到更新，但是在转账的另一个账号却会收到这9000 元，这导致的结果就是钱变多，而账不平。也许有读者会说，不对，我的网银是绑定USB Key 的，不会发生这种情况。是的，通过USB Key 登录也许可以解决这个问题，但是更重要的是在数据库层解决这个问题，避免任何可能发生丢失更新的情况。

​	**<u>要避免丢失更新发生，需要让事务在这种情况下的操作变成串行化，而不是并行的操作</u>**。即在上述四个步骤的1) 中，对用户读取的记录加上一个<u>排他X锁</u>。同样，在步骤2) 的操作过程中，用户同样也需要加一个<u>排他X锁</u>。通过这种方式，步骤2) 就必须等待一步骤1) 和步骤3) 完成，最后完成步骤4) 。表6-17 所示的过程演示了如何避免这种逻辑上丢失更新问题的产生。

​	表6-17 丢失更新问题的处理方法

![img](http://i1.go2yd.com/image.php?url=0Z4KLORAjv)

​	有读者可能会问，在上述的例子中为什么不直接允许UPDATE 语句，而首先要进行SELECT…FOR UPDATE 的操作。<u>的确，直接使用UPDATE可以避免丢失更新问题的产生。然而在实际应用中，应用程序可能需要首先检测用户的余额信息，查看是否可以进行转账操作，然后再进行最后的UPDATE 操作，因此在SELECT 与UPDATE操作之间可能还存在一些其他的SQL 操作</u>。

​	我发现，程序员可能在了解如何使用SELECT 、INSERT 、UPDATE 、DELETE 语句后就开始编写应用程序。因此，丢失更新是程序员最容易犯的错误，也是最不易发现的一个错误，因为这种现象只是随机的、零星出现的，不过其可能造成的后果却十分严重。

## * 6.6 阻塞

​	**因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞**。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。

​	在InnoDB 存储引擎中，参数`innodb_lock_wait_timeout`用来控制等待的时间（默认是50秒）， `innodb_rollback_on_timeout`用来设定是否在等待超时时对进行中的事务进行回滚操作（默认是OFF，代表不回滚）。参数`innodb_lock_wait_timeout`是动态的，可以在MySQL 数据库运行时进行调整：

```shell
mysql> SET @@innodb_lock_wait_timeout=60;
Query OK, 0 rows affected (0.00 sec)
```

​	而`innodb_rollback_on_timeout`是静态的，不可在启动时进行修改，如：

```shell
mysql> SET @@innodb_rollback_on_timeout=on;
ERROR 1238 (HYOOO): Variable'innodb_rollback_on_timeout'is a read only
variable
```

​	当发生超时， MySQL 数据库会抛出一个1205 的错误，如：

```sql
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM t WHERE a= 1 FORUPDATE;
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```

​	**<u>需要牢记的是，在默认情况下InnoDB 存储引擎不会回滚超时引发的错误异常</u>**。

​	**<u>其实InnoDB 存储引擎在大部分情况下都不会对异常进行回滚</u>**。如在一个会话中执行了如下语句：

```shell
# 会话A
mysql> SELECT * FROM t;
十一一一十
| a    |
十一一一十
|	1		 |
| 2    |
| 4 	 |
十一一一十
3 rows in set (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM t WHERE a < 4 FOR UPDATE;
十一一一十
| a 	 |
十一一一十
| 1		 |
| 2 	 |
十一一一十
2 rows in set (0.00 sec)
```

​	在会话A 中开启了一个事务，在Next-Key Lock 算法下锁定了小于4 的所有记录（其实也锁定了4 这个记录本身）。在另一个会话B 中执行如下语句：

```shell
# 会话B
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO t SELECT 5;
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0

mysql> INSERT INTO t SELECT 3;
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```

​	可以看到，在会话B 中插入记录5 是可以的，但是在插人记录3 时，因为会话A 中Next-Key Lock 算法的关系，需要等待会话A中事务释放这个资源，所以等待后产生了超时。但是在超时后用户再进行SELECT 操作时会发现， 5 这个记录依然存在：

```shell
mysql>SELECT * FROM t;
+---+
I a I
十一一一十
I l I
I 2 I
I 4 I
I 5 I
I 8 I
+---+
5 rows in set (0.00 sec)
```

​	这是因为这时<u>会话B中的事务虽然抛出了异常，但是既没有进行COMMIT 操作，也没有进行ROLLBACK</u>。而这是十分危险的状态，因此用户必须判断是否需要COMMIT 还是ROLLBACK，之后再进行下一步的操作。

## 6.7 死锁

### * 6.7.1 死锁的概念

​	**死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去**。

​	解决死锁问题最简单的方式是不要有等待，将任何的等待都转化为回滚，并且事务重新开始。毫无疑问，这的确可以避免死锁问题的产生。然而在线上环境中，这可能导致并发性能的下降，甚至任何一个事务都不能进行。而这所带来的问题远比死锁问题更为严重，因为这很难被发现并且浪费资源。

​	**解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阙值时，其中一个事务进行回滚，另一个等待的事务就能继续进行**。在InnoDB 存储引擎中，参数`innodb_lock_wait_timeout`用来设置超时的时间。

​	<u>超时机制虽然简单，但是其仅通过超时后对事务进行回滚的方式来处理，或者说其是根据FIFO的顺序选择回滚对象。但若超时的事务所占权重比较大，如事务操作更新了很多行，占用了较多的undo log，这时采用FIFO 的方式，就显得不合适了，因为回滚这个事务的时间相对另一个事务所占用的时间可能会很多</u>。

​	因此，**除了超时机制，当前数据库还都普遍采用wait-for graph （等待图）的方式来进行死锁检测**。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB 存储引擎也采用的这种方式。wait-for graph 要求数据库保存以下两种信息：

+ 锁的信息链表
+ 事务等待链表

​	**通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待**。在wait-for graph 中，事务为图中的节点。而在图中，事务T1指向T2 边的定义为：

+ 事务T1 等待事务T2 所占用的资源

+ 事务T1 最终等待T2 所占用的资源，也就是事务之间在等待相同的资源，而事务T1发生在事务T2 的后面

​	下面来看一个例子，当前事务和锁的状态如图6-5 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190801172351168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTcyMzU0NA==,size_16,color_FFFFFF,t_70)

​	图6-5 示例事务状态和锁的信息

​	在Transaction Wait Lists 中可以看到共有4 个事务t1 、t2 、t3 、t4，故在wait-for graph 中应有4 个节点。而事务t2 对row1 占用x锁，事务t1对row2 占用s 锁。事务t1需要等待事务t2 中row1的资源，因此在wait-for graph 中有条边从节点t1 指向节点t2 。事务t2 需要等待事务t1 、t4 所占用的row2 对象，故而存在节点t2 到节点t1 、t4 的边。同样，存在节点t3 到节点t1 、t2 、t4 的边，因此最终的wait-for graph 如图6-6 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190801172407299.png)

​	图6-6 wait-for graph

​	通过图6-6 可以发现存在回路(t1, t2) ，因此存在死锁。通过上述的介绍，可以发现**wait-for graph 是一种较为主动的死锁检测机制，<u>在每个事务请求锁并发生等待时都会判断是否存在回路</u>，若存在则有死锁，通常来说InnoDB 存储引擎选择<u>回滚undo量最小的事务</u>**。

> ​	wait-for graph 的死锁检测通常采用<u>深度优先</u>的算法实现，在InnoDB1.2 版本之前，都是采用递归方式实现。而从1.2 版本开始，对wait-for graph 的死锁检测进行了优化，将递归用非递归的方式实现，从而进一步提高了InnoDB 存储引擎的性能。

### 6.7.2 死锁概率

​	死锁应该非常少发生，若经常发生，则系统是不可用的。此外，死锁的次数应该还要少于等待，因为至少需要2 次等待才会产生一次死锁。本节将从纯数学的概率角度来分析，死锁发生的概率是非常小的。

​	假设当前数据库中共有n+1个线程执行，即当前总共有n+1个事务。并假设每个事务所做的操作相同。若每个事务由r+1个操作组成，每个操作为从R 行数据中随机地操作一行数据，并占用对象的锁。每个事务在执行完最后一个步骤释放所占用的所有锁资源。最后，假设nr<<R，即线程操作的数据只占所有数据的一小部分。

​	在上述的模型下，事务获得一个锁需要等待的概率是多少呢？当事务获得一个锁，其他任何一个事务获得锁的情况为：
$$
(1+2+3...+r)/(r+1) ≈r/2
$$
​	由于每个操作为从R 行数据中取一条数据，每行数据被取到的概率为1/R， 因此，事务中每个操作需要等待的概率PW 为：
$$
PW=nr/2R
$$
​	事务是由r个操作所组成，因此事务发生等待的概率PW(T) 为：
$$
PW(T)=1-(1-PW)^r≈r*PW≈nr^2/2R
$$
​	死锁是由于产生回路，也就是事务互相等待而发生的，若死锁的长度为2，即两个等待节点间发生死锁，那么其概率为：
$$
一个事务发生死锁的概率≈PW(T)^2/n≈nr^4/4R^2
$$
​	由于大部分死锁发生的长度为2，因此上述公式基本代表了一个事务发生死锁的概率。从整个系统来看，任何一个事务发生死锁的概率为：
$$
系统中任何一个事务发生死锁的概率≈n^2r^4/4R^2
$$
​	从上述的公式中可以发现，由于nr<<R ，因此事务发生死锁的概率是非常低的。m同时，事务发生死锁的概率与以下几点因素有关：

+ **系统中事务的数量(n) ，数量越多发生死锁的概率越大。**
+ **每个事务操作的数量(r)，每个事务操作的数批越多，发生死锁的概率越大。**
+ **操作数据的集合(R)，越小则发生死锁的概率越大**。

### 6.7.3 死锁的示例

​	**如果程序是串行的，那么不可能发生死锁。死锁只存在于并发的情况，而数据库本身就是一个并发运行的程序，因此可能会发生死锁**。表6-18 的操作演示了死锁的一种经典的情况，即A 等待B，B 在等待A，这种死锁问题被称为AB-BA 死锁。

​	表6-18 死锁用例1

![531691fa99c0e55965d57e166be24142.png](https://img-blog.csdnimg.cn/img_convert/531691fa99c0e55965d57e166be24142.png)

​	在上述操作中，会话B 中的事务抛出了1213 这个错误提示，即表示事务发生了死锁。死锁的原因是会话A 和B 的资源在互相等待。大多数的死锁InnoDB 存储引擎本身可以侦测到，不需要人为进行干预。但是在上面的例子中，在会话B 中的事务抛出死锁异常后，会话A 中马上得到了记录为2 的这个资源，这其实是因为会话B 中的事务发生了回滚，否则会话A 中的事务是不可能得到该资源的。还记得6.6节中所说的内容吗？**InnoDB 存储引擎并不会回滚大部分的错误异常，但是死锁除外**。**发现死锁后， InnoDB存储引擎会马上回滚一个事务，这点是需要注意的**。因此如果在应用程序中捕获了1213这个错误，其实并不需要对其进行回滚。

​	<u>Oracle 数据库中产生死锁的常见原因是没有对外键添加索引，而InnoDB存储引擎会自动对其进行添加，因而能够很好地避免了这种情况的发生</u>。而人为删除外键上的索引， MySQL 数据库会抛出一个异常：

```shell
mysql> CREATE TABLE p (
	-> a INT,
	-> PRIMARY KEY(a)
	->)ENGINE=InnoDB;
Query OK, 0 rows affected (0.00 sec)

mysql> CREATE TABLE c (
	-> b INT,
	-> FOREIGH KEY(b) REFERENCES p(a)
	->)ENGINE=InnoDB;
Query OK, 0 rows affected (0.00 sec)

mysql> SHOW INDEX FROM c\G;
*************************** 1. row***************************
	Table: C
	Non_unique: 1
	Key_name: b
	Seq_in_index: 1
	Column name: b
	Collation: A
	Cardinality: 0
	Sub_part: NULL
	Packed: NULL
	Null: YES
	Index_type: BTREE
	Comment:
1 row in set (0.00 sec)

mysql> DROP INDEX b ON c;
ERROR 1553 (HYOOO): Cannot drop index'b': needed in a foreign key constraint
```

​	通过上述例子可以看到，虽然在建立子表时指定了外键，但是InnoDB 存储引擎会自动在外键列上建立了一个索引b。并且，人为地删除这个列是不被允许的。

​	**此外还存在另一种死锁，即当前事务持有了待插入记录的下一个记录的X锁，但是在等待队列中存在一个S锁的请求，则可能会发生死锁**。来看一个例子，首先根据如下代码创建测试表t， 并导入一些数据：

```sql
CREATE TABLE t (
  a INT PRIMARY KEY
)ENGINE=InnoDB;
INSERT INTO t VALUES (1), (2), (4), (5);
```

​	表t 仅有一个列a，并插入4 条记录。接着运行表6-19 所示的查询。

​	表6-19 死锁用例2

![1613618bdce37f9907b21efd32c9236c.png](https://img-blog.csdnimg.cn/img_convert/1613618bdce37f9907b21efd32c9236c.png)

​	可以看到，<u>会话A中已经对记录4持有了X 锁，但是会话A 中插入记录3时会导致死锁发生。这个问题的产生是由于会话B 中请求记录4的S 锁而发生等待，但之前请求的锁对于主键值记录1 、2都已经成功，若在事件点5能插入记录，那么会话B 在获得记录4持有的S锁后，还需要向后获得记录3的记录，这样就显得有点不合理。因此InnoDB 存储引擎在这里主动选择了死锁，而回滚的是undo log记录大的事务，这与AB-BA 死锁的处理方式又有所不同</u>。

## 6.8 锁升级

​	**锁升级(Lock Escalation) 是指将当前锁的粒度降低。举例来说，数据库可以把一个表的1000 个行锁升级为一个页锁，或者将页锁升级为表锁**。<u>如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象</u>。

​	<u>Microsoft SQL Server 数据库的设计认为锁是一种稀有的资源，在适合的时候会自动地将行、键或分页锁升级为更粗粒度的表级锁。这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率</u>。

​	即使在Microsoft SQL Server 2005 版本之后， SQL Server 数据库支持了行锁，但是其设计和lnnoDB 存储引擎完全不同，在以下情况下依然可能发生锁升级：

+ 由一句单独的SQL 语句在一个对象上持有的锁的数量超过了阔值，默认这个阔值为5000 。值得注意的是，如果是不同对象，则不会发生锁升级
+ 锁资源占用的内存超过了激活内存的40％时就会发生锁升级

​	<u>在Microsoft SQL Server 数据库中，由于锁是一种稀有的资源，因此锁升级会带来一定的效率提高。但是锁升级带来的一个问题却是因为锁粒度的降低而导致并发性能的降低</u>。

​	**InnoDB 存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的**。

​	假设一张表有3 000 000 个数据页，每个页大约有100 条记录，那么总共有300 000 000条记录。若有一个事务执行全表更新的SQL 语句，则需要对所有记录加X 锁。

+ 若根据每行记录产生锁对象进行加锁，并且每个锁占用10 字节，则仅对锁管理就需要差不多需要3GB 的内存。
+ 而InnoDB 存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用30 个字节，则锁对象仅需90MB 的内存。由此可见两者对于锁资源开销的差距之大。

## 6.9 小结

​	这一章介绍的内容非常多，可能会让读者觉得很难，甚至会不时地抓耳挠腮。尽管锁本身相当直接，但是它的一些副作用却不是这样。关键是用户需要理解锁带来的问题，如丢失更新、脏读、不可重复读等。如果不知道这一点，那么开发的应用程序性能就会很差。如果不学会怎样通过一些命令和数据字典来查看事务锁住了哪些资源，你可能永远不知道到底发生了什么事情，可能只是认为MySQL 数据库有时会阻塞而已。

​	本章在介绍锁的同时，还比较了MySQL 数据库InnoDB 存储引擎、MylSAM 存储引擎、Microsoft SQL Server 数据库、Oracle 数据库锁的特性。通过这些比较了解到，虽然每个数据库在SQL 语句层面上的差别可能不是很大，在内部底层的实现却各有不同。通过理解InnoDB 存储引擎锁的特性，对于开发一个高性能、高并发的数据库应用显得十分重要和有帮助。

# 7. 事务

​	**事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以确保要么所有修改都已经保存了，要么所有修改都不保存**。

​	InnoDB 存储引擎中的事务完全符合ACID 的特性。ACID 是以下4个词的缩写：

+ 原子性(atomicity)

+ 一致性(consistency)

+ 隔离性(isolation)

+ 持久性(durability)

​	第6 章介绍了锁，讨论InnoDB 是如何实现事务的隔离性的。本章主要关注事务的原子性这一概念，并说明怎样正确使用事务及编写正确的事务应用程序，避免在事务方面养成一些不好的习惯。

## 7.1 认识事务

### 7.1.1 概述

​	<u>理论上说，事务有着极其严格的定义，它必须同时满足四个特性，即通常所说的事务的ACID 特性。值得注意的是，虽然理论上定义了严格的事务要求，但是数据库厂商出于各种目的，并没有严格去满足事务的ACID 标准</u>。例如，对于MySQL 的NDB Cluster 引擎来说，虽然其支持事务，但是不满足D 的要求，即持久性的要求。对于Oracle 数据库来说，其默认的事务隔离级别为READ COMMITTED，不满足I的要求，即隔离性的要求。虽然在大多数的情况下，这并不会导致严重的结果，甚至可能还会带来性能的提升，但是用户首先需要知道严谨的事务标准，并在实际的生产应用中避免可能存在的潜在问题。对于InnoDB 存储引擎而言，其默认的事务隔离级别为READ REPEATABLE，完全遵循和满足事务的ACID 特性。这里，具体介绍事务的ACID 特性，并给出相关概念。

​	**A (Atomicity) ，原子性**。在计算机系统中，每个人都将原子性视为理所当然。例如在C 语言中调用SQRT 函数，其要么返回正确的平方根值，要么返回错误的代码，而不会在不可预知的情况下改变任何的数据结构和参数。如果SQRT 函数被许多个程序调用，一个程序的返回值也不会是其他程序要计算的平方根。

​	然而在数据的事务中实现调用操作的原子性，就不是那么理所当然了。例如一个用户在ATM 机前取款，假设取款的流程为：

1. 登录ATM 机平台，验证密码。

2) 从远程银行的数据库中，取得账户的信息。

3) 用户在ATM 机上输入欲提取的金额。

4) 从远程银行的数据库中，更新账户信息。

5) ATM 机出款。

6) 用户取钱。

​	整个取款的操作过程应该视为原子操作，即要么都做，要么都不做。不能用户钱未从ATM 机上取得，但是银行卡上的钱已经被扣除了，相信这是任何人都不能接受的一种情况。而通过事物模型，可以保证该操作的原子性。

​	原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL 语句执行失败，已经执行成功的SQL 语句也必须撤销，数据库状态应该退回到执行事务前的状态。

​	如果事务中的操作都是只读的，要保持原子性是很简单的。一旦发生任何错误，要么重试，要么返回错误代码。因为只读操作不会改变系统中的任何相关部分。但是，当事务中的操作需要改变系统中的状态时，例如插入记录或更新记录，那么情况可能就不像只读操作那么简单了。如果操作失败，很有可能引起状态的变化，因此必须要保护系统中并发用户访问受影响的部分数据。

​	**C (consistency) ，一致性**。一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。例如，在表中有一个字段为姓名，为唯一约束，即在表中姓名不能重复。如果一个事务对姓名字段进行了修改，但是在事务提交或事务操作发生回滚后，表中的姓名变得非唯一了，这就破坏了事务的一致性要求，即事务将数据库从一种状态变为了一种不一致的状态。因此，事务是一致性的单位，如果事务中某个动作失败了，系统可以自动撤销事务——返回初始化的状态。

​	**I (isolation) ，隔离性**。隔离性还有其他的称呼，如并发控制(concurrency control) 、可串行化(serializability ）、锁（ locking) 等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，通常这使用锁来实现。当前数据库系统中都提供了一种粒度锁(granular lock) 的策略，允许事务仅锁住一个实体对象的子集，以此来提高事务之间的并发度。

​	**D (durability) ，持久性**。<u>事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。需要注意的是，只能从事务本身的角度来保证结果的永久性</u>。例如，在事务提交后，所有的变化都是永久的。即使当数据库因为崩溃而需要恢复时，也能保证恢复后提交的数据都不会丢失。<u>但若不是数据库本身发生故障，而是一些外部的原因，如RAID 卡损坏、自然灾害等原因导致数据库发生问题，那么所有提交的数据可能都会丢失</u>。**因此持久性保证事务系统的高可靠性(High Reliability)，而不是高可用性(High Availability ）。对于高可用性的实现，事务本身并不能保证，需要一些系统共同配合来完成**。

### 7.1.2 分类

​	从事务理论的角度来说，可以把事务分为以下几种类型：

+ 扁平事务(Flat Transactions)
+ 带有保存点的扁平事务(Flat Transactions with Savepoints)
+ 链事务(Chained Transactions)
+ 嵌套事务(Nested Transactions)
+ 分布式事务(Distributed Transactions)

​	**扁平事务(Flat Transaction)** 是事务类型中最简单的一种，但在实际生产环境中，这可能是使用最为频繁的事务。<u>在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK 开始，由COMMIT WORK 或ROLLBACK WORK 结束，其间的操作是原子的，要么都执行，要么都回滚。因此扁平事务是应用程序成为原子操作的基本组成模块</u>。图7-1 显示了扁平事务的三种不同结果。

![img](https://img-blog.csdnimg.cn/20181028000338888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_27,color_FFFFFF,t_70)

​	图7-1 扁平事务的三种情况

​	图7-1 给出了扁平事务的三种情况，同时也给出了在一个典型的事务处理应用中，每个结果大概占用的百分比。<u>再次提醒，扁平事务虽然简单，但在实际生产环境中使用最为频繁。正因为其简单，使用频繁，故每个数据库系统都实现了对扁平事务的支持</u>。

​	**扁平事务的主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交**。下面给出一个扁平事务不足以支持的例子。例如用户在旅行网站上进行自己的旅行度假计划。用户设想从杭州到意大利的佛罗伦萨，这两个城市之间没有直达的班机，需要用户预订并转乘航班，或者需要搭火车等待。用户预订旅行度假的事务为：

BEGIN WORK

Sl: 预订杭州到上海的高铁

S2: 上海浦东国际机场坐飞机，预订去米兰的航班

S3: 在米兰转火车前往佛罗伦萨，预订去佛罗伦萨的火车

​	但是当用户执行到S3 时，发现由于飞机到达米兰的时间太晚，已经没有当天的火车。这时用户希望在米兰当地住一晚，第二天出发去佛罗伦萨。这时如果事务为扁平事务，则需要回滚之前Sl 、S2 、S3 的三个操作，这个代价就显得有点大。因为当再次进行该事务时， Sl 、S2 的执行计划是不变的。也就是说，如果支持有计划的回滚操作，那么就不需要终止整个事务。因此就出现了带有保存点的扁平事务。

​	**带有保存点的扁平事务(Flat Transactions with Savepoint)** ，除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销也太大。<u>**保存点(Savepoint)** 用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态</u>。

​	**对于扁平的事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，因此，回滚只能回滚到事务开始时的状态**。<u>保存点用SAVE WORK函数来建立，通知系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点</u>。图7-2 显示了在事务中使用保存点。

​	图7-2 显示了如何在事务中使用保存点。灰色背景部分的操作表示由ROLLBACK WORK 而导致部分回滚，实际并没有执行的操作。当用BEGIN WORK 开启一个事务时，隐式地包含了一个保存点，当事务通过ROLLBACK WORK : 2 发出部分回滚命令时，事务回滚到保存点2，接着依次执行，并再次执行到ROLLBACK WORK : 7，直到最后的COMMIT WORK 操作，这时表示事务结束，除灰色阴影部分的操作外，其余操作都已经执行，并且提交。

​	另一点需要注意的是，**保存点在事务内部是递增的**，这从图7-2 中也能看出。有人可能会想，返回保存点2 以后，下一个保存点可以为3，因为之前的工作都终止了。然而新的保存点编号为5， 这意味着<u>ROLLBACK 不影响保存点的计数，并且单调递增的编号能保持事务执行的整个历史过程，包括在执行过程中的改变</u>。

​	<u>此外，当事务通过ROLLBACK WORK : 2 命令发出部分回滚命令时，要记住事务并没有完全被回滚，只是回滚到了保存点2 而已。这代表当前事务还是活跃的，如果想要完全回滚事务，还需要再执行命令ROLLBACK WORK</u>。

![img](https://img-blog.csdnimg.cn/20181028000732368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_27,color_FFFFFF,t_70)

​	图7-2 在事务中使用保存点

​	**链事务(Chained Transaction)** 可视为保存点模式的一种变种。<u>带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的(volatile)，而非持久的(persistent)</u> 。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。

​	**链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务**。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。图7-3 显示了链事务的工作方式：

![img](https://img-blog.csdnimg.cn/20181028001028222.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_27,color_FFFFFF,t_70)

​	<u>链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。对于锁的处理，两者也不相同。链事务在执行COMMIT 后即释放了当前事务所持有的锁，而带有保存点的扁平事务不影响迄今为止所持有的锁</u>。

​	**嵌套事务(Nested Transaction)** 是一个层次结构框架。由一个顶层事务(top-level transaction) 控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务(subtransaction) ，其控制每一个局部的变换。嵌套事务的层次结构如图7-4 所示。

![img](https://img-blog.csdnimg.cn/20181028001145124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_27,color_FFFFFF,t_70)

​	下面给出Moss 对嵌套事务的定义：

1) 嵌套事务是由若干事务组成的一棵树，子树既可以是嵌套事务，也可以是扁平事务。
2) 处在叶节点的事务是扁平事务。但是每个子事务从根到叶节点的距离可以是不同的。
3) 位于根节点的事务称为顶层事务，其他事务称为子事务。事务的前驱称(predecessor) 为父事务(parent) ，事务的下一层称为儿子事务(child) 。
4) 子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。因此可以推论出，<u>任何子事物都在顶层事务提交后才真正的提交</u>。
5) <u>树中的任意一个事务的回滚会引起它的所有子事务一同回滚</u>，故子事务仅保留A 、C 、I 特性，不具有D 的特性。

​	在Moss 的理论中，实际的工作是交由叶子节点来完成的，即只有叶子节点的事务才能访问数据库、发送消息、获取其他类型的资源。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务，如图7-5 所示。

![img](https://img-blog.csdnimg.cn/20181028001424528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_27,color_FFFFFF,t_70)

​	从图7-5 中也可以发现，在恢复时采用保存点技术比嵌套查询有更大的灵活性。例如在完成Tk3 这事务时，可以回滚到保存点S2 的状态。而在嵌套查询的层次结构中，这是不被允许的。

​	但是用保存点技术来模拟嵌套事务在锁的持有方面还是与嵌套查询有些区别。<u>当通过保存点技术来模拟嵌套事务时，用户无法选择哪些锁需要被子事务继承，哪些需要被父事务保留。这就是说，无论有多少个保存点，所有被锁住的对象都可以被得到和访问</u>。而在嵌套查询中，不同的子事务在数据库对象上持有的锁是不同的。例如有一个父事务P1其待有对象X 和Y 的排他锁，现在要开始一个调用子事务P11，那么父事务P1可以不传递锁，也可以传递所有的锁，也可以只传递一个排他锁。如果子事务P11 中还要持有对象Z 的排他锁，那么通过反向继承(counter-inherited) ，父事务P1 将持有3 个对象X 、Y 、Z 的排他锁。如果这时又再次调用了一个子事务P12 ，那么它可以选择传递那里已经持有的锁。

​	<u>然而，如果系统支持在嵌套事务中并行地执行各个子事务，在这种情况下，采用保存点的扁平事务来模拟嵌套事务就不切实际了。这从另一个方面反映出，想要实现事务间的并行性，需要真正支持的嵌套事务</u>。

​	<u>**分布式事务(Distributed Transactions)** 通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点</u>。

​	假设一个用户在ATM 机进行银行的转账操作，例如持卡人从招商银行的储蓄卡转账10 000 元到工商银行的储蓄卡。在这种情况下，可以将ATM 机视为节点A，招商银行的后台数据库视为节点B，工商银行的后台数据库视为C，这个转账的操作可分解为以下的步骤：

1. 节点A 发出转账命令。

2) 节点B 执行储蓄卡中的余额值减去10 000 。

3) 节点C 执行储蓄卡中的余额值加上10 000 。

4) 节点A 通知用户操作完成或者节点A 通知用户操作失败。

​	这里需要使用分布式事务，因为节点A 不能通过调用一台数据库就完成任务。其需要访问网络中两个节点的数据库，而在每个节点的数据库执行的事务操作又都是扁平的。对于分布式事务，其同样需要满足ACID 特性，要么都发生，要么都失效。对于上述的例子，如果2) 、3) 步中任何一个操作失败，都会导致整个分布式事务回滚。若非这样，结果会非常可怕。

​	<u>对于lnnoDB 存储引擎来说，其支持扁平事务、带有保存点的事务、链事务、分布式事务。对于嵌套事务，其并不原生支持，因此，对有并行事务需求的用户来说，MySQL 数据库或InnoDB 存储引擎就显得无能为力了。然而用户仍可以通过带有保存点的事务来榄拟串行的嵌套事务</u>。

## 7.2 事务的实现

​	**事务隔离性由第6章讲述的锁来实现**。**原子性、一致性、持久性通过数据库的redo log 和undo log 来完成**。redo log 称为重做日志，用来保证事务的原子性和持久性。undo log 用来保证事务的一致性。

​	有的DBA 或许会认为undo 是redo 的逆过程，其实不然。redo 和undo 的作用都可以视为是一种恢复操作， **redo 恢复提交事务修改的页操作，而undo 回滚行记录到某个特定版本**。因此两者记录的内容不同， **redo 通常是物理日志，记录的是页的物理修改操作。undo 是逻辑日志，根据每行记录进行记录**。

### 7.2.1 redo

#### * 1. 基本概念

​	**重做日志用来实现事务的持久性，即事务ACID 中的D** 。其由两部分组成：

+ 一是内存中的重做日志缓冲(redo log buffer) ，其是易失的；
+ 二是重做日志文件(redo log file)，其是持久的。

​	**InnoDB是事务的存储引擎，其通过Force Log at Commit机制实现事务的持久性，即<u>当事务提交(COMMIT) 时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成</u>**。

<u>这里的日志是指重做日志，在InnoDB 存储引擎中，由两部分组成，即redo log和undo log</u>。

+ **redo log用来保证事务的持久性**。redo log基本上都是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作。
+ **undo log用来帮助事务回滚及MVCC的功能**。而undo log是需要进行随机读写的。

​	**为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后， InnoDB 存储引擎都需要调用一次fsync 操作**。<u>由于重做日志文件打开并没有使用`O_DIRECT`选项，因此重做日志缓冲先写入文件系统缓存。为了确保重做日志写入磁盘，必须进行一次fsync 操作。**由于fsync 的效率取决于磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据库的性能**</u>。

​	lnnoDB 存储引擎允许用户手工设置非持久性的情况发生，以此提高数据库的性能。即当事务提交时，日志不写入重做日志文件，而是等待一个时间周期后再执行fsync 操作。由于并非强制在事务提交时进行一次fsync 操作，显然这可以显著提高数据库的性能。但是当数据库发生宅机时，由于部分日志未刷新到磁盘，因此会丢失最后一段时间的事务。

​	**参数`innodb_flush_log_at_trx_commit`用来控制重做日志刷新到磁盘的策略。该参数的默认值为1，表示事务提交时必须调用一次fsync 操作**。还可以设置该参数的值为0和2 。0表示事务提交时不进行写入重做日志操作，这个操作仅在master thread 中完成，而在master thread 中每1秒会进行一次重做日志文件的fsync 操作。2 表示事务提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync 操作。在这个设置下，当MySQL 数据库发生宕机而操作系统不发生宅机时，并不会导致事务的丢失。而当操作系统宕机时，重启数据库后会丢失未从文件系统缓存刷新到重做日志文件那部分事务。

​	**虽然用户可以通过设置参数`innodb_flush_log_at_trx_commit`为0或2来提高事务提交的性能，但是需要牢记的是，这种设置方法丧失了事务的ACID 特性**。

​	**在MySQL 数据库中还有一种二进制日志(binlog)，其用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立**。从表面上看其和重做日志非常相似，都是记录了对于数据库操作的日志。然而，从本质上来看，两者有着非常大的不同。

+ 首先，重做日志是在InnoDB 存储引擎层产生，而二进制日志是在MySQL 数据库的上层产生的，并且**二进制日志不仅仅针对于InnoDB 存储引擎， MySQL 数据库中的任何存储引擎对于数据库的更改都会产生二进制日志**。

+ 其次，两种日志记录的内容形式不同。**MySQL 数据库上层的二进制日志是一种逻辑日志，其记录的是对应的SQL 语句。而InnoDB 存储引擎层面的重做日志是物理格式日志，其记录的是对于每个页的修改**。

​	此外，两种日志记录写入磁盘的时间点不同，如图7-6 所示。

+ **二进制日志只在事务提交完成后进行一次写入**。
+ **而InnoDB 存储引擎的重做日志在事务进行中不断地被写入**，这表现为日志并不是随事务提交的顺序进行写入的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201223155905772.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM5MDU3NDQ=,size_16,color_FFFFFF,t_70)

​	图7-6 二进制日志与重做日志的写入的时间点不同

​	从图7-6 中可以看到，<u>二进制日志仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于lnnoDB 存储引擎的重做日志，由于其记录的是物理操作日志，因此每个事务对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入，故其在文件中记录的顺序并非是事务开始的顺序</u>。\*T1 、\*T2 、\*T3表示的是事务提交时的日志。

#### 2. log block

​	在InnoDB存储引擎中，重做日志都是以512字节进行存储的。这意味着<u>重做日志缓存、重做日志文件都是以块(block) 的方式进行保存的，称之为重做日志块(redo log block) ，每块的大小为512 字节</u>。

​	若一个页中产生的重做日志数量大于512 字节，那么需要分割为多个重做日志块进行存储。此外，**由于重做日志块的大小和磁盘扇区大小一样，都是512 字节，因此<u>重做日志的写入可以保证原子性</u>，不需要doublewrite 技术**。

​	重做日志块除了日志本身之外，还由日志块头(log block header) 及日志块尾(log block tailer) 两部分组成。重做日志头一共占用12 字节，重做日志尾占用8 字节。故每个重做日志块实际可以存储的大小为492 字节(512-12-8) 。图7-7 显示了重做日志块缓存的结构。

![在这里插入图片描述](https://img-blog.csdnimg.cn/eafb6ed254ff43278f1a3318e2753e29.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	图7-7 重做日志块缓存的结构

​	图7-7 显示了重做日志缓存的结构，可以发现重做日志缓存由每个为512 字节大小的日志块所组成。日志块由三部分组成，依次为日志块头(log block header) 、日志内容(log body) 、日志块尾(log block tailer) 。

​	log block header 由4 部分组成，如表7-2 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/08e2cd84046e4fb7876042dbc3c7fda5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	log buffer 是由log block 组成，在内部log buffer 就好似一个数组，因此`LOG_BLOCK_HDR_NO`用来标记这个数组中的位置。其是递增并且循环使用的，占用4 个字节，但是由于第一位用来判断是否是flush bit，所以最大的值为2G。

​	`LOG_BLOCK_HDR_DATA_LEN`占用2 字节，表示log block 所占用的大小。当log block 被写满时，该值为0x200，表示使用全部log block 空间，即占用512 字节。

​	`LOG_BLOCK_FIRST_REC_GROUP`占用2 个字节，表示log block 中第一个日志所在的偏移数量。如果该值的大小和`LOG_BLOCK_HDR_DATA_LEN`相同，则表示当前logblock 不包含新的日志。如事务T1的重做日志1占用762 字节，事务T2 的重做日志占用100 字节。由于每个log block 实际只能保存492 个字节，因此其在log buffer 中的情况应如图7-8 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/090100ff6d634df08b5ee95afd1656dc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	图7-8 LOG_BLOCK_FIRST_REC_GROUP 的例子

​	从图7-8 中可以观察到，由于事务T1的重做日志占用792 字节，因此需要占用两个log block 。左侧的log block 中`LOG_BLOCK_FIRST_REC_GROUP`为12, 即log block中第一个日志的开始位置。在第二个log block 中，由于包含了之前事务T1的重做日志，事务T2 的日志才是log block 中第一个日志，因此该log block 的`LOG_BLOCK_FIRST_REC_GROUP`为282 (270+12) 。

​	`LOG_BLOCK_CHECKPOINT_NO` 占用4 字节，表示该log block 最后被写入时的检查点第4字节的值。

​	log block tailer 只由1 个部分组成（如表7-3 所示），且其值和`LOG_BLOCK_HDR_NO`相同，并在函数log_block_init 中被初始化。

![在这里插入图片描述](https://img-blog.csdnimg.cn/bf761bc96b2440adb124c809456138f1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 3. log group

​	log group 为重做日志组，其中有多个重做日志文件。虽然源码中已支持log group的镜像功能，但是在ha_innobase.cc 文件中禁止了该功能。因此InnoDB 存储引擎实际只有一个log group 。

​	log group 是一个逻辑上的概念，并没有一个实际存储的物理文件来表示log group信息。log group 由多个重做日志文件组成，每个log group 中的日志文件大小是相同的，且在InnoDB 1.2 版本之前，重做日志文件的总大小要小于4GB （不能等于4GB) 。从InnoDB 1.2 版本开始重做日志文件总大小的限制提高为了512GB 。InnoSQL 版本的InnoDB 存储引擎在1.1 版本就支持大于4GB 的重做日志。

​	重做日志文件中存储的就是之前在log buffer 中保存的log block，因此其也是根据块的方式进行物理存储的管理，每个块的大小与log block 一样，同样为512 字节。在InnoDB 存储引擎运行过程中， log buffer 根据一定的规则将内存中的log block 刷新到磁盘。这个规则具体是：

+ 事务提交时

+ 当log buffer 中有一半的内存空间已经被使用时

+ log checkpoint 时

​	对于log block 的写入追加(append) 在redo log file 的最后部分，当一个redo logfile 被写满时，会接着写入下一个redo log file，其使用方式为round-robin 。

​	虽然log block 总是在redo log file 的最后部分进行写入，有的读者可能以为对redo log file 的写人都是顺序的。其实不然，因为redo log file 除了保存log buffer 刷新到磁盘的log block，还保存了一些其他的信息，这些信息一共占用2KB 大小，即每个redo log file 的前2KB的部分不保存log block的信息。对于log group 中的第一个redo log file，其前2KB 的部分保存4 个512 字节大小的块，其中存放的内容如表7-4 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/f65934403b28473bbb3ed5fe833b4c90.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	需要特别注意的是，上述信息仅在每个log group 的第一个redo log file 中进行存储。log group 中的其余redo log file 仅保留这些空间，但不保存上述信息。正因为保存了这些信息，就意味着对redo log file 的写入并不是完全顺序的。因为其除了log block 的写入操作，还需要更新前2KB 部分的信息，这些信息对于InnoDB 存储引擎的恢复操作来说非常关键和重要。故log group 与redo log file 之间的关系如图7-9 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/8e854ae5f430464db178cdf27bb2d158.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	图7-9 log group 与redo log file 之间的关系

​	在log filer header 后面的部分为InnoDB 存储引擎保存的checkpoint （检查点）值，其设计是交替写入，这样的设计避免了因介质失败而导致无法找到可用的checkpoint 的情况。

#### 4. 重做日志格式

​	不同的数据库操作会有对应的重做日志格式。此外，由于InnoDB 存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。虽然有着不同的重做日志格式，但是它们有着通用的头部格式，如图7-10 所示。

![687d755bb7e25be2d32d49ca4f1a7295.png](https://img-blog.csdnimg.cn/img_convert/687d755bb7e25be2d32d49ca4f1a7295.png)

​	图7-10 重做日志格式

​	通用的头部格式由以下3 部分组成：

+ redo_log_type: 重做日志的类型。

+ space: 表空间的ID 。

+ page_no: 页的偏移量。

​	之后redo log body 的部分，根据重做日志类型的不同，会有不同的存储内容，例如，对于页上记录的插入和删除操作，分别对应如图7-11 所示的格式：

![ec47d283f86dfc2e1775e2e17d9c95f1.png](https://img-blog.csdnimg.cn/img_convert/ec47d283f86dfc2e1775e2e17d9c95f1.png)

​	到InnoDB1.2 版本时，一共有51种重做日志类型。随若功能不断地增加，相信会加入越来越多的重做日志类型。

#### * 5. LSN

​	<u>LSN 是Log Sequence Number 的缩写，其代表的是日志序列号</u>。在InnoDB 存储引挚中， LSN 占用8 字节，并且单调递增。LSN 表示的含义有：

+ 重做日志写入的总量

+ **checkpoint 的位置**

+ **页的版本**

​	LSN 表示事务写入重做日志的字节的总散。例如当前重做日志的LSN 为1 000，有一个事务T1 写入了100 字节的重做日志，那么LSN 就变为了1100，若又有事务T2 写入了200 字节的重做日志，那么LSN 就变为了1300 。可见LSN 记录的是重做日志的总量，其单位为字节。

​	LSN 不仅记录在重做日志中，还存在于每个页中。在每个页的头部，有一个值`FIL_PAGE_LSN`，记录了该页的LSN 。<u>在页中， LSN 表示该页最后刷新时LSN 的大小。因为重做日志记录的是每个页的日志，因此页中的LSN 用来判断页是否需要进行恢复操作</u>。例如，页P1的LSN 为10 000，而数据库启动时， lnnoDB 检测到写入重做日志中的LSN 为13000，并且该事务已经提交，那么数据库需要进行恢复操作，将重做日志应用到P1页中。同样的，对于重做日志中LSN 小于P1页的LSN，不需进行重做，因为P1页中的LSN 表示页已经被刷新到该位置。

​	用户可以通过命令`SHOW ENGINE INNODB STATUS`查看LSN 的情况：

```shell
mysql> SHOW ENGINE INNODB STATUS\G;
...
---
LOG
---
Log sequence number 11 3047174608
Log flushed up to 11 3047174608
Last checkpoint at 11 3047174608
0 pending log writes, 0 pending chkp writes
142 log i/o's done, 0.00 log i/o's/second
......
l row in set (0.00 sec)
```

​	Log sequence number 表示当前的LSN，Log flushed up to 表示刷新到重做日志文件的LSN, Last checkpoint at 表示刷新到磁盘的LSN 。

​	虽然在上面的例子中， Log sequence number 和Log flushed up to 的值是相同的，但是在实际生产环境中，该值有可能是不同的。因为在一个事务中从日志缓冲刷新到重做日志文件并不只是在事务提交时发生，每秒都会有从日志缓冲刷新到重做日志文件的动作。下面是在生产环境下重做日志的信息的示例。

```shell
mysql> show engine innodb status\G;
---
LOG
---
Log sequence number 203318213447
Log flushed up to 203318213326
Last checkpoint at 203252831194
l pending log writes, 0 pending chkp writes
103447 log i/o"s done, 7.00 log i/o's/second
......
1 row in set (0.00 sec)
```

​	可以看到，在生产环境下Log sequence number、Log flushed up to 、Last checkpoint at 三个值可能是不同的。

#### * 6. 恢复

+ **bin log二进制日志即使设置ROW，也非幂等**
+ **redo log重做日志是物理日志，是幂等的**

---

​	**InnoDB 存储引擎在启动时不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作**。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如二进制日志，要快很多。与此同时， InnoDB 存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步地提高数据库恢复的速度。

​	由千checkpoint 表示已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint 开始的日志部分。对于图7-12 中的例子，当数据库在checkpoint 的LSN 为10 000 时发生宕机，恢复操作仅恢复LSN 10 000 ～ 13 000 范围内的日志。

![0654899dcbb3a103d4450ceace0cd240.png](https://img-blog.csdnimg.cn/img_convert/0654899dcbb3a103d4450ceace0cd240.png)

​	**InnoDB 存储引擎的重做日志是物理日志，因此其恢复速度较之二进制日志恢复快得多**。例如对于INSERT 操作，其记录的是每个页上的变化。对于下面的表：

```sql
CREATE TABLE t (a INT, b INT, PRIMARY KEY (a), KEY (b));
```

​	若执行SQL 语句：

```sql
INSERT INTO t SELECT 1,2;
```

​	由于需要对聚集索引页和辅助索引页进行操作，其记录的重做日志大致为：

```log
page(2,3), offset 32, value 1,2 #聚集索引
page(2,4), offset 64, value 2 	#辅助索引
```

​	可以看到记录的是页的物理修改操作，若插入涉及B＋树的split，可能会有更多的页需要记录日志。此外，由于**重做日志是物理日志，因此其是幂等的**。幕等的概念如下：
$$
f(f(x)) =f(x)
$$
​	<u>有的DBA 或开发人员错误地认为只要将二进制日志的格式设置为ROW，那么二进制日志也是幂等的。这显然是错误的，举个简单的例子， **INSERT 操作在二进制日志中就不是幂等的，重复执行可能会插入多条重复的记录。而上述INSERT 操作的重做日志是幂等的**</u>。

### 7.2.2 undo

#### * 1. 基本概念

+ 事务回滚依赖undo log
+ undo是逻辑日志，将数据库逻辑恢复原状，如：对于INSERT操作会生成对应的DELETE逻辑语句
+ InnoDB引擎的MVCC通过undo log来实现
+ 用户执行ROLLBACK回滚事务时，之前已占用的表空间大小不会马上缩容，undo log执行事务相反的逻辑
+ **undo log也会产生redo log，因为undo log也需要持久化的保护**

---

​	重做日志记录了事务的行为，可以很好地通过其对页进行“重做“操作。**但是事务有时还需要进行回滚操作，这时就需要undo** 。因此**在对数据库进行修改时， InnoDB 存储引擎不但会产生redo，还会产生一定量的undo**。这样<u>如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK 语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子</u>。

​	redo 存放在重做日志文件中，与redo 不同， undo 存放在数据库内部的一个特殊段(segment) 中，这个段称为undo 段(undo segment) 。undo 段位于共享表空间内。

​	用户通常对undo 有这样的误解： undo 用于将数据库物理地恢复到执行语句或事务之前的样子——但事实并非如此。<u>**undo 是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子**。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同</u>。这是因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调对数据记录的并发访问。比如，一个事务在修改当前一个页中某几条记录，同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将一个页回滚到事务开始的样子，因为这样会影响其他事务正在进行的工作。

​	例如，用户执行了一个INSERT 10W 条记录的事务，这个事务会导致分配一个新的段，即表空间会增大。**在用户执行ROLLBACK 时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩**。<u>因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作</u>。

+ 对于每个INSERT，InnoDB 存储引擎会完成一个DELETE；
+ 对于每个DELETE，InnoDB 存储引擎会执行—个INSERT；
+ 对于每个UPDATE，InnoDB 存储引擎会执行一个相反的UPDATE，将修改前的行放回去。

​	**除了回滚操作， undo 的另一个作用是MVCC，即<u>在InnoDB 存储引擎中MVCC 的实现是通过undo 来完成</u>**。<u>当用户读取一行记录时，**若该记录已经被其他事务占用，当前事务可以通过undo 读取之前的行版本信息**，以此实现非锁定读取</u>。

​	最后也是最为重要的一点是， **<u>undo log 会产生redo log，也就是undo log 的产生会伴随着redo log 的产生，这是因为undo log 也需要持久性的保护</u>**。

#### * 2. undo存储管理

+ **事务提交后并不能马上删除undo log 及undo log 所在的页。这是因为可能还有其他事务需要通过undo log 来得到行记录之前的版本**。<u>故事务提交时将undo log 放入一个链表中，是否可以最终删除undo log 及undo log 所在页由**purge 线程**来判断</u>。
+ 若为每一个事务分配一个单独的undo 页会非常浪费存储空间，特别是对于OLTP的应用类型。因为在事务提交时，可能并不能马上释放页
+ 由于存放undo log 的列表是以记录进行组织的，而undo 页可能存放着不同事务的undo log，因此<u>purge 操作需要涉及磁盘的离散读取操作</u>，是一个比较缓慢的过程

---

​	<u>InnoDB 存储引擎对undo的管理同样采用段的方式。但是这个段和之前介绍的段有所不同</u>。首先lnnoDB 存储引擎有rollback segment，每个回滚段中记录了1024 个undolog segment，而在每个undo log segment 段中进行undo 页的申请。共享表空间偏移量为5 的页（0，5) 记录了所有rollback segment header 所在的页，这个页的类型为`FIL_PAGE_TYPE_SYS`。

​	在lnnoDB1.1版本之前（不包括1.1 版本），只有一个rollback segment，因此支持同时在线的事务限制为1024。虽然对绝大多数的应用来说都已经够用，但不管怎么说这是一个瓶颈。从1.1版本开始InnoDB 支持最大128 个rollback segment，其支持同时在线的事务限制提高到了128*1024 。

​	虽然InnoDB1.1 版本支持了128 个rollback segment，但是这些rollback segment 都存储于共享表空间中。从InnoDB1.2 版本开始，可通过参数对rollback segment 做进一步的设置。这些参数包括：

+ innodb_undo_directory

  参数`innodb_undo_directory`用于设置rollback segment 文件所在的路径。这意味着rollback segment 可以存放在共享表空间以外的位置，即可以设赏为独立表空间。该参数的默认值为“.“，表示当前JnnoDB 存储引擎的目录。

+ innodb_undo_logs

  参数`innodb_undo_logs` 用来设置rollback segment 的个数，默认值为128。在InnoDB1.2版本中，该参数用来替换之前版本的参数`innodb_rollback_segments`。

+ innodb_undo_tablespaces

  参数`innodb_undo_tablespaces`用来设置构成rollback segment 文件的数量，这样<u>rollback segment 可以较为平均地分布在多个文件中</u>。设置该参数后，会在路径`innodb_undo_directory`看到undo 为前缀的文件，该文件就代表rollback segment 文件。

​	图7-13 的示例显示了由3 个文件组成的rollback segment 。

![img](https://img-blog.csdnimg.cn/20181031232445604.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	图7-13 由3 个文件组成的rollback segment

​	**<u>需要特别注意的是，事务在undo log segment 分配页并写入undo log 的这个过程同样需要写入重做日志</u>**。

​	当事务提交时， InnoDB 存储引擎会做以下两件事情：

+ 将undo log 放入列表中，以供之后的purge操作

+ 判断undo log所在的页是否可以重用，若可以则分配给下个事务使用

​	**事务提交后并不能马上删除undo log 及undo log 所在的页。这是因为可能还有其他事务需要通过undo log 来得到行记录之前的版本**。<u>故事务提交时将undo log 放入一个链表中，是否可以最终删除undo log 及undo log 所在页由**purge 线程**来判断</u>。

​	此外，**若为每一个事务分配一个单独的undo 页会非常浪费存储空间，特别是对于OLTP的应用类型。因为在事务提交时，可能并不能马上释放页**。假设某应用的删除和更新操作的TPS (transaction per second) 为1000，为每个事务分配一个undo 页，那么一分钟就需要1000*60 个页，大约需要的存储空间为1GB。若每秒的purge 页的数量为20 ，这样的设计对磁盘空间有着相当高的要求。因此，**在lnnoDB 存储引擎的设计中对undo 页可以进行重用**。<u>具体来说当事务提交时，首先将undo log 放入链表中，然后判断undo 页的使用空间是否小于3/4，若是则表示该undo 页可以被重用，之后新的undo log 记录在当前undo log 的后面</u>。**由于存放undo log 的列表是以记录进行组织的，而undo 页可能存放着不同事务的undo log，因此<u>purge 操作需要涉及磁盘的离散读取操作</u>，是一个比较缓慢的过程**。

​	可以通过命令`SHOW ENGINE INNODB STATUS`来查看链表中undo log 的数量，如：

![img](https://img-blog.csdnimg.cn/20181031232857887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	History list length 就代表了undo log 的数量，这里为12 。<u>purge 操作会减少该值。然而由于undo log 所在的页可以被重用，因此即使操作发生， History list length 的值也可以不为0</u> 。

#### * 3. undo log 格式

在InnoDB存储引擎中， undo log 分为：

+ insert undo log

+ update undo log

​	**insert undo log 是指在insert 操作中产生的undo log。<u>因为insert 操作的记录，只对事务本身可见，对其他事务不可见（这是事务隔离性的要求），故该undo log 可以在事务提交后直接删除。不需要进行purge操作</u>**。insert undo log 的格式如图7-14 所示。

![img](https://pic2.zhimg.com/80/v2-bc94547f501ea9e40dfe35280dd17679_1440w.jpg)

​	图7-14 insert undo log 的格式

​	图7-14 显示了insert undo log 的格式，其中＊表示对存储的字段进行了压缩，insert undo log开始的前两个字节next 记录的是下一个undo log 的位置，通过该next 的字节可以知道一个undo log 所占的空间字节数。类似地，尾部的两个字节记录的是undo log 的开始位置。type_cmpl占用一个字节，记录的是undo 的类型，对于insert undo log，该值总是为11。undo_no 记录事务的ID，table_id 记录undo log 所对应的表对象。这两个值都是在压缩后保存的。接着的部分记录了所有主键的列和值。在进行rollback 操作时，根据这些值可以定位到具体的记录，然后进行删除即可。

​	**update undo log 记录的是对delete 和update 操作产生的undo log。<u>该undo log 可能需要提供MVCC 机制，因此不能在事务提交时就进行删除。提交时放入undo log 链表，等待purge 线程进行最后的删除</u>**。update undo log 的结构如图7-15 所示。

![img](https://pic4.zhimg.com/80/v2-59c34b737c4cc9f053390d1c11f5e883_1440w.jpg)

​	update undo log 相对于之前介绍的insert undo log，记录的内容更多，所需占用的空间也更大。next、start、undo_no、table_id与之前介绍的insert undo log部分相同。这里type_cmpl，由于update undo log本身还有分类，故可能的值如下：

+ 12 `TRX_UNDO_UPD_EXIST_REC` 更新non-delete-mark 的记录

+ 13 `TRX_UNDO_UPD_DEL_REC` 将delete 的记录标记为not delete

+ 14 `TRX_UNDO_DEL_MARK_REC` 将记录标记为delete

​	接着的部分记录update_vector信息， update_vector表示update操作导致发生改变的列。每个修改的列信息都要记录的undo log中。对于不同的undo log类型，可能还需要记录对索引列所做的修改。

#### * 4. 查看undo 信息

+ `INNODB_TRX_ROLLBACK_SEGMENT`数据字典表用来查看rollback segment

+ `INNODB_TRX_UNDO`数据字典表用来记录事务对应的undo log
+ 事务提交时，undo页不会直接销毁，根据前面介绍的undo页重用，下次再有事务需要向该rollback segment 申请undo 页时，可以直接使用该页
+ <u>delete 操作并不直接删除记录，而只是将记录标记为已删除，也就是将记录的delete flag 设置为1 。而**记录最终的删除是在purge 操作中完成的**</u>
+ **update操作**：
  + **非主键**的操作。只产生一个类型为TRX_UNDO_UPD_EXIST_REC的undo log
  +  **主键**的操作分两步完成。首先将原主键记录标记为己删除，因此需要产生一个类型为TRX_UNDO_DEL_MARK_REC 的undo log，之后插入一条新的记录，因此需要产生一个类型为TRX_UNDO_INSERT _REC 的undo log

---

​	Oracle 和Microsoft SQL Server 数据库都由内部的数据字典来观察当前undo 的信息，InnoDB 存储引擎在这方面做得还不够， DBA 只能通过原理和经验来进行判断。<u>InnoSQL对information_schema 进行了扩展，添加了两张数据字典表，这样用户可以非常方便和快捷地查看undo 的信息</u>。

​	首先增加的数据字典表为`INNODB_TRX_ROLLBACK_SEGMENT`。顾名思义，这个数据字典表用来查看rollback segment，其表结构如图7-16 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609204619445.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	例如，可以通过如下的命令来查看rollback segment 所在的页：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609204832217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	另一张数据字典表为`INNODB_TRX_UNDO`，用来记录事务对应的undo log，方便DBA 和开发人员详细了解每个事务产生的undo量。下面将演示如何使用`INNODB_TRX_UNDO`表，首先根据如下代码创建测试表t 。

```sql
CREATE TABLE t (
  a INT,
  b VARCHAR(32),
  PRIMARY KEY (a),
  KEY(b)
)ENGINE=InnoDB;
```

​	接着插入一条记录，并尝试通过`INNODB_TRX_UNDO`观察该事务的undo log 的情况：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609204951547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	通过数据字典表可以看到，事务ID 为3001，rollback segment 的ID 为2，因为是该条事务的第一个操作，故undo_rec_no 为0 。之后可以看到插入的类型为`TRX_UNDO_INSERT_REC`，表示是insert undo log。size 表示undo log 的大小，占用12 字节。最后的space 、page_no 、offset 表示undo log 开始的位置。打开文件ibdata1，定位到页(334，272) ，并读取12 字节，可得到如下内容：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609205646502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	此外，由于知道该undo log 所在的rollback segment 的ID 为2，用户还可以通过数据字典表`INNODB_TRX_ROLLBACK_SEGMENT`来查看当前rollback segment 的信息，如：

```shell
mysql> SELECT segment_id,insert_undo_list,insert_undo_cached
		-> FROM information schema.INNODB_TRX_ROLLBACK_SEGMENT
		-> WHERE segment_id=2\G;
*************************** 1. row***************************
segment_id: 2
insert undo list: 1
insert undo cached: O
1 row in set (0.00 sec)
```

​	可以看到insert_undo_list 为1。若这时进行事务的COMMIT 操作，再查看该数据字典表：

```shell
mysql> COMMIT;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT segment_id,insert_undo_list,insert_undo_cached
		-> FROM information schema.INNODB_TRX_ROLLBACK_SEGMENT
		-> WHERE segment_id=2\G;
*************************** 1. row***************************
segment_id: 2
insert undo list: 0
insert undo cached: 1
1 row in set (0.00 sec)
```

​	可以发现， <u>insert_undo_ list 变为0。而insert_undo_cached 增加为1。这就是前面所介绍的undo页重用</u>。<u>下次再有事务需要向该rollback segment 申请undo 页时，可以直接使用该页</u>。

​	接着再来观察delete 操作产生的undo log。进行如下操作：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609220051974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200609220128990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	观察rollback segment 信息，可以看到：

```shell
mysql> SELECT segrnent_id,update_undo_list,update_undo_cached
		-> FROM information scherna.INNODB TRX ROLLBACK SEGMENT
		-> WHERE segment_id=2\G;
********************＊＊食＊＊＊＊ 1. row***************************
segment_id: 2
update_undo_list: 1
update_undo_cached: 0
1 row in set (0.00 sec)
```

​	同样的，在事务提交后， undo 页会放入cache 列表以供下次重用：

```shell
mysql> COMMIT;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT segment_id,update_undo_list,update_undo_cached
		-> FROM information schema.INNODB TRX ROLLBACK SEGMENT
		-> WHERE segment_id=2\G;
*************************** 1. row***************************
segment_id: 2
update undo list: O
update_undo_cached: l
l row in set (0.00 sec)
```

​	通过上面的例子可以看到， <u>delete 操作并不直接删除记录，而只是将记录标记为已删除，也就是将记录的delete flag 设置为1 。而**记录最终的删除是在purge 操作中完成的**</u>。

​	最后来看update 操作产生的undo log 情况。首先再次插入记录(1, '1') ，然后进行update 操作，同时通过数据字典表`INNODB_TRX_UNDO`观察undo log 的情况：

```shell
mysql>INSERT INTO t SELECT 1,'l';
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> UPDATE t SET b='2'WHERE a=l;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1 Changed: 1 Warnings: 0

mysql> SELECT* FROM information schema.INNODB TRX UNDO\G;
*************************** 1. row***************************
trx_id: 3205
rseg_id: 5
undo_rec_no: 0
undo_rec_ty-pe: TRX_UNDO_UPD_EXIST_REC
size: 41
space: O
page no: 318
offset: 724
1 row in set (0.00 sec)
```

​	用上述同样的方法定位到页318，偏移址为724 的位置，得到如下结果：

```shell
04f82d0 00 00 00 00 02 fd Oc 00 16 00 00 00 00 32 04 eO
04f82e0 84 00 00 01 48 01 10 04 80 00 00 01 01 03 01 31
04f82f0 00 Ob 00 04 80 00 00 01 03 01 31 02 d4 00 00 00
```

​	整理后得到：

```shell
02 fd ＃下一个undo log 的开始位竖
Oc # undo log 类型， TRX UNDO UPD DEL REC 为13
00 # undo no
16 # table id
00 # info bits
00 00 00 32 04 eO # rec trx id
84 00 00 01 48 01 10 # rec 回滚指针
04 ＃主键长度
80 00 00 01 ＃主键值
01 # update vector 的数量
03 # update vector 列b 的编号
01 # update vector 列的长度
31 # update vector 列的值，这里是'l'
00 Ob ＃接下去部分占用的字节
00 ＃列的位置
04 ＃列的长度
80 00 00 01 ＃列的值
03 ＃列的长度
31 ＃列的值
02 d4 # undo log 开始位置的偏移昼
```

​	<u>上面的例子是更新一个非主键值，若更新的对象是一个主键值，那么其产生的undolog 完全不同</u>，如：

```shell
mysql> ROLLBACK;
Query OK, 1 row affected (0.00 sec)

mysql> UPDATE t SET a=2 WHERE a=l;
Rows matched: 1 Changed: 1 Warnings: 0

mysql>. SELECT * FROM information_schema.INNODB_TRX_UNDO
-> ORDER BY undo_rec_no\G;
"************** ********* 1. row******* ＊*＊＊＊＊＊＊＊*＊＊＊*****
trx id: 320F
rseg_id: 11
undo rec no: 0
undo_rec_type: TRX_UNDO_DEL_MARK_REC
size: 37
space: 0
page no: 324
offset: 492
*************************** 2. row ＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊ * ** *
trx id: 320F
rseg_id: 11
undo rec no: 1
undo rec type: TRX_UNDO_INSERT_REC
size: 12
space: 0
page no: 336
offset: 272
2 rows in set (0.00 sec)
```

​	可以看到， <u>update **主键**的操作其实分两步完成。首先将原主键记录标记为己删除，因此需要产生一个类型为TRX_UNDO_DEL_MARK_REC 的undo log，之后插入一条新的记录，因此需要产生一个类型为TRX_UNDO_INSERT _REC 的undo log</u> 。undo_rec_no 显示了产生日志的步骤。对undo log 不再详细进行分析，相关内容和之前介绍的并无不同。

​	总之， InnoSQL 数据库提供的关于undo 信息的数据字典表可以帮助DBA 和开发人员更好地了解当前各个事务产生的undo 信息。

### * 7.2.3 purge

​	delete 和update 操作可能并不直接删除原有的数据。例如，对上一小节所产生的表t执行如下的SQL 语句：

```sql
DELETE FROM t WHERE a=l;
```

​	表t 上列a 有聚集索引，列b 上有辅助索引。对于上述的delete 操作，通过前而关于undo log 的介绍已经知道仅是将主键列等于1 的记录delete flag 设置为1，记录并没有被删除，即记录还是存在于B＋树中。**其次，对辅助索引上a 等于1，b 等于1 的记录同样没有做任何处理，甚至没有产生undo log** 。<u>而真正删除这行记录的操作其实被“延时“了，最终在purge 操作中完成</u>。

​	**purge 用于最终完成delete 和update 操作。这样设计是因为InnoDB 存储引擎支持MVCC，所以记录不能在事务提交时立即进行处理。这时其他事物可能正在引用这行，故InnoDB 存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge 来进行判断**。<u>若该行记录已不被任何其他事务引用，那么就可以进行真正的delete 操作</u>。可见， purge 操作是清理之前的delete 和update 操作，将上述操作“最终“完成。而实际执行的操作为delete 操作，清理之前行记录的版本。

​	在前一个小节中已经介绍过，**为了节省存储空间， InnoDB 存储引擎的undo log 设计是这样的：一个页上允许多个事务的undo log 存在**。虽然这不代表事务在全局过程中提交的顺序，但是后面的事务产生的undo log 总在最后。此外， **<u>InnoDB 存储引擎还有一个history 列表，它根据事务提交的顺序，将undo log 进行链接</u>**。如下面的一种情况：

![img](https://pic3.zhimg.com/80/v2-9be945521dcb7e99f89302129d40196e_1440w.jpg)

​	在图7-17 的例子中， <u>history list 表示按照事务提交的顺序将undo log 进行组织</u>。**在InnoDB 存储引擎的设计中，先提交的事务总在尾端**。undo page 存放了undo log，由于可以重用，因此一个undo page 中可能存放了多个不同事务的undo log。<u>trx5 的灰色阴影表示该undo log 还被其他事务引用</u>。

​	在执行purge 的过程中， InnoDB 存储引擎首先从history list 中找到第一个需要被清理的记录，这里为trx1，清理之后InnoDB 存储引擎会在trx1的undo log 所在的页中继续寻找是否存在可以被清理的记录，这里会找到事务trx3，接着找到trx5，但是发现trx5 被其他事务所引用而不能清理，故去再次去history list 中查找，发现这时最尾端的记录为trx2，接着找到trx2 所在的页，然后依次再把事务trx6 、trx4 的记录进行清理。<u>由于undo page2 中所有的页都被清理了，因此该undo page 可以被重用</u>。

​	**lnnoDB 存储引擎这种先从history list 中找undo log，然后再从undo page 中找undo log 的设计模式是为了避免大批的随机读取操作，从而提高purge 的效率**。

​	全局动态参数innodb_purge_batch_ size 用来设置每次purge 操作需要清理的undo page 数量。在InnoDB1.2 之前，该参数的默认值为20 。而从1.2 版本开始，该参数的默认值为300。

+ 通常来说，该参数设置得越大，每次回收的undo page 也就越多，这样可供重用的undo page 就越多，减少了磁盘存储空间与分配的开销。
+ <u>不过，若该参数设置得太大，则每次需要purge 处理更多的undo page，从而导致CPU 和磁盘IO 过于集中于对undo log 的处理，使性能下降</u>。

​	因此对该参数（innodb_purge_batch_ size）的调整需要由有经验的DBA 来操作，并且需要长期观察数据库的运行的状态。正如官方的MySQL 数据库手册所说的，普通用户不需要调整该参数。

​	<u>当InnoDB 存储引擎的压力非常大时，并不能高效地进行purge 操作。那么history list 的长度会变得越来越长。全局动态参数innodb_max_purge_lag 用来控制history list 的长度，若长度大于该参数时，其会“延缓“DML 的操作</u>。**该参数默认值为0，表示不对history list 做任何限制。当大于0时，就会延缓DML 的操作**，其延缓的算法为：
$$
delay = ((length (history_list) - innodb\_max\_purge\_lag)*10)-5
$$
​	delay 的单位是毫秒。**此外，需要特别注意的是， delay 的对象是行，而不是一个DML 操作**。<u>例如当一个update 操作需要更新5 行数据时，每行数据的操作都会被delay，故总的延时时间为5*delay 。而delay 的统计会在每一次purge 操作完成后，重新进行计算</u>。

​	<u>lnnoDB1.2 版本引入了新的全局动态参数`innodb_max_purge_lag_delay`，其用来控制delay 的最大毫秒数。也就是当上述计算得到的delay 值大于该参数时，将delay 设置为`innodb_max_purge_lag_delay`，避免由于purge 操作缓慢导致其他SQL 线程出现无限制的等待</u>。

### * 7.2.4 group commit

​	**若事务为非只读事务，则每次事务提交时需要进行一次fsync 操作，以此保证重做日志都已经写入磁盘**。当数据库发生宕机时，可以通过重做日志进行恢复。虽然固态硬盘的出现提高了磁盘的性能，然而磁盘的fsync 性能是有限的。**为了提高磁盘fsync 的效率，当前数据库都提供了group commit 的功能，即一次fsync 可以刷新确保多个事务日志被写入文件**。对于InnoDB 存储引擎来说，事务提交时会进行两个阶段的操作：

1) **修改内存中事务对应的信息，并且将日志写入重做日志缓冲**。

2) **调用fsync 将确保日志都从重做日志缓冲写入磁盘**。

​	<u>步骤2) 相对步骤1) 是一个较慢的过程，这是因为存储引擎需要与磁盘打交道。但当有事务进行这个过程时，其他事务可以进行步骤1) 的操作，正在提交的事物完成提交操作后，再次进行步骤2) 时，可以将多个事务的重做日志通过一次fsync 刷新到磁盘，这样就大大地减少了磁盘的压力，从而提高了数据库的整体性能。对于写入或更新较为频繁的操作， group commit 的效果尤为明显</u>。

​	**然而在InnoDB1.2 版本之前，在开启二进制日志后， InnoDB 存储引擎的group commit 功能会失效，从而导致性能的下降。并且在线环境多使用replication 环境，因此二进制日志的选项基本都为开启状态，因此这个问题尤为显著**。

​	<u>导致这个问题的原因是在开启二进制日志后，为了**保证存储引擎层中的事务和二进制日志的一致性**，二者之间使用了**两阶段事务**</u>，其步骤如下：

1) 当事务提交时InnoDB 存储引擎进行prepare操作。

2) MySQL 数据库上层写入二进制日志。

3) InnoDB 存储引擎层将日志写入重做日志文件。

​		a) 修改内存中事务对应的信息，并且将日志写入重做日志缓冲。

​		b) 调用fsync 将确保日志都从重做日志缓冲写入磁盘。

​	<u>一旦步骤2) 中的操作完成，就确保了事务的提交，即使在执行步骤3) 时数据库发生了宕机</u>。此外需要注意的是，**每个步骤都需要进行一次fsync 操作才能保证上下两层数据的一致性**。步骤2) 的fsync 由参数`sync_binlog`控制，步骤3) 的fsync 由参数`innodb_flush_log_at_trx_commit`控制。因此上述整个过程如图7-18 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200610101826909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	**为了保证MySQL 数据库上层二进制日志的写入顺序和lnnoDB 层的事务提交顺序一致， MySQL 数据库内部使用了`prepare_commit_ mutex`这个锁。但是在启用这个锁之后，步骤3) 中的步骤a) 步不可以在其他事务执行步骤b) 时进行，从而导致了group commit 失效**。

​	**然而，为什么需要保证MySQL 数据库上层二进制日志的写入顺序和InnoDB 层的事务提交顺序一致呢？这是因为备份及恢复的需要**，例如通过工具xtrabackup或者ibbackup进行备份，并用来建立replication，如图7-19 所示。

​	<u>可以看到若通过在线备份进行数据库恢复来重新建立replication，事务T1的数据会产生丢失。因为在InnoDB 存储引擎层会检测事务T3 在上下两层都完成了提交，不需要再进行恢复</u>。因此通过锁`prepare_commit_mutex`以串行的方式来保证顺序性，然而这会使group commit 无法生效，如图7-20 所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200610102930359.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODM2NzgxNw==,size_16,color_FFFFFF,t_70)

​	<u>这个问题最早在2010 年的MySQL 数据库大会中提出， Facebook MySQL 技术组，Percona 公司都提出过解决方案。最后由MariaDB 数据库的开发人员Kristian Nielsen 完成了最终的“完美“解决方案。**在这种情况下，不但MySQL 数据库上层的二进制日志写入是group commit 的， InnoDB 存储引擎层也是group commit 的**</u>。**此外还移除了原先的锁`prepare_commit_mutex`，从而大大提高了数据库的整体性**。MySQL 5.6 采用了类似的实现方式，并将其称为**Binary Log Group Commit (BLGC)** 。

​	MySQL 5.6 BLGC 的实现方式是将事务提交的过程分为几个步骤来完成，如图7-21所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200610103449530.png)

​	**在MySQL 数据库上层进行提交时首先按顺序将其放入一个队列中，队列中的第一个事务称为leader，其他事务称为follower，leader 控制着follower 的行为**。BLGC 的步骤分为以下三个阶段：

+ **Flush 阶段，将每个事务的二进制日志写入内存中**。

+ **Sync 阶段，将内存中的二进制日志刷新到磁盘，若队列中有多个事务，那么仅一次fsync 操作就完成了二进制日志的写入，这就是BLGC** 。

+ **Commit 阶段， leader 根据顺序调用存储引擎层事务的提交， InnoDB 存储引擎本就支持group commit, 因此修复了原先由于锁`prepare_commit_mutex`导致group commit 失效的问题**。

​	当有一组事务在进行Commit 阶段时，其他新事物可以进行Flush 阶段，从而使group commit 不断生效。当然group commit 的效果由队列中事务的数量决定，若每次队列中仅有一个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时， group commit 的效果越明显，数据库性能的提升也就越大。

​	参数`binlog_max_flush_queue_time`用来控制Flush 阶段中等待的时间，即使之前的一组事务完成提交，当前一组的事务也不马上进入Sync 阶段，而是至少需要等待一段时间。这样做的好处是group commit 的事务数量更多，然而这也可能会导致事务的响应时间变慢。该参数的默认值为0，且推荐设置依然为0 。除非用户的MySQL 数据库系统中有着大量的连接（如100 个连接），并且不断地在进行事务的写入或更新操作。

## * 7.3 事务控制语句

​	**在MySQL 命令行的默认设置下，事务都是自动提交(auto commit) 的，即执行SQL 语句后就会马上执行COMMIT 操作。因此要显式地开启一个事务需使用命令`BEGIN`、`START TRANSACTION`， 或者执行命令`SET AUTOCOMMIT=0`，禁用当前会话的自动提交**。每个数据库厂商自动提交的设置都不相同，每个DBA 或开发人员需要非常明白这一点，这对之后的SQL 编程会有非凡的意义，因此用户不能以之前的经验来判断MySQL 数据库的运行方式。在具体介绍其含义之前，先来看看用户可以使用哪些事务控制语句。

+ START TRANSACTION I BEGIN: 显式地开启一个事务。

+ COMMIT: 要想使用这个语句的最简形式，只需发出COMMIT。也可以更详细一些，写为COMMIT WORK, 不过这二者几乎是等价的。COMMIT 会提交事务，并使得已对数据库做的所有修改成为永久性的。

+ ROLLBACK: 要想使用这个语句的最简形式，只需发出ROLLBACK 。同样地，也可以写为ROLLBACK WORK， 但是二者几乎是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。

+ **SAVEPOINT identifier : SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT** 。

+ RELEASE SAVEPOINT identifier: 删除一个事务的保存点，当没有一个保存点执行这句语句时，会抛出一个异常。

+ ROLLBACK TO [SAVEPOINT] identifier：这个语句与SAVEPOINT 命令一起使用。可以把事务回滚到标记点，而不回滚在此标记点之前的任何工作。例如可以发出两条UPDATE 语句，后面跟一个SAVEPOINT，然后又是两条DELETE 语句。如果执行DELETE 语句期间出现了某种异常情况，并且捕获到这个异常，同时发出了ROLLBACK TO SAVEPOINT 命令，事务就会回滚到指定的SAVEPOINT， 撤销DELETE 完成的所有工作，而UPDATE 语句完成的工作不受影响。

+ **SET TRANSACTION: 这个语句用来设置事务的隔离级别。InnoDB 存储引擎提供的事务隔离级别有：READ UNCOMMITTED 、READ COMMITTED 、REPEATABLE READ 、SERIALIZABLE** 。

​	START TRANSACTION、BEGIN 语句都可以在MySQL 命令行下显式地开启一个事务。但是<u>在存储过程中， MySQL 数据库的分析器会自动将BEGIN 识别为BEGIN …END， 因此在存储过程中只能使用START TRANSACTION 语句来开启一个事务</u>。

​	**COMMIT 和COMMIT WORK 语句基本是一致的，都是用来提交事务。不同之处在于COMMIT WORK 用来控制事务结束后的行为是CHAIN 还是RELEASE 的。如果是CHAIN 方式，那么事务就变成了链事务**。

​	用户可以通过参数`completion_type`来进行控制，该参数默认为0。

+ 当参数`completion_type` 的值为0表示没有任何操作。在这种设置下COMMIT 和COMMIT WORK 是完全等价的。
+ **当参数`completion_type` 的值为1 时， COMMIT WORK 等同于COMMIT AND CHAIN，表示马上自动开启一个相同隔离级别的事务**。
+ **参数`completion_type`为2 时， COMMIT WORK 等同于COMMIT AND RELEASE 。在事务提交后会自动断开与服务器的连接**。

​	ROLLBACK 和ROLLBACK WORK 与COMMIT 和COMMIT WORK 的工作一样，这里不再进行赘述。

​	SAVEPOINT 记录了一个保存点，可以通过ROLLBACK TO SAVEPOINT 来回滚到某个保存点，但是如果回滚到一个不存在的保存点，会抛出异常：

```shell
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> ROLLBACK TO SAVEPOINT tl;
ERROR 1305 (42000): SAVEPOINT tl does not exist
```

​	**InnoDB 存储引擎中的事务都是原子的，这说明下述两种情况：构成事务的每条语句都会提交（成为永久），或者所有语句都回滚**。**<u>这种保护还延伸到单个的语句。一条语句要么完全成功，要么完全回滚（注意，这里说的是语句回滚）</u>**。<u>因此一条语句失败并抛出异常时，并不会导致先前已经执行的语句自动回滚。所有的执行都会得到保留，必须由用户自己来决定是否对其进行提交或回滚的操作</u>。

```shell
mysql> CREATE TABLE t (a INT,PRIMARY KEY(a))ENGINE=INNODB;
Query OK, 0 rows affected (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql > INSERT INTO t SELECT 1;
Query OK, 1 工ow affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0

mysql> INSERT INTO t SELECT 1;
ERROR 1062 (23000): Duplicate entry'l'for key'PRIMARY'

mysql> SELECT* FROM t\G;
*************＊＊＊＊＊＊＊＊＊食＊＊＊＊ 1. row***************************
a: 1
1 row in set (0.00 sec)
```

​	可以看到，插入第二记录1 时，因为重复的关系抛出了1062 的错误，但是数据库并没有进行自动回滚，这时事务仍需要用户显式地运行COMMIT 或ROLLBACK命令。

​	**另一个容易犯的错误是ROLLBACK TO SAVEPOINT，虽然有ROLLBACK，但其并不是真正地结束一个事务，因此即使执行了ROLLBACK TO SAVEPOINT，之后也需要显式地运行COMMIT 或ROLLBACK 命令**。

```shell
mysql> CREATE TABLE t (a INT,PRIMARY KEY(a))ENGINE=INNODB;
Query OK, 0 rows affected (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO t SELECT 1;
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0

mysql> SAVEPOINT tl;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO t SELECT 2;
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0

mysql> SAVEPOINT t2;
Query OK, 0 rows affected (0.00 sec)

mysql> RELEASE SAVEPOINT tl;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO t SELECT 2;
ERROR 1062 (23000): Duplicate entry'2'for key'PRIMARY'

mysql> ROLLBACK TO SAVEPOINT t2;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT* FROM t;
十一一一十
I a I
十一一一十
I 1 I
I 2 I
十一一一十
2 rows in set (0.00 sec)

mysql> ROLLBACK;
Query OK, O rows affected (0.00 sec)

mysql> SELECT * FROM t;
Empty set (0.00 sec)
```

​	可以看到，在上面的例子中，虽然在发生重复错误后用户通过ROLLBACK TO SAVEPOINT t2 命令回滚到了保存点t2，但是事务此时没有结束。再运行命令ROLLBACK 后，事务才会完整地回滚。<u>这里再一次提醒， ROLLBACK TO SAVEPOINT命令并不真正地结束事务</u>。

## 7.4 隐式提交的SQL 语句

​	以下这些SQL 语句会产生一个**隐式的提交**操作，即执行完这些语句后，会有一个隐式的COMMIT 操作。

+ DDL语句：
  + ALTER DATABASE...UPGRADE DATA DIRECTORY NAME
  + ALTER EVENT
  + ALTER PROCEDURE
  + ALTER TABLE
  + ALTER VIEW
  + CREATE DATABASE
  + CREATE EVENT
  + CREATE INDEX
  + CREATE PROCEDURE
  + CREATE TABLE
  + CREATE TRIGGER
  + CREATE VIEW
  + DROP DATABASE
  + DROP EVENT
  + DROP INDEX
  + DROP PROCEDURE
  + DROP TABLE
  + DROP TRIGGER
  + DROP VIEW
  + RENAME TABLE
  + TRUNCATE TABLE
+ 用来隐式地修改 MySQL架构的操作:
  + CREATE USER
  + DROP USER
  + GRANT
  + RENAME USER
  + REVOKE
  + SET PASSWORD
+ 管理语句: 
  + ANALYZE TABLE
  + CACHE INDEX
  + CHECK TABLE
  + LOAD INDEX INTO CACHE
  + OPTIMIZE TABLE
  + REPAIR TABLE。

> 注意：Microsoft SQL Server 的数据库管理员或开发人员往往忽视对于DDL 语句的隐式提交操作，因为在Microsoft SQL Server 数据库中，即使是DDL 也是可以回滚的。这和InnoDB 存储引擎、Oracle 这些数据库完全不同。

​	**<u>另外需要注意的是， TRUNCATE TABLE 语句是DDL，因此虽然和对整张表执行DELETE 的结果是一样的，但它是不能被回滚的（这又是和Microsoft SQL Server数据库不同的地方）</u>**。

```shell
rnysql> SELECT * FROM t\G;
*************************** 1. row * ** ** * * * * * * * ** * * * * * * * * * * * * *
a: 1
*************************** 2. row ***************************
a: 2
2 rows in set (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.01 sec)

mysql> TRUNCATE TABLE t;
Query OK, O rows affected (0.00 sec)

mysql> ROLLBACK;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM t;
Empty set (0.00 sec)
```

## 7.5 对于事务操作的统计

​	由于InnoDB 存储引擎是支持事务的，因此lnnoDB 存储引擎的应用需要在考虑**每秒请求数(Question Per Second, QPS)** 的同时，应该关注**每秒事务处理的能力(Transaction Per Second, TPS)** 。

​	**计算TPS 的方法是(com_commit + com_rollback) / time**。但是<u>利用这种方法进行计算的前提是：所有的事务必须都是显式提交的，如果存在隐式地提交和回滚（默认autocommit=1) ，不会计算到com_commit和com_rollback变量中</u>。如：

```shell
mysql> SHOW GLOBAL STATUS LIKE 'com_commit'\G;
*************************** 1. row**********＊＊＊ *** *********
Variable name: Com commit
Value: 5
1 row in set (0.00 sec)

mysql> INSERT INTO t SELECT 3;
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: 0

mysql> SELECT * FROM t\G;
*************************** 1. row *****＊＊ * ** * ** * * ** ** * * *
a: 1
*************************** 2. row***************************
a: 2
*************************** 3. row***************************
a: 3
3 rows in set (0.00 sec)

mysql> SHOW GLOBAL STATUS LIKE 'com_commit'\G;
***********＊＊＊＊＊＊＊＊＊＊＊＊＊ ** 1. row * * * * * * * * * * * * * * * * * * * *
Variable name: Com commit
Value: 5
1 row in set (0.00 sec)
```

​	MySQL 数据库中另外还有两个参数handler_commit 和handler_rollback 用于事务的统计操作。但是我注意到这两个参数在MySQL 5.1 中可以很好地用来统计InnoDB 存储引擎显式和隐式的事务提交操作，但是在InnoDB Plugin 中这两个参数的表现有些“怪异“，并不能很好地统计事务的次数。所以，如果用户的程序都是显式控制事务的提交和回滚，那么可以通过com_commit 和com_rollback 进行统计。如果不是，那么情况就显得有些复杂。

## * 7.6 事务的隔离级别

​	令人惊讶的是，大部分数据库系统都没有提供真正的隔离性，最初或许是因为系统实现者并没有真正理解这些问题。如今这些问题已经弄清楚了，但是数据库实现者在正确性和性能之间做了妥协。ISO 和ANIS SQL 标准制定了四种事务隔离级别的标准，但是很少有数据库厂商遵循这些标准。比如Oracle 数据库就不支持READ UNCOMMITTED 和REPEATABLE READ 的事务隔离级别。

​	SQL 标准定义的四个隔离级别为：

+ READ UNCOMMITTED

+ READ COMMITTED

+ REPEATABLE READ

+ SERIALIZABLE

​	READ UNCOMMITTED 称为浏览访问(browse access) ，仅仅针对事务而言的READ COMMITTED 称为游标稳定(cursor stability) 。REPEATABLE READ 是2.9999°的隔离，没有幻读的保护。SERIALIZABLE 称为隔离，或3°的隔离。SQL 和SQL2 标准的默认事务隔离级别是SERIALIZABLE 。

​	<u>InnoDB 存储引擎默认支持的隔离级别是REPEATABLE READ，但是与标准SQL不同的是， InnoDB 存储引擎在REPEATABLE READ 事务隔离级别下，使用Next-Key Lock 锁的算法，因此避免幻读的产生</u>。这与其他数据库系统（如Microsoft SQL Server数据库）是不同的。所以说， **lnnoDB 存储引擎在默认的REPEATABLE READ 的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL 标准的SERIALIZABLE 隔离级别**。

​	隔离级别越低，事务请求的锁越少或保持锁的时间就越短。这也是为什么大多数数据库系统默认的事务隔离级别是READ COMMITTED 。

​	据了解，**大部分的用户质疑SERIALIZABLE 隔离级别带来的性能问题，但是根据Jim Gray 在《Transaction Processing》一书中指出，两者的开销几乎是一样的，甚至SERIALIZABLE 可能更优**！！！<u>因此在InnoDB 存储引擎中选择REPEATABLE READ 的事务隔离级别并不会有任何性能的损失。同样地，即使使用READ COMMITTED 的隔离级别，用户也不会得到性能的大幅度提升</u>。

​	在InnoDB 存储引擎中，可以使用以下命令来设置当前会话或全局的事务隔离级别：

```sql
SET [GLOBAL | SESSION) TRANSACTION ISOLATION LEVEL
{
  READ UNCOMMITTED
  | READ COMMITTED
  | REPEATABLE READ
  | SERIALIZABLE
}
```

​	如果想在MySQL 数据库启动时就设置事务的默认隔离级别，那就需要修改MySQL的配置文件，在[mysqld] 中添加如下行：

```none
[mysqld]
transaction-isolation = READ-COMMITTED
```

​	查看当前**会话**的事务隔离级别，可以使用：

```shell
mysql>SELECT @@tx_isolation\G;
*************************** 1. row***************************
@@tx_isolation: REPEATABLE-READ
1 row in set (0.01 sec)
```

​	查看**全局**的事务隔离级别，可以使用：

```shell
mysql>SELECT @@global.tx_isolation\G;
*************************** 1. row***************************
@@global.tx_isolation: REPEATABLE-READ
1 row in set (0.00 sec)
```

​	**在SERIALIABLE 的事务隔离级别， InnoDB 存储引擎会对每个SELECT 语句后自动加上LOCK IN SHARE MODE，即为每个读取操作加一个共享锁**。因此在这个事务隔离级别下，读占用了锁，对一致性的非锁定读不再予以支持。这时，事务隔离级别SERIALIZABLE 符合数据库理论上的要求，即事务是well-formed 的，并且是two-phrased的。有兴趣的读者可进一步研究。

​	因为InnoDB 存储引擎在REPEATABLE READ 隔离级别下就可以达到3°的隔离，因此一般不在本地事务中使用SERIALIABLE 的隔离级别。**SERIALIABLE 的事务隔离级别主要用于InnoDB 存储引擎的分布式事务**。

​	**在READ COMMITTED 的事务隔离级别下，除了唯一性的约束检查及外键约束的检查需要gap lock，InnoDB 存储引擎不会使用gap lock的锁算法**。但是使用这个事务隔离级别需要注意一些问题。首先，在MySQL 5.1 中， READ COMMITTED 事务隔离级别默认只能工作在replication （复制）二进制日志为ROW 的格式下。如果二进制日志工作在默认的STATEMENT 下，则会出现如下的错误：

```shell
mysql> CREATE TABLE a (
		-> b INT,PRIMARY KEY(b)
		->) ENGINE=INNODB;
Query OK, 0 rows affected (0.01 sec)

mysql>SET @@tx_isolation='READ-COMMITTED';
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT @@tx_isolation\G;
*************************** 1. row***************************
@@tx_isolation: REPEATABLE-READ
1 row in set (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql>INSERT INTO a SELECT l;
ERROR 1598 {HYOOO) : Binary logging not possible. Message: Transaction level
'READ-COMMITTED'in InnoDB is not safe for binlog mode'STATEMENT'
```

​	在MySQL 5.0 版本以前，在不支持ROW 格式的二进制日志时，也许有人知道通过将参数`innodb_locks_unsafe_for_bin_log`设置为1 可以在二进制日志为STATEMENT 下使用READ COMMITTED 的事务隔离级别：

```shell
mysql> SELCT @@version\G
*************************** 1. row* ＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊＊ *** *
@@version: 5.0.77-log
1 row in set (0.00 sec)

mysql> SHOW VARIABLES LIKE'innodb_locks_unsafe_for_binlog'\G;
*******************＊＊＊＊＊ * 1. row***************************
Variable_name: innodb_locks_unsafe_for_binlog
Value: ON
1 row in set (0.00 sec)

mysql> SET @@tx_isolation='READ-COMMITTED';
Query OK, 0 rows affected (0.00 sec)

mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO a SELECT 1;
Query OK, 0 rows affected (0.00 sec)

mysql> COMMIT;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM a\G;
*************************** 1. row***************************
b: 1
*************************** 2. row***************************
b: 2
*************************** 3. row***************************
b: 4
*************************** 4. row***************************
b: 5
4 rows in set (0.00 sec)
```

​	接着在master 上开启一个会话A 执行如下事务，并且不要提交：

```shell
# Session A on master
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> DELETE FROM a WHERE b<=5;
Query OK, 4 rows affected (0.01 sec)
```

​	同样，在master 上开启另一个会话B, 执行如下事务，并且提交：

```shell
# Session Bon master
mysql> BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql> INSERT INTO a SELECT 3;
Query OK, 0 rows affected (0.01 sec)

mysql> COMMIT;
Query OK, 0 rows affected (0.00 sec)
```

​	接着会话A 提交，并查看表a 中的数据：

```shell
# Session A on master
mysql> COMMIT;
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM a\G;
*************************** 1. row***************************
b: 3
```

​	但是在slave 上看到的结果却是：

```shell
# Slave
mysql> SELECT * FROM a;
Empty set (0.00 sec)
```

​	可以看到，数据产生了不一致。导致这个问题发生的原因有两点：

+ **在READ COMMITTED 事务隔离级别下，事务没有使用gap lock 进行锁定**，因此用户在会话B 中可以在小于等于5 的范围内插入一条记录；

+ **STATEMENT 格式记录的是master 上产生的SQL 语句，因此在master 服务器上执行的顺序为先删后插，但是在STATEMENT 格式中记录的却是先插后删，逻辑顺序上产生了不一致**。

​	<u>要避免主从不一致的问题，只需解决上述问题中的一个就能保证数据的同步了。如使用READ REPEATABLE 的事务隔离级别可以避免上述第一种情况的发生，也就避免了master 和slave 数据不一致问题的产生</u>。

​	在MySQL 5.1 版本之后，因为支持了ROW 格式的二进制日志记录格式，避免了第二种情况的发生，所以可以放心使用READ COMMITTED 的事务隔离级别。但**即使不使用READ COMMITTED 的事务隔离级别，也应该考虑将二进制日志的格式更换成ROW，因为这个格式记录的是行的变更，而不是简单的SQL 语句，所以可以避免一些不同步现象的产生，进一步保证数据的同步**。<u>InnoDB 存储引擎的创始人HeikkiTuuri 也在`http:// bugs.mysql.com/bug.php?id=33210`这个帖子中建议使用ROW 格式的二进制日志</u>。

## 7.7 分布式事务

### * 7.7.1 MySQL 数据库分布式事务

​	**InnoDB 存储引擎提供了对XA 事务的支持，并通过XA 事务来支持分布式事务的实现**。分布式事务指的是允许多个独立的事务资源(transactional resources) 参与到一个全局的事务中。事务资源通常是关系型数据库系统，但也可以是其他类型的资源。<u>全局事务要求在其中的所有参与的事务要么都提交，要么都回滚，这对于事务原有的ACID 要求又有了提高。另外，**在使用分布式事务时， InnoDB 存储引擎的事务隔离级别必须设置为SERIALIZABLE**</u>。

​	**XA 事务允许不同数据库之间的分布式事务，如一台服务器是MySQL 数据库的，另一台是Oracle 数据库的，又可能还有一台服务器是SQL Server 数据库的，只要参与在全局事务中的每个节点都支持XA 事务**。分布式事务可能在银行系统的转账中比较常见，如用户David 需要从上海转10 000 元到北京的用户Mariah 的银行卡中：

```shell
# Bank@Shanghai:
UPDATE account SET money = money - 10000 WHERE user='David';

# Bank@Beijing
UPDATE account SET money = money + 10000 WHERE user='Mariah';
```

​	在这种情况下，一定需要使用分布式事务来保证数据的安全。如果发生的操作不能全部提交或回滚，那么任何一个结点出现问题都会导致严重的结果。要么是David的账户被扣款，但是Mariah 没收到，又或者是David 的账户没有扣款，Mariah 却收到钱了。

​	**XA事务由一个或多个资源管理器(Resource Managers)、一个事务管理器(Transaction Manager) 以及一个应用程序(Application Program) 组成**。

+ 资源管理器：提供访问事务资源的方法。<u>通常一个数据库就是一个资源管理器</u>。

+ 事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器进行通信。

+ 应用程序：定义事务的边界，指定全局事务中的操作。

​	**在MySQL 数据库的分布式事务中，资源管理器就是MySQL 数据库，事务管理器为连接MySQL 服务器的客户端**。图7-22 显示了一个分布式事务的模型。

![在这里插入图片描述](https://img-blog.csdnimg.cn/4f89e9fd4bb340a790c573102f0fe547.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5pif5YWJ5LmL5a2QMDMxNw==,size_20,color_FFFFFF,t_70,g_se,x_16)

​	图7-22 分布式事务模型

​	**分布式事务使用两段式提交(two-phase commit) 的方式**。

+ 在第一阶段，所有参与全局事务的节点都开始准备(PREPARE) ，告诉事务管理器它们准备好提交了。
+ 在第二阶段，事务管理器告诉资源管理器执行ROLLBACK 还是COMMIT。如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚。

​	可见与本地事务不同的是，分布式事务需要多一次的PREPARE 操作，待收到所有节点的同意信息后，再进行COMMIT 或是ROLLBACK 操作。

​	MySQL 数据库XA 事务的SQL 语法如下：

```shell
XA {START|BEGIN} xid [JOIN|RESUME]
XA END xid [SUSPEND [FOR MIGRATE]]
XA PREPARE xid
XA COMMIT xid [ONE PHASE]
XA ROLLBACK xid
XA RECOVER
```

​	在单个节点上运行XA 事务的例子：

```shell
mysql> XA START 'a';
Query OK, 0 rows affected (0.00 sec)

mysql > INSERT INTO z SELECT 11;
Query OK, 1 row affected (0.00 sec)
Records: 1 Duplicates: 0 Warnings: O

mysql> XA END'a';
Query OK, 0 rows affected (0.00 sec)

mysql> XA PREPARE'a';
Query OK, 0 rows affected (0.05 sec)

mysql> XA RECOVER\G;
*************************** 1. row***************************
formatID: 1
gtrid_length: 1
bqual_length: 0
data: a
1 row in set (0.00 sec)

mysql> XA COMMIT 'a';
Query OK, 0 rows affected (0.05 sec)
```

​	在单个节点上运行分布式事务没有太大的实际意义，但是要在MySQL 数据库的命令下演示多个节点参与的分布式事务也是行不通的。通常来说，都是通过编程语言来完成分布式事务的操作的。当前Java 的JTA (Java Transaction API) 可以很好地支持MySQL 的分布式事务，需要使用分布式事务应该认真参考其API 。下面的一个示例显示了如何使用JTA 来调用MySQL 的分布式事务，就是前面所举例的银行转账的例子，代码如下，仅供参考：

```java
import java.sql.Connection;
import javax.sql.XAConnection;
import javax.transaction.xa.*;
import com.mysql.jdbc.jdbc2.optional.MysqlXADataSource;
import java.sql.*;

class MyXid implements Xid
{
  public int formatId;
  public byte gtrid[];
  public byte bqual[];
  
  public MyXid() {
  }
  
  public MyXid(int formatId, byte gtrid[], byte bqual[])
  {
    this.formatId = formatId;
    this.gtrid = gtrid;
    this.bqual = bqual;
  }
  
  public int getFormatId ()
  {
    return formatId;
  }
  
  public byte[] getBranchQualifier()
  {
    return bqual;
  }
  
  public byte[] getGlobalTransactionid()
  {
    return gtrid;
  }
}
public class xa_demo {
  public static MysqlXADataSource GetDataSource(
    String connString,String user,String passwd) {
    try{
      MysqlXADataSource ds = new MysqlXADataSource();
      ds.setUrl(connString);
      ds.setUser(user);
      ds.setPassword(passwd);
      return ds;
    } catch(Exception e) {
      System.out.println(e.toString());
      return null;
    }
  }

  public static void main(String[] args) {
    String connStringl = "jdbc:mysql://192.168.24.43:3306/bank_shanghai";
    String connString2 = "jdbc:mysql://192.168.24.166:3306/bank_beijing";
    try {
      MysqlXADataSource dsl = GetDataSource(connStringl,"peter","12345");
      MysqlXADataSource ds2 = GetDataSource(connString2,"david","12345");
      
      XAConnection xaConnl = dsl.getXAConnection();
      XAResource xaResl = xaConnl.getXAResource();
      Connection connl = xaConnl.getConnection();
      Statement stmtl = connl.createStatement();

      XAConnection xaConn2 = ds2.getXAConnection();
      XAResource xaRes2 = xaConn2.getXAResource();
      Connection conn2 = xaconn2.getConnection();
      Statement stmt2 = conn2.createStatement();

      Xid xid1 = new MyXid(100, new byte[] {0x01}, new byte[]{0x02});
      Xid xid2 = new MyXid(100, new byte[] {0x11}, new byte[]{0x12});

      try{
        xaRes1.start(xid1,XAResource.TMNOFLAGS);
        stmt1.excute("UPDATE account SET money = money-10000 WHERE user='david'");
        xaRes1.end(xid1,XAResoure.TMSUCCESS);
        xaRes2.start(xid2,XAResoure.TMNOFLAGS);
        stmt2.excute("UPDATE account SET money = money+10000 WHERE user='mariah'");
        xaRes2.end(xid2,XAResoure.TMSUCCESS);
        int ret2 = xaRes2.prepare(xid2);
        int ret1 = xaRes1.prepare(xid1);
        if(ret1 == XAResource.XA_OK && ret2 == XAResource.XA_OK) {
          xaRes1.commit(xid1, false);
          xaRes2.commit(xid2, false);
        }
      } catch(Exception e) {
        e.printStackTrace();
      }
    } catch (Exception e) {
      System.out.println(e.toString());
    }
  }
}
```

通过参数innodb_support_xa 可以查看是否启用了XA事务的支持（默认为ON)：

```shell
mysql> SHOW VARIABLES LIKE'innodb_support_xa'\G;
*************************** 1. row*********************************
Variable_name: innodb_support_xa
		Value: ON
1 row in set (0.01 sec)
```

### 7.7.2 内部XA事务

​	**之前讨论的分布式事务是外部事务，即资源管理器是MySQL 数据库本身。在MySQL 数据库中还存在另外一种分布式事务，其在存储引擎与插件之间，又或者在存储引擎与存储引擎之间，称之为内部XA 事务**。

​	最为常见的内部XA 事务存在于binlog 与lnnoDB 存储引擎之间。由于复制的需要，因此目前绝大多数的数据库都开启了binlog 功能。**在事务提交时，先写二进制日志，再写InnoDB 存储引擎的重做日志。对上述两个操作的要求也是原子的，即二进制日志和重做日志必须同时写入。若二进制日志先写了，而在写入InnoDB 存储引擎时发生了宕机，那么slave 可能会接收到master 传过去的二进制日志并执行，最终导致了主从不一致的情况**。如图7-23 所示。

​	<u>在图7-23 中，如果执行完➀、➁后在步骤➂之前MySQL 数据库发生了宕机，则会发生主从不一致的情况。为了解决这个问题， MySQL 数据库在binlog 与InnoDB 存储引擎之间采用XA 事务。当事务提交时， InnoDB 存储引擎会先做一个PREPARE 操作，将事务的xid 写入，接着进行二进制日志的写入，如图7-24 所示。如果在InnoDB 存储引擎提交前， MySQL 数据库宕机了，那么MySQL 数据库在重启后会先检查准备的UXID 事务是否已经提交，若没有，则在存储引擎层再进行一次提交操作</u>。

![img](https://img-blog.csdnimg.cn/20181104194333555.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

## 7.8 不好的事务习惯

### 7.8.1 在循环中提交

​	开发人员非常喜欢在循环中进行事务的提交，下面是他们可能常写的一个存储过程：

```sql
CREATE PROCEDURE load1(count INT UNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT 1;
DECLARE c CHAR(80) DEFAULT REPEAT('a',80);
WHILE s <= count DO
INSERT INTO tl SELECT NULL, c;
COMMIT;
SET s = s+l;
END WHILE;
END;
```

​	<u>其实，在上述的例子中，是否加上提交命令COMMIT 并不关键。因为lnnoDB 存储引擎默认为自动提交，所以在上述的存储过程中去掉COMMIT，结果其实是完全一样的</u>。这也是另一个容易被开发人员忽视的问题：

```sql
CREATE PROCEDURE load2(count INT UNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT l;
DECLARE c CHAR(80) DEFAULT REPEAT('a',80);
WHILE s <= count DO
INSERT INTO tl SELECT NULL,c;
SET s = s+l;
END WHILE;
END;
```

​	不论上面哪个存储过程都存在一个问题，当发生错误时，数据库会停留在一个未知的位置。例如，用户需要插入10 000 条记录，但是在插入5000 条时，发生了错误，这时前5000 条记录已经存放在数据库中，那应该怎么处理呢？另一个问题是性能问题，上面两个存储过程都不会比下面的存储过程load3 快，因为下<u>面的存储过程将所有的INSERT 都放在一个事务中</u>：

```sql
CREATE PROCEDURE load3{count INT UNSIGNED)
BEGIN
DECLARE s INT UNSIGNED DEFAULT l;
DECLARE c CHAR (80) DEFAULT REPEAT {'a', 80);
START TRANSACTION;
WHILE s <= count DO
INSERT INTO tl SELECT NULL, c;
SET s = s+l;
END WHILE;
COMMIT;
END;
```

​	比较这3 个存储过程的执行时间：

```sql
mysql> CALL loadl(lOOOO);
Query OK, O rows affected (1 min 3.15 sec)

mysql> TRUNCATE TABLE tl;
Query OK, 0 rows affected (0.05 sec)

mysql> CALL load2(10000);
Query OK, 1 row affected (1 min 1.69 sec)

mysql> TRUNCATE TABLE tl;
Query OK, 0 rows affected (0.05 sec)

mysql> CALL load3(10000);
Query OK, 0 rows affected (0.63 sec)
```

​	显然，第三种方法要快得多！这是因为每一次提交都要写一次重做日志，存储过程load1和load2 实际写了10 000 次重做日志文件，而对千存储过程load3 来说，实际只写了1 次。可以对第二个存储过程load2 的调用进行调整，同样可以达到存储过程load3 的性能，如：

```sql
mysql> BEGIN;
Query OK, O rows affected (0.00 sec)

mysql> CALL load2(10000);
Query OK, 1 row affected (0.56 sec)

mysql> COMMIT;
Query OK, 0 rows affected (0.03 sec)
```

​	大多数程序员会使用第一种或第二种方法，有人可能不知道InnoDB 存储引擎自动提交的情况，另外有些人可能持有以下两种观点：首先，在他们曾经使用过的数据库中，对事务的要求总是尽快地进行释放，不能有长时间的事务；其次，他们可能担心存在Oracle 数据库中由于没有足够undo 产生的Snapshot Too Old 的经典问题。**MySQL 的lnnoDB 存储引擎没有上述两个问题，因此程序员不论从何种角度出发，都不应该在一个循环中反复进行提交操作，不论是显式的提交还是隐式的提交**。

### 7.8.2 使用自动提交

​	**自动提交并不是一个好的习惯**，因为这会使初级DBA 容易犯错，另外还可能使一些开发人员产生错误的理解，如我们在前一小节中提到的循环提交问题。MySQL数据库默认设置使用自动提交(autocommit) ，可以使用如下语句来改变当前自动提交的方式：

```shell
mysql> SET autocommit=0;
Query OK, 0 rows affected (0.00 sec)
```

​	也可以使用`START TRANSACTION`，`BEGIN`来显式地开启一个事务。在显式开启事务后，在默认设置下（即参数`completion_type`等于0)，MySQL 会自动地执行`SET AUTOCOMMIT=0`的命令，并在`COMMIT`或`ROLLBACK`结束一个事务后执行`SET AUTOCOMMIT=1`。

​	**另外，对于不同语言的API，自动提交是不同的**。MySQL C API 默认的提交方式是自动提交，而MySQL Python API 则会自动执行`SET AUTOCOMMIT=0`，以禁用自动提交。因此在选用不同的语言来编写数据库应用程序前，应该对连接MySQL 的API 做好研究。

​	我认为，在编写应用程序开发时，最好把事务的控制权限交给开发人员，即在程序端进行事务的开始和结束。同时，开发人员必须了解自动提交可能带来的问题。我曾经见过很多开发人员没有意识到自动提交这个特性，等到出现错误时应用就会遇到大麻烦。

### 7.8.3 使用自动回滚

​	**InnoDB 存储引擎支持通过定义一个HANDLER 来进行自动事务的回滚操作，如在一个存储过程中发生了错误会自动对其进行回滚操作**。因此我发现很多开发人员喜欢在应用程序的存储过程中使用自动回滚操作，例如下面所示的一个存储过程：

```sql
CREATE PROCEDURE sp_auto_rollback_demo()
BEGIN
DECLARE EXIT HANDLER FOR SQLEXCEPTION ROLLBACK;
START TRANSACTION;
INSERT INTO b SELECT 1;
INSERT INTO b SELECT 2;
INSERT INTO b SELECT 1;
INSERT INTO b SELECT 3;
COMMIT;
END;
```

​	存储过程sp_auto_rollback_demo首先定义了一个exit 类型的HANDLER，当捕获到错误时进行回滚。结构如下：

```shell
mysql>SHOW CREATE TABLE b\G;
*************************** 1. row ******************************
Table: b
Create Table: CREATE TABLE'b' (
'a'int(ll) NOT NULL DEFAULT'0',
PRIMARY KEY ('a')
) ENGINE=InnoDB DEFAULT CHARSET=latinl
1 row.in set (0. 00 sec)
```

​	因此插入第二个记录1 时会发生错误，但是因为启用了自动回滚的操作，因此这个存储过程的执行结果如下：

```sql
mysql>CALL sp_auto_rollback_demo;
Query OK, 0 rows affected (0.06 sec)

mysql>SELECT * FROM b;
Empty set (0.00 sec)
```

​	看起来运行没有问题，非常正常。但是，执行sp_auto_rollback_demo这个存储过程的结果到底是正确的还是错误的？对于同样的存储过程sp_auto_rollback_demo，为了得到执行正确与否的结果，开发人员可能会进行这样的处理：

```sql
CREATE PROCEDURE sp_auto_rollback_demo ()
BEGIN
DECLARE EXIT HANDLER FOR SQLEXCEPTION BEGIN ROLLBACK; SELECT -1; END;
START TRANSACTION;
INSERT INTO b SELECT 1;
INSERT INTO b SELECT 2;
INSERT INTO b SELECT 1;
INSERT INTO b SELECT 3;
COMMIT;
SELECT 1;
END;
```

​	当发生错误时，先回滚然后返回-1，表示运行有错误。运行正常返回值1 。因此这次运行的结果就会变成：

```shell
mysql>CALL sp_auto_rollback_demo (l\G;
*********************** 1. row***************************
-1: -1
1 row in set (0.04 sec)

mysql>SELECT * FROM b;
Empty set (0.00 sec)
```

​	看起来用户可以得到运行是否准确的信息。但问题还没有最终解决，对于开发人员来说，重要的不仅是知道发生了错误，而是发生了什么样的错误。因此自动回滚存在这样的一个问题。

​	习惯使用自动回滚的人大多是以前使用Microsoft SQL Server 数据库的开发人员。在Microsoft SQL Server 数据库中，可以使用SET XABORT ON 来自动回滚一个事务。但是Microsoft SQL Server 数据库不仅会自动回滚当前的事务，还会抛出异常，开发人员可以捕获到这个异常。因此，Microsoft SQL Server 数据库和MySQL数据库在这方面是有所不同的。

​	就像之前小节中所讲到的，**<u>对事务的BEGIN 、COMMIT 和ROLLBACK 操作应该交给程序端来完成，存储过程需要完成的只是一个逻辑的操作，即对逻辑进行封装</u>**。下面演示用Python 语言编写的程序调用一个存储过程`sp_rollback_demo`，这里的存储过程`sp_rollback_demo`和之前的存储过程`sp_auto_rollback_demo`在逻辑上完成的内容大致相同：

```sql
CREATE PROCEDURE sp_rollback_demo ()
BEGIN
INSERT INTO b SELECT l;
INSERT INTO b SELECT 2;
INSERT INTO b SELECT 1;
INSERT INTO b SELECT 3;
END;
```

​	和sp_auto_rollback_demo 存储过程不同的是，在sp_rollback_demo 存储过程中去掉了对于事务的控制语句，将这些操作都交由程序来完成。接着来看test_demo.py 的程序源代码：

```python
#！/usr/bin/env python
#encoding=<utf-8

import MySQLdb
try:
  conn=MySQLdb.connect(host="l92.168.8.7",user="root",passwd="xx",db="test")
  cur=conn.cursor()
  cur.execute("SET autocommit=O")
  cur.execute("CALL sp_rollback_demo")
  cur.execute("COMMIT")
  except: Exception,e:
    cur.execute("ROLLBACK")
    print e
```

​	观察运行test_demo.py 这个程序的结果：

```shell
[root@nineyou0-43 ~]# python test_demo.py
starting rollback
(1062, "Duplicate entry'l'for key'PRIMARY'")
```

​	在程序中控制事务的好处是，用户可以得知发生错误的原因。如在上述这个例子中，我们知道是因为发生了1062 这个错误，错误的提示内容是Duplicate entry '1' for key 'PRIMARY' ，即发生了主键重复的错误。然后可以根据发生的原因来进一步调试程序。

## 7.9 长事务

​	长事务(Long-Lived Transactions) ，顾名思义，就是执行时间较长的事务。比如，对于银行系统的数据库，每过一个阶段可能需要更新对应账户的利息。如果对应账号的数批非常大，例如对有1亿用户的表account，需要执行下列语句：

```sql
UPDATE account
SET account_total = account_total + (1 + interest_rate)
```

​	这时这个事务可能需要非常长的时间来完成。可能需要1个小时，也可能需要4 、5个小时，这取决于数据库的硬件配置。DBA 和开发人员本身能做的事情非常少。然而，由于事务ACID 的特性，这个操作被封装在一个事务中完成。这就产生了一个问题，在执行过程中，当数据库或操作系统、硬件等发生问题时，重新开始事务的代价变得不可接受。数据库需要回滚所有巳经发生的变化，而这个过程可能比产生这些变化的时间还要长。因此，**对于长事务的问题，有时可以通过转化为小批量(mini batch) 的事务来进行处理。当事务发生错误时，只需要回滚一部分数据，然后接着上次已完成的事务继续进行**。

​	例如，对于前面讨论的银行利息计算问题，我们可以通过分解为小批量事务来完成。例如将一个需要处理1亿用户的大事务分解为每次处理10 万用户的小事务，通过批量处理小事务来完成大事务的逻辑。每完成一个小事务，将完成的结果存放在batchcontext 表中，表示已完成批量事务的最大账号ID 。若事务在运行过程中产生问题，需要重做事务，可以从这个已完成的最大事务ID 继续进行批量的小事务，这样重新开启事务的代价就显得比较低，也更容易让用户接受。batchcontext 表的另外一个好处是，在长事务的执行过程中，用户可以知道现在大概已经执行到了哪个阶段。比如一共有1亿条的记录，现在表batchcontext 中最大的账号ID 为4000 万，也就是说这个大事务大概完成了40％的工作。

​	这里还有一个小地方需要注意，<u>在从表account 中取得max_account_no 时，人为地加上了一个**共享锁**，以保证在事务的处理过程中，没有其他的事务可以来更新表中的数据，这是有意义的，并且也是非常有必要的操作</u>。

## 7.10 小结

​	在这一章中我们了解了InnoDB 存储引擎管理事务的许多方面。了解了事务如何工作以及如何使用事务，这在任何数据库中对于正确实现应用都是必要的。此外，事务是数据库区别于文件系统的一个关键特性。

​	事务必须遵循ACID 特性，即Atomicity（原子性）、Consistency（一致性）、Isolation（隔离性）和Durability（持久性）。

+ **隔离性通过第6章介绍过的锁来完成**；
+ **原子性、一致性、隔离性通过redo 和undo 来完成**。

​	通过对redo 和undo 的了解，可以进一步明白事务的工作原理以及如何更好地使用事务。接着我们讲到了InnoDB 存储引擎支持的四个事务隔离级别，知道了InnoDB 存储引擎的默认事务隔离级别是REPEATABLE READ的，不同于SQL 标准对于事务隔离级别的要求， <u>InnoDB 存储引擎在REPEATABLE READ 隔离级别下就可以达到3°的隔离要求</u>。

​	本章最后讲解了操作事务的SQL 语句以及怎样在应用程序中正确使用事务。**在默认配置下， MySQL 数据库总是自动提交的一一如果不知道这点，可能会带来非常不好的结果**。<u>此外，在应用程序中，最好的做法是把事务的START TRANSACTION 、COMMIT 、ROLLBACK 操作交给程序端来完成，而不是在存储过程内完成</u>。在完整了解了InnoDB 存储引擎事务机制后，相信你可以开发出一个很好的企业级MySQLlnnoDB 数据库应用了。

# 8. 备份与恢复

​	对于DBA 来说，数据库的备份与恢复是一项最基本的操作与工作。在意外情况下（如服务器宕机、磁盘损坏、RAID 卡损坏等）要保证数据不丢失，或者是最小程度地丢失，每个DBA 应该每时每刻关心所负责的数据库备份情况。

​	本章主要介绍对lnnoDB 存储引擎的备份，应该知道MySQL 数据库提供的大多数工具（如mysqldump 、ibbackup 、replication) 都能很好地完成备份的工作，当然也可以通过第三方的一些工具来完成，如xtrabacup 、LVM 快照备份等。DBA 应该根据自己的业务要求，设计出损失最小、对千数据库影响最小的备份策略。

## * 8.1 备份与恢复概述

​	可以根据不同的类型来划分备份的方法。根据备份的方法不同可以将备份分为：

+ Hot Backup （热备）

  Hot Backup 是指**数据库运行中**直接备份，对正在运行的数据库操作没有任何的影响。这种方式在MySQL 官方手册中称为Online Backup （在线备份）。

+ Cold Backup （冷备）

  Cold Backup 是指备份操作是在**数据库停止**的情况下，这种备份最为简单，**一般只需要复制相关的数据库物理文件即可**。这种方式在MySQL 官方手册中称为Offline Backup （离线备份）。

+ Warm Backup （温备）

  WarmBackup 备份同样是在**数据库运行中**进行的，但是会**对当前数据库的操作有所影响**，<u>如加一个全局读锁以保证备份数据的一致性</u>。

​	按照备份后文件的内容，备份又可以分为：

+ 逻辑备份

  在MySQL 数据库中，逻辑备份是指备份出的文件内容是可读的，一般是文本文件。**内容一般是由一条条SQL语句，或者是表内实际数据组成。如`mysqldump`和`SELECT * INTO OUTFILE` 的方法**。这类方法的好处是可以观察导出文件的内容，一般适用于数据库的升级、迁移等工作。但其缺点是恢复所需要的时间往往较长。

+ 裸文件备份

  **裸文件备份是指复制数据库的物理文件**，既可以是在数据库运行中的复制（如ibbackup 、xtrabackup 这类工具），也可以是在数据库停止运行时直接的数据文件复制。这类备份的恢复时间往往较逻辑备份短很多。	

​	若按照备份数据库的内容来分，备份又可以分为：

+ 完全备份

  完全备份是指对数据库进行一个完整的备份。

+ 增量备份

  增量备份是指<u>在上次完全备份的基础上</u>，对于更改的数据进行备份。

+ 日志备份

  日志备份主要是指<u>对MySQL 数据库二进制日志的备份</u>，通过对一个完全备份进行二进制日志的重做(replay) 来完成数据库的point-in-time 的恢复工作。**MySQL 数据库复制(replication) 的原理就是异步实时地将二进制日志重做传送并应用到从(slave/standby) 数据库**。

​	<u>对于MySQL 数据库来说，官方没有提供真正的增量备份的方法，大部分是通过二进制日志完成增量备份的工作。这种备份较之真正的增量备份来说，效率还是很低的</u>。假设有一个100GB 的数据库，要通过二进制日志完成备份，可能同一个页需要执行多次的SQL 语句完成重做的工作。但是<u>对于真正的增量备份来说，只需要记录当前每页最后的检查点的LSN，如果大于之前全备时的LSN，则备份该页，否则不用备份，这大大加快了备份的速度和恢复的时间</u>，同时这也是xtrabackup工具增量备份的原理。

​	此外还需要理解数据库备份的一致性，这种备份要求在备份的时候数据在这一时间点上是一致的。举例来说，在一个网络游戏中有一个玩家购买了道具，这个事务的过程是：先扣除相应的金钱，然后向其装备表中插入道具，确保扣费和得到道具是互相一致的。否则，在恢复时，可能出现金钱被扣除了而装备丢失的问题。

​	对于lnnoDB 存储引擎来说，因为其支持MVCC 功能，因此实现一致的备份比较简单。用户可以先开启一个事务，然后导出一组相关的表，最后提交。当然用户的事务隔离级别必须设置为REPEATABLE READ，这样的做法就可以给出一个完美的一致性备份。然而这个方法的前提是需要用户正确地设计应用程序。对于上述的购买道具的过程，不可以分为两个事务来完成，如一个完成扣费，一个完成道具的购买。若备份这时发生在这两者之间，则由于逻辑设计的问题，导致备份出的数据依然不是一致的。

​	**对于mysqldump备份工具来说，可以通过添加`--single-transaction`选项获得InnoDB存储引擎的一致性备份**，原理和之前所说的相同。需要了解的是，这时的备份是在一个执行时间很长的事务中完成的。另外，对于lnnoDB 存储引擎的备份，务必加上`--single-transaction`的选项（虽然是mysqldump的一个可选选项，但是我找不出任何不加的理由）。

​	同时我建议每个公司要根据自己的备份策略编写一个备份的应用程序，这个程序可以方便地设置备份的方法及监控备份的结果，并且通过第三方接口实时地通知DBA，这样才能真正地做到24X7的备份监控。久游网开发过一套DAO (Database Admin Online) 系统，这套系统完全由DBA开发完成，整个平台用Python语言编写， Web 操作界面采用Django 。通过这个系统DBA 可以方便地对几百台MySQL 数据库服务器进行备份，同时查看备份完成后备份文件的状态。之后DBA 又对其进行了扩展，不仅可以完成备份的工作，也可以实时监控数据库的状态、系统的状态和硬件的状态，当发生问题时，通过飞信接口在第一时间以短信的方式告知DBA 。

​	最后，**任何时候都需要做好远程异地备份，也就是容灾的防范**。只是同一机房的两台服务器的备份是远远不够的。我曾经遇到的情况是，公司在2008 年的汶川地震中发生一个机房可能被淹的的情况，这时远程异地备份显得就至关重要了。

## 8.2 冷备

​	**对于InnoDB 存储引擎的冷备非常简单，只需要备份MySQL 数据库的frm文件，共享表空间文件，独立表空间文件(*.ibd) ，重做日志文件。另外建议定期备份MySQL 数据库的配置文件my.cnf，这样有利于恢复的操作**。

​	通常DBA 会写一个脚本来进行冷备的操作， DBA 可能还会对备份完的数据库进行打包和压缩，这都并不是难事。关键在于不要遗漏原本需要备份的物理文件，如共享表空间和重做日志文件，少了这些文件可能数据库都无法启动。**另外一种经常发生的情况是由于磁盘空间已满而导致的备份失败**， DBA 可能习惯性地认为运行脚本的备份是没有问题的，少了检验的机制。

​	正如前面所说的，在同一台机器上对数据库进行冷备是远远不够的，至少还需要将本地产生的备份存放到一台远程的服务器中，确保不会因为本地数据库的的宕机而影响备份文件的使用。

冷备的优点是：

+ 备份简单，只要复制相关文件即可。

+ 备份文件易于在不同操作系统，不同MySQL 版本上进行恢复。

+ 恢复相当简单，只需要把文件恢复到指定位置即可。

+ 恢复速度快，不需要执行任何SQL 语句，也不需要重建索引。

冷备的缺点是：

+ InnoDB 存储引擎**冷备的文件通常比逻辑文件大很多**，因为表空间中存放着很多其他的数据，如undo 段，插入缓冲等信息。

+ **冷备也不总是可以轻易地跨平台。操作系统、MySQL 的版本、文件大小写敏感和浮点数格式都会成为问题**。

## 8.3 逻辑备份

### 8.3.1 mysqldump

​	mysqldump备份工具最初由Igor Romanenko编写完成，通常用来完成转存(dump)数据库的备份及不同数据库之间的移植，如从MySQL 低版本数据库升级到MySQL 高版本数据库，又或者从MySQL数据库移植到Oracle 、Microsoft SQL Server数据库等。

​	mysqldump的语法如下：

```bash
mysqldump [arguments] >file_name
```

​	如果想要备份所有的数据库，可以使用`--all-databases`选项：

```bash
mysqldump --all-databases >dump.sql
```

​	如果想要备份指定的数据库，可以使用`--databases`选项：

```bash
mysqldump --databases db1 db2 db3 >dump.sql
```

​	如果想要对test这个架构进行备份，可以使用如下语句：

```bash
mysqldump --single-transaction test >test_backup.sql
```

​	上述操作产生了一个对test架构的备份，使用`--single-transaction`选项来保证备的一致性。备份出的 test_backup.sql是文本文件，通过文本查看命令cat就可以得到文件的内容。

​	备份出的文件内容就是表结构和数据，所有这些都是用SQL语句方式表示。文件开始和结束的注释部分是用来设置MySQL 数据库的各项参数，一般用来使还原工作更有效和准确地进行。之后的部分先是CREATE TABLE语句，接着就是INSERT的SQL语句了。

​	mysqldump的参数选项很多，可以通过使用`mysqldump --help`命令来查看所有的参数，有些参数有缩写形式，如`--lock-tables`的缩写形式-l。这里列举一些比较重要的参数。

+ `--single-transaction`：在备份开始前，先执行START TRANSACTION命令，以此来获得备份的一致性，当前该参数只对 InnoDB存储引擎有效。<u>当启用该参数并进行备份时，确保没有其他任何的DDL语句执行，因为一致性读并不能隔离DDL操作</u>。
+ `--lock-tables(-l)`：在备份中，依次锁住**每个架构**下的所有表。一般用于 MyISAM存储引擎，<u>当备份时只能对数据库进行读取操作</u>，不过备份依然可以保证一致性。对于 InnoDB存储引擎，不需要使用该参数，用`-- single-transaction`即可。<u>并且`--lock-tables`和`--single-transaction`是互斥(exclusive)的，不能同时使用</u>。如果用户的 MySQL数据库中，既有 MyISAM存储引擎的表，又有 InnoDB存储引擎的表，那么这时用户的选择只有`--lock-tables`了。此外，正如前面所说的那样，`--lock-tables`选项是依次对每个架构中的表上锁的，因此**只能保证每个架构下表备份的一致性，而不能保证所有架构下表的一致性**。
+ `--lock-all-tables(-x)`：备份过程中，对**所有架构**中的所有表上锁。这个可以避免之前说的`--lock-tables`参数不能同时锁住所有表的问题。
+ `--add-drop-database`：在 CREATE DATABASE前先运行 DROP DATABASE。这个参数需要和`--all-databases`或者`--databases`选项一起使用。在默认情况下，导出的文本文件中并不会有CREATE DATABASE，除非指定了这个参数。
+ `--master-data[=value]`：通过该参数产生的备份转存文件主要用来建立一个replication。当value的值为1时，转存文件中记录CHANGE MASTER语句。当value的值为2时， CHANGE MASTER语句被写出SQL注释。在默认情况下，value的值为空。当 value值为1时，在备份文件中会看到:CHANGE MASTER TO MASTER_LOG_FILE='xen-server-bin.000006'，MASTER_LOG_POS=8095;当 value为2时，在备份文件中会看到 CHANGE MASTER语句被注释了。
+ `--master-data`：会自动忽略`--lock-tables`选项。如果没有使用`--single-transaction`选项，则会自动使用`--lock-all-tables`选项。
+ `--events(-E)`：备份事件调度器。
+ `--routines(-R)`：备份存储过程和函数。
+ `--triggers`：备份触发器。
+ `--hex-blob`：将 BINARY、VARBINARY、BLOG和BIT列类型备份为十六进制的格式。mysqldump导出的文件一般是文本文件，但是如果导出的数据中有上述这些类型,在文本文件模式下可能有些字符不可见，若添加`--hex-blob`选项，结果会以十六进制的方式显示。
+ `--tab=path(-T path)`：产生TAB分割的数据文件。对于每张表，mysqldump创建一个包含 CREATE TABLE语句的 table_name. sql文件，和包含数据的tbl_name. txt文件。可以使用`--fields-terminated-by=.…`，`--fields-enclosed-by=.…`，`--fields-optionally-enclosed-by=....`，`--fields-escaped-by=....`，`--lines-terminated-by=....`来改变默认的分割符、换行符等。

​	大多数DBA 喜欢用SELECT…INTO OUTFILE 的方式来导出一张表，但是通过mysqldump 一样可以完成工作，而且可以一次完成多张表的导出，并且实现导出数据的一致性。

- `--where='where_condition' (-W 'where_condition')`：导出给定条件的数据。

### 8.3.2 SELECT...INTO OUTFILE

​	SELECT... INTO 语句也是一种逻辑备份的方法，更准确地说是导出一张表中的数据。SELECT...INTO 的语法如下：

![img](https://img-blog.csdnimg.cn/20181104215938832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	其中FIELDS[TERMINATED BY 'string'] 表示每个列的分隔符，[[OPTIONALLY] ENCLOSED BY'char'］表示对于字符串的包含符，［ESCAPED BY 'char'］表示转义符。[STARTING BY 'string'] 表示每行的开始符号， TERMINATED BY 'string' 表示每行的结束符号。如果没有指定任何的FIELDS和LINES的选项，默认使用以下的设置：

```shell
FIELDS TERMINATED BY '\t' ENCLOSED BY''ESCAPED BY '\\'
LINES TERMINATED BY '\n' STARTING BY''
```

​	file_name 表示导出的文件，但文件所在的路径的权限必须是mysql：mysql的，否则MySQL 会报没有权限导出：

```shell
mysql> select* into outfile'/root/a.txt'from a;
ERROR 1 (HYOOO): Can't create/write to file'/root/a.txt'(Errcode: 13)
```

​	若已经存在该文件，则同样会报错：

```shell
[root@xen-server ~]# mysql test -e "select * into outfile '/home/mysql/a.txt'
fields terminated by ',' from a";
ERROR 1086 (HYOOO) at line 1: File '/home/mysql/a.txt' already exists
```

​	查看通过SELECT INTO 导出的表a 文件：

```shell
mysql> select * into outfile'/home/mysql/a.txt'from a;
Query OK, 3 rows affected (0.02 sec)

mysql> quit
Bye
[root@xen-server ~]# cat /home/mysql/a.txt
1 a
2 b
3 C
```

​	可以发现，默认导出的文件是以TAB 进行列分割的，如果想要使用其他分割符，如“,＂，则可以使用FIELDS TERMINATED BY 'string' 选项，如：

```shell
[root@xen-server ~]# mysql test -e "select * into outfile'/home/mysql/a.txt'
fields terminated by','from a";
[root@xen-server ~]# cat /home/mysql/a.txt
l,a
2,b
3,c
```

​	在Windows 平台下，由于换行符是"\r\n"，因此在导出时可能需要指定LINESTERMINATED BY 选项，如：

```shell
[root@xen-servermysql]# mysql test -e "select * into outfile'/home/mysql/a.txt'
fields terminated by ',' lines terminated by'\r\n' from a";

(root@xen-servermysql)# od -c a.txt
0000000 l, a \r ＼n 2, b \r \n 3 c \r \n
0000017
```

### 8.3.3 逻辑备份的恢复

+ mysqldump备份的文件就是导出的SQL，但是不包含"视图"，需要用户自行导出视图的定义，或者备份视图定义的frm 文件，并在恢复时进行导入。

---

​	mysqldump 的恢复操作比较简单，因为<u>备份的文件就是导出的SQL 语句</u>，一般只需要执行这个文件就可以了，可以通过以下的方法：

```shell
[root@xen-server ~Ill mysql -uroot -p <test_backup.sql
Enter password:
```

​	如果在导出时包含了创建和删除数据库的SQL 语句，那必须确保删除架构时，架构目录下没有其他与数据库相关的文件，否则可能会得到以下的错误：

```shell
mysql> drop database test;
ERROR 1010 (HYOOO): Error dropping database (can't rmdir'./test', errno: 39)
```

​	因为逻辑备份的文件是由SQL 语句组成的，也可以通过SOURCE 命令来执行导出的逻辑备份文件，如下：

```shell
mysql> source /home/mysql/test_backup.sql;
Query OK, O rows affected (0.00 sec)

Query OK, 0 rows affected (0.00 sec)
...
Query OK, 0 rows affected (0.00 sec)
Query OK, 0 rows affected (0.00 sec)
```

​	通过mysqldump 可以恢复数据库，但是经常发生的一个问题是， <u>mysqldump 可以导出存储过程、导出触发器、导出事件、导出数据，但是却**不能导出视图**</u>。因此，<u>如果用户的数据库中还使用了视图，那么在用mysqldump 备份完数据库后还需要导出视图的定义，或者备份视图定义的frm 文件，并在恢复时进行导入，这样才能保证mysqldump 数据库的完全恢复</u>。

### 8.3.4 LOAD DATA INFILE

​	若通过mysqldump-tab, 或者通过SELECT INTO OUTFILE 导出的数据需要恢复，这时可以通过命令LOAD DATA INFILE 来进行导入。LOAD DATA INFILE 的语法如下：

```shell
LOAD DATA INTO TABLE a IGNORE 1 LINES INFILE'/home/mysql/a.txt'
[REPLACE | IGNORE]
INTO TABLE tbl_name
[CHARACTER SET charset_name]
[{ FIELDS | COLUMNS}
[TERMINATED BY 'string']
[[OPTIONALLY) ENCLOSED BY 'char']
[ESCAPED BY 'char']
]
[LINES
[STARTING BY 'string']
[TERMINATED BY 'string']
]
[IGNORE number LINES]
[(col_name_or_user_var,...)]
[SET col_ name= expr,...]
```

​	要对服务器文件使用LOAD DATA INFILE, 必须拥有FILE 权。其中对于导入格式的选项和之前介绍的SELECT INTO OUTFILE 命令完全一样。IGNORE number LINES选项可以忽略导入的前几行。下面显示一个用LOAD DATA INFILE 命令导入文件的示例，并忽略第一行的导入：

```shell
mysql> load data infile'/home/mysql/a.txt'into table a;
Query OK, 3 rows affected (0.00 sec)
Records: 3 Deleted: 0 Skipped: 0 Warnings: 0
```

​	为了加快InnoDB 存储引擎的导入，可能希望导入过程忽略对外键的检查，因此可以使用如下方式：

```shell
mysql>SET @@foreign_key_checks=0;
Query OK, 0 rows affected (0.00 sec)

mysql>LOAD DATA INFILE '/home/mysql/a.txt' INTO TABLE a;
Query OK, 4 rows affected (0.00 sec)
Records: 4 Deleted: 0 Skipped: 0 Warnings: 0

mysql>SET @@foreign_key_checks=l;
Query OK, 0 rows affected (0.00 sec)
```

​	另外可以针对指定的列进行导入，如将数据导入列a 、b, 而c 列等于a 、b 列之和：

```sql
mysql>CREATE TABLE b (
	->a INT,
	->b INT,
	->c INT,
  -> PRIMARY KEY(a)
	->)ENGINE=InnoDB;
Query OK, O rows affected (0.01 sec)

mysql>LOAD DATA INFILE'/home/mysql/a.txt'
	->INTO TABLE b FIELDS TERMINATED BY ','(a,b)
	-> SET c=a+b;
Query OK, 4 rows affected (0.01 sec)
Records: 4 Deleted: 0 Skipped: 0 Warnings: 0

mysql>SELECT * FROM b;
十一一一十一一一一一一十一一一一一一十
I a 	 I b         I c
＋－－－＋－－－－－－＋－－－－一一十
I 1    I 2         I 3        I
I 2    I 3         I 5        I
I 4    I 5         I 9        I
I 5    I 6         I 11       I
+---+------+------+
4 rows in set (0.00 sec)
```

### 8.3.5 mysqlimport

​	mysqlimport 是MySQL 数据库提供的一个命令行程序，从本质上来说，是LOAD DATA INFILE 的命令接口，而且大多数的选项都和LOAD DATA INFILE 语法相同。其语法格式如下：

```shell
shell>mysqlimport [options] db_name textfilel [textfile2... ]
```

​	<u>和LOAD DATA INFILE 不同的是， mysqlimport 命令可以用来导入多张表</u>。并且通过`--user-thread`参数并发地导入不同的文件。**这里的并发是指并发导入多个文件，而不是指mysqlimport 可以并发地导入一个文件，这是有明显区别的**。此外，**<u>通常来说并发地对同一张表进行导入，其效果一般都不会比串行的方式好</u>**。下面通过mysqlimport 并发地导入2 张表：

```shell
[root@xen-servermysql] # mysqlimport --use-threads=2 test /home/mysql/t.txt /home/mysql/s.txt
test.s: Records: 5000000 Deleted: 0 Skipped: 0 Warnings: 0
test.t: Records: 5000000 Deleted: 0 Skipped: 0 Warnings: 0
```

​	如果在上述命令的运行过程中，查看MySQL 的数据库线程列表，应该可以看到类似如下内容：

```shell
mysql>SHOW FULL PROCESSLIST\G;
*************************** 1. row ***************************
Id: 46
User: rep
Host: www.dao.com:1028
db: NULL
Command: Binlog Dump
Time: 37651
State: Master has sent all binlog to slave; waiting for binlog to be updated
Info: NULL
*************************** 2. row ***************************
Id: 77
User: root
Host: localhost
db: test
Command: Query
Time: 0
State: NULL
Info: show full processlist
*************************** 3. row ***************************
Id: 83
User: root
Host: localhost
db: test
Command: Query
Time: 73
State: NULL
Info: LOAD DATA INFILE '/home/mysql/t.txt' INTO TABLE 't' IGNORE LINES
*************************** 4. row ***************************
Id: 84
User: root
Host: localhost
db: test
Command: Query
Time: 73
State: NULL
Info: LOAD DATA INFILE '/home/mysql/s.txt' INTO TABLE 's' IGNORE LINES
4 rows in set (0.00 sec)
```

​	可以看到**mysqlimport 实际上是同时执行了两句LOAD DTA INFILE 并发地导入数据**。

## 8.4 二进制日志备份与恢复

​	**二进制日志非常关键，用户可以通过它完成point-in-time的恢复工作。MySQL 数据库的replication同样需要二进制日志**。<u>在默认情况下并不启用二进制日志，要使用二进制日志首先必须启用它</u>。如在配置文件中进行设置：

```ini
[mysqld]
log-bin=mysql-bin
```

​	在3.2.4 节中已经阐述过，对于InnoDB存储引擎只简单启用二进制日志是不够的，还需要启用一些其他参数来保证最为安全和正确地记录二进制日志，因此对于InnoDB存储引擎，推荐的二进制日志的服务器配置应该是：

```ini
(mysqld]
log-bin= mysql-bin
sync_binlog = 1
innodb_support_xa = 1
```

​	<u>在备份二进制日志文件前，可以通过FLUSH LOGS 命令来生成一个新的二进制日志文件，然后备份之前的二进制日志</u>。

​	要恢复二进制日志也是非常简单的，通过mysqlbinlog 即可。mysqlbinlog 的使用方法如下：

```shell
shell>mysqlbinlog [options] log_file...
```

​	例如要还原binlog.0000001, 可以使用如下命令：

```shell
shell>mysqlbinlog binlog.0000001 | mysql-uroot -p test
```

​	**如果需要恢复多个二进制日志文件，最正确的做法应该是同时恢复多个二进制日志文件，而不是一个一个地恢复**，如：

```shell
shell>mysqlbinlog binlog.[0-10]* | mysql -u root -p test
```

​	也可以先通过mysqlbinlog 命令导出到一个文件，然后再通过SOURCE 命令来导入，这种做法的好处是可以对导出的文件进行修改后再导入，如：

```shell
shell>mysqlbinlog binlog.000001 > /tmp/statements.sql
shell>mysqlbinlog binlog.000002 >> /tmp/statements.sql
shell>mysql -u root -p -e "source /tmp/statements.sql"
```

​	`--start-position`和`--stop-position`选项可以用来指定从二进制日志的某个偏移量来进行恢复，这样可以跳过某些不正确的语句，如：

```shell
shell>mysqlbinlog--start-position=107856 binlog.0000001 | mysql-uroot -p test
```

​	`--start-datetime`和`--stop-datetime`选项可以用来指定从二进制日志的某个时间点来进行恢复，用法和`--start-position`和`--stop-position`选项基本相同。

## 8.5 热备

### 8.5.1 ibbackup

​	ibbackup是lnnoDB存储引擎官方提供的热备工具，可以同时备份MylSAM存储引擎和InnoDB存储引擎表。对于InnoDB 存储引擎表其备份工作原理如下：

1. 记录备份开始时， InnoDB存储引擎重做日志文件检查点的LSN。

2) 复制共享表空间文件以及独立表空间文件。

3) 记录复制完表空间文件后， lnnoDB 存储引擎重做日志文件检查点的LSN 。

4) 复制在备份时产生的重做日志。

​	对于事务的数据库，如Microsoft SQL Server 数据库和Oracle 数据库，热备的原理大致和上述相同。可以发现，**在备份期间不会对数据库本身有任何影响，所做的操作只是复制数据库文件，因此任何对数据库的操作都是允许的，不会阻塞任何操作**。故ibbackup 的优点如下：

+ 在线备份，不阻塞任何的SQL 语句。

+ 备份性能好，**备份的实质是复制数据库文件和重做日志文件**。

+ 支持压缩备份，通过选项，可以支持不同级别的压缩。

+ 跨平台支持， ibbackup 可以运行在Linux 、Windows 以及主流的UNIX 系统平台上。

​	ibbackup 对InnoDB 存储引擎表的恢复步骤为：

+ 恢复表空间文件。

+ 应用重做日志文件。

​	ibbackup 提供了一种高性能的热备方式，是InnoDB 存储引擎备份的首选方式。不过它是收费软件，并非免费的软件。好在开源的魅力就在千社区的力最， Percona 公司给用户带来了开源、免费的XtraBackup 热备工具，它实现所有ibbackup 的功能，并且扩展支持了真正的增量备份功能。因此，更好的选择是使用XtraBackup 来完成热备的工作。

### 8.5.2 XtraBackup

​	XtraBackup 备份工具是由Percona 公司开发的开源热备工具。支持MySQL5.0 以上的版本。XtraBackup 在GPLv2 开源下发布。

### 8.5.3 XtraBackup 实现增量备份

​	MySQL 数据库本身提供的工具并不支持真正的增量备份，更准确地说，二进制日志的恢复应该是point-in-time 的恢复而不是增量备份。而XtraBackup 工具支持对于InnoDB 存储引擎的增量备份，其工作原理如下：

1. 首选完成一个全备，并记录下此时检查点的LSN。

2) 在进行增量备份时，比较表空间中每个页的LSN 是否大于上次备份时的LSN，如果是，则备份该页，同时记录当前检查点的LSN。

## * 8.6 快照备份

​	**MySQL 数据库本身并不支持快照功能，因此快照备份是指通过文件系统支持的快照功能对数据库进行备份**。

​	<u>备份的前提是将所有数据库文件放在同一文件分区中，然后对该分区进行快照操作</u>。支持快照功能的文件系统和设备包括FreeBSD 的UFS文件系统， Solaris 的ZFS 文件系统， GNU/Linux 的逻辑管理器(Logical VolumeManager, LVM) 等。这里以LVM 为例进行介绍， UFS 和ZFS 的快照实现大致和LVM 相似。

​	LVM 是LINUX 系统下对磁盘分区进行管理的一种机制。LVM 在硬盘和分区之上建立一个逻辑层，来提高磁盘分区管理的灵活性。管理员可以通过LVM 系统轻松管理磁盘分区，例如，将若干个磁盘分区连接为一个整块的卷组(Volume Group) ，形成一个存储池。管理员可以在卷组上随意创建逻辑卷(Logical Volumes) ，并进一步在逻辑卷上创建文件系统。管理员通过LVM 可以方便地调整卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配。简单地说，用户可以通过LVM由物理块设备（如硬盘等）创建物理卷，由一个或多个物理卷创建卷组，最后从卷组中创建任意个逻辑卷（不超过卷组大小），如图8-1 所示。

![img](https://img-blog.csdnimg.cn/20181104230017619.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	图8-2 显示了由多块磁盘组成的逻辑卷LV0 。

![img](https://img-blog.csdnimg.cn/20181104230123464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	通过vgdisplay 命令查看系统中有哪些卷组，如：

![img](https://img-blog.csdnimg.cn/20181104230247487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	vgdisplay 命令的输出结果显示当前系统有一个rep 的卷组，大小为260.77GB, 该卷组访问权限是read/write 等。命令lvdisplay 可以用来查看当前系统中有哪些逻辑卷：

![img](https://img-blog.csdnimg.cn/20181104230428712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20181104230509350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/2018110423053292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	可以看到，一共有3 个逻辑卷，都属于卷组rep, 每个逻辑卷的大小都是100GB 。/dev/rep/repdata 这个逻辑卷有两个只读快照，并且当前都是激活状态的。

​	**LVM 使用了写时复制(Copy-on-write) 技术来创建快照**。当创建一个快照时，仅复制原始卷中数据的元数据(meta data) ，并不会有数据的物理操作，因此快照的创建过程是非常快的。当快照创建完成，原始卷上有写操作时，快照会跟踪原始卷块的改变，将要改变的数据在改变之前复制到快照预留的空间里，因此这个原理的实现叫做写时复制。而对于快照的读取操作，如果读取的数据块是创建数据来源卷快照后没有修改过的，那么会将读操作直接重定向到原始卷上，如果要读取的是已经修改过的块，则将读取保存在快照中该块在原始卷上改变之前的数据。因此，采用写时复制机制保证了读取快照时得到的数据与快照创建时一致。

![img](https://img-blog.csdnimg.cn/20181104230945655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	图8-3 显示了LVM 的快照读取，可见B 区块被修改了，因此历史数据放入了快照区域。读取快照数据时， A 、C 、D 块还是从原有卷中读取，而B 块就需要从快照读取了。

​	命令lvcreate 可以用来创建一个快照，`--permission r` 表示创建的快照是只读的：

![img](https://img-blog.csdnimg.cn/20181104231049571.png)

​	在快照制作完成后可以用Ivdisplay 命令查看，输出中的COW-table size 字段表示该快照最大的空间大小， Allocated to snapshot 字段表示该快照目前空间的使用状况：

![img](https://img-blog.csdnimg.cn/20181104231309996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	可以看到，当前快照只使用0.04％的空间。快照在最初创建时总是很小，当数据来源卷的数据不断被修改时，这些数据库才会放入快照空间，这时快照的大小才会慢慢增大。

​	<u>用LVM 快照备份InnoDB 存储引擎表相当简单，只要把与InnoDB 存储引擎相关的文件如共享表空间、独立表空间、重做日志文件等放在同一个逻辑卷中，然后对这个逻辑卷做快照备份即可</u>。

​	**在对InnoDB 存储引擎文件做快照时，数据库无须关闭，即可以进行在线备份。虽然此时数据库中可能还有任务需要往磁盘上写数据，但这不会妨碍备份的正确性。因为InnoDB 存储引擎是事务安全的引擎，在下次恢复时，数据库会自动检查表空间中页的状态，并决定是否应用重做日志，恢复就好像数据库被意外重启了**。

## 8.7 复制

### * 8.7.1 复制的工作原理

​	复制（replication）是MySQL 数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。总体来说， replication 的工作原理分为以下3 个步骤：

1. **主服务器(master) 把数据更改记录到二进制日志(binlog) 中。**

2) **从服务器(slave) 把主服务器的二进制日志复制到自己的中继日志(relay log) 中。**

3) **从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性**。

​	复制的工作原理并不复杂，其实就是一个完全备份加上二进制日志备份的还原。不同的是这个二进制日志的还原操作基本上实时在进行中。这里特别**<u>需要注意的是，复制不是完全实时地进行同步，而是异步实时。这中间存在主从服务器之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大</u>**。复制的工作原理如图8-4 所示。

![img](https://img-blog.csdnimg.cn/2020062908045784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FpbHViYnk=,size_16,color_FFFFFF,t_70)

​	图8-4 MySQL 数据库的复制工作原理

​	从服务器有2 个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是SQL 线程，复制执行中继日志。MySQL4.0 版本之前，从服务器只有1 个线程，既负责读取二进制日志，又负责执行二进制日志中的SQL 语句。这种方式不符合高性能的要求，目前已淘汰。因此如果查看一个从服务器的状态，应该可以看到类似如下内容：

![img](https://img-blog.csdnimg.cn/20181104232033981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20181104232128322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	可以看到ID 为1 的线程就是I/O 线程，目前的状态是等待主服务器发送二进制日ID 为2 的线程是SQL 线程，负责读取中继日志并执行。目前的状态是已读取所有的中继日志，等待中继日志被I/O线程更新。

​	在replication 的主服务器上应该可以看到一个线程负责发送二进制日志，类似内容如下：

![img](https://img-blog.csdnimg.cn/20181104232256639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	之前已经说过MySQL 的复制是异步实时的，并非完全的主从同步。若用户要想得知当前的延迟，可以通过命令`SHOW SLAVE STATUS`和`SHOW MASTER STATUS`得知，如：

![img](https://img-blog.csdnimg.cn/2018110423245454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	通过`SHOW SLAVE STATUS`命令可以观察当前复制的运行状态，一些主要的变量如表8-1 所示。

​	表8-1 SHOW SLAVE STATUS 的主要变量

| 变量                  | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| Slave_IO_State        | 显示当前IO线程的状态,上述状态显示的是等待主服务发送二进制日志 |
| Master_Log_File       | 显示当前同步的主服务器的二进制日志,上述显示当前同步的是主服务器的mysql-bin.000007 |
| Read_master_Log_Pos   | 显示当前同步到主服务器上二进制日志的偏移量位置,单位是字节。上述的示例显示当前同步到 mysql-bin000007的551671偏移量位置,即已经同步了mysql-bin000007这个二进制日志中529MB (555176471/10241024)的内容 |
| Relay_Master_Log_File | 当前中继日志同步的二进制日志                                 |
| Relay_Log_File        | 显示当前写入的中继日志                                       |
| Relay_Log_Pos         | 显示当前执行到中继日志的偏移量位置                           |
| Slave_IO_Running      | 从服务器中IO线程的运行状态,YES表示运行正常                   |
| Slave_SQL_Running     | 从服务器中SQL线程的运行状态,YES表示运行正常                  |
| Exec_master_Log_Pos   | 表示同步到主服务器的二进制日志偏移量的位置。(Read_Master_Log_Pos-Exec_Master_Log._Pos)可以表示当前SQL线程运行的延时,单位是字节。上述例子显示当前主从服务器是完全同步的 |

​	命令SHOW MASTER STATUS 可以用来查看主服务器中二进制日志的状态，如：

![img](https://img-blog.csdnimg.cn/20181104233459678.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	可以看到，当前二进制日志记录了偏移量606181078 的位置，该值减去这一时间点时从服务器上的`Read_Master_Log_Pos`，就可以得知I/O线程的延时。

​	对于一个优秀的MySQL 数据库复制的监控，用户不应该仅仅监控从服务器上I/O线程和SQL 线程运行得是否正常，同时也应该监控从服务器和主服务器之间的延迟，确保从服务器上的数据库总是尽可能地接近于主服务器上数据库的状态。

### 8.7.2 快照+复制的备份架构

​	复制可以用来作为备份，但功能不仅限于备份，其主要功能如下：

+ 数据分布。由于MySQL 数据库提供的复制并不需要很大的带宽要求，因此可以在不同的数据中心之间实现数据的复制。

+ **读取的负载平衡**。通过建立多个从服务器，可将读取平均地分布到这些从服务器中，并且减少了主服务器的压力。一般通过DNS 的Round-Robin 和Linux 的LVS 功能都可以实现负载平衡。
+ 数据库备份。复制对备份很有帮助，但是从服务器不是备份，不能完全代替备份。
+ 高可用性和故障转移。通过复制建立的从服务器有助于故障转移，减少故障的停机时间和恢复时间。

​	可见，复制的设计不是简简单单用来备份的，并且只是用复制来进行备份是远远不够的。假设当前应用采用了主从的复制架构，从服务器作为备份。这时，一个初级DBA执行了误操作，如`DROP DATABASE`或`DROP TABLE`，这时从服务器也跟着运行了。这时用户怎样从服务器进行恢复呢？

​	因此，<u>一个比较好的方法是通过对从服务器上的数据库所在分区做快照，以此来避免误操作对复制造成影响。当发生主服务器上的误操作时，只需要将从服务器上的快照进行恢复，然后再根据二进制日志进行point-in-time 的恢复即可</u>。因此快照＋复制的备份架构如图8-5 所示。

![img](https://img-blog.csdnimg.cn/2018110423405093.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5jaGFvaGFvMTIzMjE=,size_16,color_FFFFFF,t_70)

​	还有一些其他的方法来调整复制，比如采用延时复制，即间歇性地开启从服务器上的同步，保证大约一小时的延时。这的确也是一个方法，只是数据库在高峰和非高峰期间每小时产生的二进制日志量是不同的，用户很难精准地控制。另外，这种方法也不能完全起到对误操作的防范作用。

​	此外，**<u>建议在从服务上启用read-only 选项，这样能保证从服务器上的数据仅与主服务器进行同步，避免其他线程修改数据</u>**。如：

```ini
[mysqld]
read-only
```

​	在启用read-only 选项后，如果操作从服务器的用户没有SUPER 权限，则对从服务器进行任何的修改操作会抛出一个错误，如：

```shell
mysql>INSERT INTO z SELECT 2;
ERROR 1290 (HY000): The MySQL server is running with the --read-only option so
it cannot execute this statement
```

## 8.8 小结

​	本章中介绍了不同的备份类型，并介绍了MySQL 数据库常用的一些备份方式。同时主要介绍了对于InnoDB 存储引擎表的备份。不管是mysqldump 还是xtrabackup 工具，都可以对InnoDB 存储引擎表进行很好的在线热备工作。最后，介绍了复制，通过快照和复制技术的结合，可以保证用户得到一个异步实时的在线MySQL 备份解决方案。

# 9. 性能调优

​	性能优化不是一项简单的工作，但也不是复杂的难事，关键在于对InnoDB 存储引擎特性的了解。如果之前各章的内容读者已经完全理解并掌握了，那就应该基本掌握了如何使InnoDB 存储引擎更好地工作。本章将从以下几个方面集中讲解InnoDB 存储引擎的性能问题：

+ 选择合适的CPU

+ 内存的重要性

+ 硬盘对数据库性能的影响

+ 合理地设置RAID

+ 操作系统的选择也很重要

+ 不同文件系统对数据库的影响

+ 选择合适的基准测试工具

## 9.1 选择合适的CPU

​	用户首先需要清楚当前数据库的应用类型。一般而言，可分为两大类： OLTP(Online Transaction Processing，在线事务处理）和OLAP (Online Analytical Processing，在线分析处理）。这是两种截然不同的数据库应用。OLAP 多用在数据仓库或数据集市中，一般需要执行复杂的SQL 语句来进行查询； OLTP 多用在日常的事物处理应用中，如银行交易、在线商品交易、Blog 、网络游戏等应用。相对于OLAP，数据库的容量较小。

​	InnoDB 存储引擎一般都应用于OLTP 的数据库应用，这种应用的特点如下：

+ 用户操作的并发量大

+ 事务处理的时间一般比较短

+ 查询的语句较为简单，一般都走索引
+ 复杂的查询较少

​	可以看出， OLTP 的数据库应用本身对CPU 的要求并不是很高，因为复杂的查询可能需要执行比较、排序、连接等非常耗CPU 的操作，这些操作在OLTP 的数据库应用中较少发生。因此，**可以说OLAP 是CPU 密集型的操作，而OLTP 是IO 密集型的操作。建议在采购设备时，将更多的注意力放在提高IO 的配置上**。

​	此外，为了获得更多内存的支持，用户采购的CPU 必须支持64 位，否则无法支持64 位操作系统的安装。因此，为新的应用选择64 位的CPU 是必要的前提。现在4 核的CPU 已经非常普遍，如今Intel 和AMD 又相继推出了8 核的CPU，将来随着操作系统的升级我们还可能看到128 核的CPU，这都需要数据库更好地对其提供支持。

​	从InnoDB 存储引擎的设计架构上来看，其主要的后台操作都是在一个单独的master thread 中完成的，因此并不能很好地支持多核的应用。当然，开源社区已经通过多种方法来改变这种局面，而InnoDBl.0 版本在各种测试下已经显示出对多核CPU 的处理性能的支持有了极大的提高，而lnnoDB 1.2 版本又支持多个purge 线程，以及将刷新操作从master thread 中分离出来。因此，若用户的CPU 支持多核， InnoDB 的版本应该选择1.1或更高版本。另外，如果CPU 是多核的，可以通过修改参数`innodb_read_io_threads`和`innodb_write_io_threads`来增大IO的线程，这样也能更充分有效地利用CPU的多核性能。

​	在当前的MySQL 数据库版本中，一条SQL 查询语句只能在一个CPU 中工作，并不支持多CPU 的处理。OLTP 的数据库应用操作一般都很简单，因此对OLTP 应用的影响并不是很大。但是，多个CPU 或多核CPU对处理大并发掀的请求还是会有帮助。

## 9.2 内存的重要性

​	内存的大小是最能直接反映数据库的性能。通过之前各个章节的介绍，已经了解到<u>lnnoDB 存储引擎既缓存数据，又缓存索引，并且将它们缓存于一个很大的缓冲池中，即InnoDB Buffer Pool 。因此，内存的大小直接影响了数据库的性能</u>。

​	应该在开发应用前预估“活跃“数据库的大小是多少，并以此确定数据库服务器内存的大小。当然，要使用更多的内存还必须使用64 位的操作系统。

​	如何判断当前数据库的内存是否已经达到瓶颈了呢？可以通过查看当前服务器的状态，比较物理磁盘的读取和内存读取的比例来判断缓冲池的命中率，通常InnoDB 存储引擎的缓冲池的命中率不应该小于99% ，如：

```shell
mysql>SHOW GLOBAL $TAUTS LIKE'innodb%read%'\G;
*************************** 1. row***************************
Variable_name: Innodb_buffer_pool_read_ahead
Value: 0
*************************** 2. row***************************
variable_name: Innodb_buffer_pool_read_ahead_evicted
Value: 0
*****•********************* 3. row***************************
variable_name: Innodb_buffer_pool_read_requests
Value: 167051313
*************************** 4. row***************************
Variable_name: Innodb_buffer_pool_reads
Value: 129236
*************************** 5. row***************************
Variable_name: Innodb_data_pending_reads
Value: 0
*************************** 6. row***************************
Variable_name: Innodb_data_read
Value: 2135642112
*************************** 7. row***************************
Variable_name: Innodb_data_reads
Value: 130309
*************************** 8. row***************************
Variable_name: Innodb_pages_read
Value: 130215
*************************** 9. row***************************
Variable name: Innodb rows read
Value: 17651085
9 rows in set (0.00 sec)
```

​	上述参数的具体含义如表9-1 所示。

​	表9-1 当前服务器的状态参数

| 参数                                  | 说明                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| Innodb_buffer_pool_reads              | 表示从物理磁盘读取的页数                                     |
| Innodb_buffer_pool_read_ahead         | 预读的页数                                                   |
| Innodb_buffer_pool_read_ahead_evicted | 预读的页数，但是没有被读取就从缓冲池中被替换的页的数量，一般用来判断预读的效率 |
| Innodb_buffer_pool_read_requests      | 从缓冲池中读取的次数                                         |
| Innodb_data_read                      | 总共读入的字节数                                             |
| Innodb_data_reads                     | 发起读请求的次数，每次读取可能需要读取多个页                 |

​	以下公式可以计算各种对缓冲池的操作：
$$
缓冲池命中率 = \frac{Innodb\_buffer\_pool\_read\_requests}{ (Innodb\_buffer\_pool\_read\_requests + Innodb\_buffer\_pool\_read\_ahead+Innodb\_buffer\_pool\_reads)}
$$

$$
平均每次读区的字节数=\frac{Innodb\_data\_read}{Innodb\_data\_reads}
$$

​	从上面的例子看，缓冲池命中率＝167051313/ (167051313+129236+0) = 99.92%。

​	<u>即使缓冲池的大小已经大于数据库文件的大小，这也并不意味着没有磁盘操作。数据库的缓冲池只是一个用来存放热点的区域，后台的线程还负责将脏页异步地写入到磁盘。此外，每次事务提交时还需要将日志写入重做日志文件</u>。

## 9.3 硬盘对数据库性能的影响

### 9.3.1 传统机械硬盘

​	当前大多数数据库使用的都是传统的机械硬盘。机械硬盘的技术目前已非常成熟，在服务器领域一般使用SAS 或SATA 接口的硬盘。服务器机械硬盘开始向小型化转型，目前大部分使用2.5 寸的SAS 机械硬盘。

​	机械硬盘有两个重要的指标：一个是寻道时间，另一个是转速。当前服务器机械硬盘的寻道时间已经能够达到3ms，转速为15 000RPM (rotate per minute) 。传统机械硬盘最大的问题在于读写磁头，读写磁头的设计使硬盘可以不再像磁带一样，只能进行顺序访问，而是可以随机访问。但是，<u>机械硬盘的访问需要耗费长时间的磁头旋转和定位来查找，因此顺序访问的速度要远高于随机访问。传统关系数据库的很多设计也都是在尽盘充分地利用顺序访问的特性</u>。

​	<u>通常来说，可以将多块机械硬盘组成RAID 来提高数据库的性能，也可以将数据文件分布在不同硬盘上来达到访问负载的均衡</u>。

### 9.3.2 固态硬盘

​	固态硬盘，更准确地说是基于闪存的固态硬盘，是近几年出现的一种新的存储设备，其内部由闪存(Flash Memory) 组成。因为闪存的低延迟性、低功耗，以及防能性，闪存设备已在移动设备上得到了广泛的应用。企业级应用一般使用固态硬盘，通过并联多块闪存来进一步提高数据传输的吞吐量。传统的存储服务提供商EMC 公司已经开始提供基于闪存的固态硬盘的TB 级别存储解决方案。数据库厂商Oracle 公司最近也开始提供绑定固态硬盘的Exadata 服务器。

​	不同于传统的机械硬盘，闪存是一个完全的电子设备，没有传统机械硬盘的读写磁头。因此，固态硬盘不需要像传统机械硬盘一样，需要耗费大量时间的磁头旋转和定位来查找数据，所以<u>固态硬盘可以提供一致的随机访问时间</u>。固态硬盘这种对数据的快速读写和定位特性是值得研究的。

​	另一方面，**闪存中的数据是不可以更新的，只能通过扇区(sector) 的覆盖重写，而在覆盖重写之前，需要执行非常耗时的擦除(erase) 操作**。擦除操作不能在所含数据的扇区上完成，而需要在删除整个被称为擦除块的基础上完成，这个擦除块的尺寸大于扇区的大小，通常为128KB 或者256KB 。此外，每个擦除块有擦写次数的限制。已经有一些算法来解决这个问题。但是对于数据库应用，需要认真考虑固态硬盘在写入方面存在的问题。

​	因为存在上述写入方面的问题，闪存提供的读写速度是非对称的。读取速度要远快于写入的速度，因此对于固态硬盘在数据库中的应用，应该好好利用其读取的性能，避免过多的写入操作。

​	由于闪存是一个完全的电子设备，没有读写磁头等移动部件，因此固态硬盘有着较低的访问延时。当主机发布一个读写请求时，固态硬盘的控制器会把I/O命令从逻辑地址映射成实际的物理地址，写操作还需要修改相应的映射表信息。算上这些额外的开销，固态硬盘的访问延时一般小于0.1ms 左右。

​	对于固态硬盘在InnoDB 存储引擎中的优化，可以增加`innodb_io_capacity`变量的值达到充分利用固态硬盘带来的高IOPS 特性。不过这需要用户根据自己的应用进行有针对性的调整。在InnoSQL 及InnoDB1.2 版本中，可以选择关闭邻接页的刷新，同样可以为数据库的性能带来一定效果的提升。

​	此外，还可以使用InnoSQL 开发的L2 Cache 解决方案，该解决方案可以充分利用固态硬盘的超高速随机读取性能，在内存缓冲池和传统存储层之间建立一层基于闪存固态硬盘的二级缓冲池，以此来扩充缓冲池的容量，提高数据库的性能。与基于磁盘的固态硬盘Cache 类似的解决方案还有Facebook Flash Cache 和bcache，只不过它们是基于通用文件系统的，对lnnoDB 存储引擎本身的优化较少。

## 9.4 合理地设置RAID

### 9.4.1 RAID 类型

​	RAID (Redundant Array of Independent Disks, 独立磁盘冗余数组）的基本思想就是把多个相对便宜的硬盘组合起来，成为一个磁盘数组，使性能达到甚至超过一个价格昂贵、容拭巨大的硬盘。由于将多个硬盘组合成为一个逻辑扇区， RAID 看起来就像一个单独的硬盘或逻辑存储单元，因此操作系统只会把它当作一个硬盘。

​	RAID 的作用是：

+ 增强数据集成度

+ 增强容错功能

+ 增加处理量或容蜇

​	根据不同磁盘的组合方式，常见的RAID 组合方式可分为RAID0 、RAID1 、RAID5 、RAID 10 和RAID 50 等。

+ RAID 0

  将多个磁盘合并成一个大的磁盘，不会有冗余，并行I/O 速度最快。

  在所有的级别中， RAID 0 的速度是最快的。

  多磁盘的效能就等于（单一磁盘效能 * 磁盘数），但实际上受限于总线I/O瓶颈及其他因素的影响， RAID 效能会随边际递减。也就是说，假设一个磁盘的效能是50MB/s，两个磁盘的RAID 0效能约96MB/s，三个磁盘的RAID 0 也许是130MB/s 而不是150MB/s 。

+ RAID 1

  两组以上的N 个磁盘相互作为镜像。

  在一些多线程操作系统中能有很好的读取速度，但写入速度略有降低。除非拥有相同数据的主磁盘与镜像同时损坏，否则只要一个磁盘正常即可维持运作，可靠性最高。

  无论用多少磁盘作为RAID 1，仅算一个磁盘的容量，是所有RAID 中磁盘利用率最低的一个级别。

+ RAID 5

  使用的是Disk Striping （硬盘分区）技术。至少需要需要三个硬盘， RAID 5 不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5 的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID 5 的一个磁盘数据发生损坏后，利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。

  RAID 5 可以理解为是RAID 0 和RAID 1的折中方案。

+ RAID 10 和 RAID 01

  RAID 10 是先镜像再分区数据，将所有硬盘分为两组，视为RAID 0的最低组合，然后将这两组各自视为RAID 1 运作。RAID 10 有着不错的读取速度，而且拥有比RAID 0 更高的数据保护性。

  RAID 01 则与RAID 10的程序相反，先分区再将数据镜射到两组硬盘。RAID 01 将所有的硬盘分为两组，变成RAID I 的最低组合，而将两组硬盘各自视为RAID 0运作。

+ RAID 50

  RAID 50 也被称为镜像阵列条带，由至少六块硬盘组成，像RAID 0 一样，数据被分区成条带，在同一时间内向多块磁盘写入：像RAID 5 一样，也是以数据的校验位来保证数据的安全，且校验条带均匀分布在各个磁盘上，其目的在于提高RAID5 的读写性能。

​	对于数据库应用来说， RAID 10 是最好的选择，它同时兼顾了RAID 1 和RAID 0的特性。但是，当一个磁盘失效时，性能可能会受到很大的影响，因为条带(strip) 会成为瓶颈。我曾在生产环境下遇到过的情况是，两台负载基本相同的数据库，一台正常的服务器磁盘IO 负载为20％左右，而另一台服务器IO 负载却高达90% 。

### 9.4.2 RAID Write Back功能

​	RAID Write Back 功能是指RAID 控制器能够将写入的数据放入自身的缓存中，并把它们安排到后面再执行。这样做的好处是，不用等待物理磁盘实际写入的完成，因此写入变得更快了。对于数据库来说，这显得十分重要。例如，对重做日志的写入，在将`sync_binlog`设为1 的情况下二进制日志的写入、脏页的刷新等都可以使性能得到明显的提升。

​	<u>但是，当操作系统或数据库关机时， Write Back 功能可能会破坏数据库的数据。这是由于已经写入的数据库可能还在RAID 卡的缓存中，数据可能并没有完全写入磁盘，而这时故障发生了。为了解决这个问题，目前大部分的硬件RAID 卡都提供了电池备份单元(BBU, Battery Backup Unit) ，因此可以放心地开启Write Back 的功能</u>。不过我发现每台服务器的出厂设置都不相同，应该将RAID 设置要求告知服务器提供商，开启一些认为需要的参数。

​	如果没有启用Write Back 功能，那么在RAID 卡设置中显示的就是Write Through。Write Through 没有缓冲写入，因此写入性能可能不是很好，但它却是最安全的写入。

​	即使用户开启了Write Back 功能， RAID 卡也可能只是在Write Through 模式下工作。这是因为安全使用Write Back 的前提是RAID 卡有电池备份单元。为了确保电池的有效性， RAID 卡会定期检查电池状态，并在电池电量不足时对其进行充电，在充电的这段时间内会将Write Back 功能切换为最为安全的Write Through 。

​	用户可以在没有电池备份单元的情况下强制启用Write Back 功能，也可以在电池充电时强制使用Write Back 功能，只是写入是不安全的。用户应该非常确信这点，否则不应该在没有电池备份单元的情况下启用Write Back 。

### 9.4.3 RAID 配置工具

​	对RAID 卡进行配置可以在服务器启动时进入一个类似于BIOS 的配置界面，然后再对其进行各种设置。此外，很多厂商都开发了各种操作系统下的软件对RAID 进行配置，如果用户使用的是LSI 公司生产提供的RAID 卡，则可以使用MegaCLI 工具来进行配置。

## 9.5 操作系统的选择

+ Linux

+ FreeBSD

+ Solaris

+ Windows

  在Windows 操作系统下表名不区分大小写，而Linux 操作系统却是大小写敏感的，这点在开发阶段需要特别注意。

​	4G 内存在当前已经非常普遍了，即使是桌面用户也开始使用8G 的内存。为了可以更好地使用大于4G 的内存容量，用户必须使用64 位的操作系统，上述介绍的这些操作系统都提供了64 位的版本。此外，使用64 位的操作系统还必须使用64 位的软件。这听上去像是句废话，但是我曾多次看到32 位的MySQL 数据库安装在64 位的系统上，导致不能充分发挥64 位操作系统的内存寻址能力。

## 9.6 不同的文件系统对数据库性能的影响

​	每个操作系统都默认支持一种文件系统并推荐用户使用，如Windows 默认支持NTFS，Solaris 默认支持ZFS 。而对于Linux 这样的操作系统，不同发行版本默认支持的文件系统各不相同，有的默认支持EXT3，有的是ReiserFS，有的是EXT4，有的是XFS。

​	虽然不同特性的文件系统有很多，但是在实际使用过程中从未感觉到文件系统的性能差异有多大。网上有多个关于XFS 文件系统的“神话”，认为其是多么地适合数据库应用，性能较之EXT3 有极大的提升。但是在实际测试和使用后发现，它的性能和EXT3 在整体上没有大的差距。因此， **DBA 首先应该把更多的注意力放到数据库上，而不是纠结于文件系统**。

​	文件系统可提供的功能也许是DBA 需要关注的，例如ZFS 文件系统本身就可以支持快照，因此就不需要LVM 这样的逻辑卷管理工具。此外，可能还需要知道mount 的参数，这些参数在每个文件系统中可能有所不同。

# 9.7 选择合适的基准测试工具

​	基准测试工具可以用来对数据库或操作系统调优后的性能进行对比。MySQL 数据库本身提供了一些比较优秀的工具，这里将介绍另外两款更为优秀和常用的基准测试工具： sysbench 和mysql-tpcc。

### 9.7.1 sysbench

​	sysbench 是一个模块化的、跨平台的多线程基准测试工具，主要用于测试各种不同系统参数下的数据库负载情况。它主要包括以下几种测试方式：

+ CPU 性能

+ 磁盘IO 性能

+ 调度程序性能

+ 内存分配及传输速度

+ POSIX 线程性能

+ 数据库OLTP 基准测试

​	sysbench 的数据库OLTP 测试支持MySQL 、PostgreSQL 和Oracle 。目前sysbench主要用于Linux 操作系统，开源社区已经将sysbench 移植到Windows，并支持对Microsoft SQL Server 数据库的测试。

### 9.7.2 mysql-tpcc

​	TPC (Transaction Processing Performance Council, 事务处理性能协会）是一个用来评价大型数据库系统软硬件性能的非盈利组织。TPC-C 是TPC 协会制定的，用来测试典型的复杂OLTP （在线事务处理）系统的性能。目前在学术界和工业界普遍采用TPC-C来评价OLTP 应用的性能。

​	tpcc-mysql 是开源的TPC-C 测试工具，该测试工具完全遵守TPC-C的标准。

## 9.8 小结

​	在这一章中我们根据lnnoDB 存储引擎的应用特点对CPU 、内存、硬盘、固态硬盘、RAID 卡做了详细的介绍，相信只有通过理解InnoDB 存储引擎的应用场合和范围才能更好地对其进行调优。最后，介绍了两个在Linux 操作系统平台下常用的基准测试工具sysbench 和tpcc-mysql，借助这两个工具可以更有效地得知当前系统的负载承受能力，以及对MySQL 数据库的调优结果进行分析。

# 10. InnoDB 存储引擎源代码的编译和调试

## 10.1 获取lnnoDB 存储引擎源代码

## 10.2 lnnoDB 源代码结构

​	进入lnnoDB 存储引擎的源代码文件夹，介绍一些主要文件夹内的源代码的具体作用。

+ btr: B＋树的实现。

+ buf: 缓冲池的实现，包括LRU 算法， Flush 刷新算法等。

+ diet: InnoDB 存储引擎中内存数据字典的实现。

+ dyn: InnoDB 存储引擎中动态数组的实现。

+ fil: InnoDB 存储引擎中文件数据结构以及对文件的一些操作。

+ fsp：可以理解为file space，即对lnnoDB 存储引擎物理文件的管理，如页、区、段等。

+ ha：哈希算法的实现。

+ handler：继承于MySQL 的handler, 插件式存储引擎的实现。

+ ibuf: 插入缓冲的实现。

+ include: InnoDB 将头文件(`.h`, `.ic`) 文件都统一放在这个文件夹下。

+ lock: lnnoDB 存储引擎锁的实现，如S锁、X锁，以及定义锁的一系列算法。

+ log: 日志缓冲和重组日志文件的实现。对重组日志感兴趣的应该好好阅读该源代码。

+ mem: 辅助缓冲池的实现，用来申请一些数据结构的内存。

+ mtr: 事务的底层实现。

+ os：封装一些对于操作系统的操作。

+ page: 页的实现。

+ row: 对于各种类型行数据的操作。

+ srv ：对于InnoDB 存储引擎参数的设计。

+ sync: InnoDB 存储引擎互斥量(Mutex) 的实现。

+ thr：InnoDB 储存引擎封装的可移植的线程库。

+ trx: 事务的实现。

+ ut ：工具类。

## 10.3 MySQL 5.1 版本编译和调试lnnoDB 源代码

### 10.3.1 Windows 下的调试

### 10.3.2 Linux 下的调试

## 10.4 cmake 方式编译和调试lnnoDB 存储引擎

## 10.5 小结

​	MySQL 数据库和InnoDB 存储引擎都是开源的，我们可以通过常用的开发工具，如Visual Studio 、Eclipse 对其进行编译和调试，以此来更好地了解数据库内部运行机制。有能力的开发人员可以进一步扩展数据库的功能，这就是开源的魅力，这在Oracle、Microsoft SQL Server、DB2 等商业数据库中是永远不可能发生的。
